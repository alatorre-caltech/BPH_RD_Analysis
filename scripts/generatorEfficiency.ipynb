{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook to collect the information of the generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-04T23:00:57.326302Z",
     "start_time": "2019-11-04T23:00:57.319852Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys, os, re, yaml, pickle\n",
    "import commands\n",
    "from glob import glob\n",
    "sys.path.append('../lib')\n",
    "\n",
    "import time, datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import signal\n",
    "\n",
    "class TimeoutError(Exception):\n",
    "    pass\n",
    "\n",
    "class timeout:\n",
    "    def __init__(self, seconds=1, error_message='Timeout'):\n",
    "        self.seconds = seconds\n",
    "        self.error_message = error_message\n",
    "    def handle_timeout(self, signum, frame):\n",
    "        raise TimeoutError(self.error_message)\n",
    "    def __enter__(self):\n",
    "        signal.signal(signal.SIGALRM, self.handle_timeout)\n",
    "        signal.alarm(self.seconds)\n",
    "    def __exit__(self, type, value, traceback):\n",
    "        signal.alarm(0)\n",
    "\n",
    "# with timeout(seconds=1):\n",
    "#     try:\n",
    "#         time.sleep(2)\n",
    "#     except TimeoutError:\n",
    "#         print 'Got it'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-04T23:00:57.880990Z",
     "start_time": "2019-11-04T23:00:57.535016Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import mode\n",
    "import matplotlib.pyplot as plt\n",
    "from prettytable import PrettyTable\n",
    "import humanfriendly\n",
    "from progressBar import ProgressBar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-04T23:00:59.175644Z",
     "start_time": "2019-11-04T23:00:57.885084Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to JupyROOT 6.12/07\n"
     ]
    }
   ],
   "source": [
    "import uproot as ur\n",
    "import ROOT as rt\n",
    "rt.gErrorIgnoreLevel = rt.kError\n",
    "rt.RooMsgService.instance().setGlobalKillBelow(rt.RooFit.ERROR)\n",
    "import root_numpy as rtnp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load FWLite C++ libraries\n",
    "rt.gSystem.Load(\"libFWCoreFWLite.so\");\n",
    "rt.gSystem.Load(\"libDataFormatsFWLite.so\");\n",
    "rt.FWLiteEnabler.enable()\n",
    "\n",
    "# load FWlite python libraries\n",
    "from DataFormats.FWLite import Lumis\n",
    "from DataFormats.FWLite import Handle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "site_loc_conf = '/mnt/hadoop/store/user/ocerri'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampleFile = '/storage/user/ocerri/work/CMSSW_10_2_3/src/ntuplizer/BPH_RDntuplizer/production/samples.yml'\n",
    "samples = yaml.load(open(sampleFile))['samples']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-04T23:00:59.195419Z",
     "start_time": "2019-11-04T23:00:59.179871Z"
    }
   },
   "outputs": [],
   "source": [
    "class Bauble(object):\n",
    "    def __init__(self, in_sample, \n",
    "                 candLoc='/storage/user/ocerri/BPhysics/data/cmsMC_private/', \n",
    "                 candDir='ntuples_B2DstMu'):\n",
    "        if not in_sample in samples.keys():\n",
    "            raise\n",
    "        self.sample = in_sample\n",
    "        self.candLoc = candLoc\n",
    "        self.candDir = candDir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-04T23:01:19.700694Z",
     "start_time": "2019-11-04T23:01:19.684231Z"
    }
   },
   "outputs": [],
   "source": [
    "setName = 'SignalRegion'\n",
    "outDic = {}\n",
    "\n",
    "outDic['mu'] = Bauble('B0_MuNuDmst_PU20')\n",
    "\n",
    "outDic['tau'] = Bauble('B0_TauNuDmst_PU20')\n",
    "\n",
    "outDic['Hc'] = Bauble('B0_DmstHc_PU20')\n",
    "\n",
    "outDic['Dstst'] = Bauble('Bp_MuNuDstst_PU20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-04T23:01:19.700694Z",
     "start_time": "2019-11-04T23:01:19.684231Z"
    }
   },
   "outputs": [],
   "source": [
    "# setName = 'SidePT'\n",
    "# outDic = {}\n",
    "\n",
    "# outDic['JPsiKst'] = Bauble('B0_JpsiKst_PU0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gather the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in outDic.values():\n",
    "    d.MINIAOD_dirs = []\n",
    "    for part in samples[d.sample]['parts']:\n",
    "        aux = glob(part)\n",
    "        if len(aux) > 0:\n",
    "            aux = os.path.dirname(part)\n",
    "        else:\n",
    "            aux = glob(site_loc_conf + part[:-38].replace('ocerri-','') + '/*/*')\n",
    "        d.MINIAOD_dirs += aux\n",
    "    \n",
    "    d.full_name = samples[d.sample]['dataset']\n",
    "    d.ntuples_dir = glob(os.path.join(d.candLoc, d.full_name, d.candDir))[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-04T23:01:20.322756Z",
     "start_time": "2019-11-04T23:01:20.307921Z"
    }
   },
   "outputs": [],
   "source": [
    "def getEff(k,N):\n",
    "    e = k/float(N)\n",
    "    de = np.sqrt(e*(1-e)/N)\n",
    "    return [e, de]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "handle = {}\n",
    "handle['genFilter'] = [Handle('GenFilterInfo'), ('genFilterEfficiencyProducer', '', 'SIM')]\n",
    "handle['genProduct'] = [Handle('GenLumiInfoProduct'), ('generator', '', 'SIM')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-04T23:02:17.419301Z",
     "start_time": "2019-11-04T23:02:09.765091Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "--> mu\n",
      "Analizing 5000 logs\n",
      "[####################]  100% - Tot. time: 1735.1 s\n",
      "Skipped 50 files for timeout\n",
      "Xsec: 1.4799e+11 +/- 2.5726e+06 fb (1.7e-05)\n",
      "eff generator: 7.005e-03 +/- 3.000e-06 (4.3e-04)\n",
      "Analyzing 784 ntuplizer jobs\n",
      "[####################]  100% - Tot. time: 12.3 s\n",
      "eff candidates (trigger): 2.406e-01 +/- 6.819e-05 (2.8e-04)\n",
      "eff candidates (cand): 9.106e-02 +/- 9.357e-05 (1.0e-03)\n",
      "eff candidates: 2.191e-02 +/- 2.335e-05 (1.1e-03)\n",
      "\n",
      "\n",
      "--> tau\n",
      "Analizing 5000 logs\n",
      "[##------------------]  13% - ETA: 14.6 min "
     ]
    }
   ],
   "source": [
    "N_max = 5000\n",
    "\n",
    "for name, d in outDic.iteritems():\n",
    "    print '\\n\\n--> ' + name\n",
    "    N_gen = 0\n",
    "    N_cuts = 0\n",
    "    xsec = []\n",
    "    xsec_err = []\n",
    "    \n",
    "    fileList = []\n",
    "    for directory in d.MINIAOD_dirs:\n",
    "        fileList += glob(directory + '/out_MINIAODSIM_*.root')\n",
    "    if N_max > 0 and N_max < len(fileList):\n",
    "        fileList = np.random.choice(fileList, N_max)\n",
    "    \n",
    "    print 'Analizing', len(fileList), 'logs'\n",
    "    pb = ProgressBar(maxEntry=len(fileList))\n",
    "    skippedFiles = []\n",
    "    for i_j, fileName in enumerate(fileList):\n",
    "        pb.show(i_j)\n",
    "        \n",
    "        with timeout(seconds=3):\n",
    "            try:\n",
    "                for lumi in Lumis(fileName):\n",
    "                    prods = {}\n",
    "                    for k,v in handle.iteritems():\n",
    "                        lumi.getByLabel(v[1], v[0])\n",
    "                        prods[k] = v[0].product()\n",
    "                    N_cuts += prods['genFilter'].numEventsPassed()\n",
    "                    N_gen += prods['genFilter'].numEventsTotal()\n",
    "                    xs = prods['genProduct'].getProcessInfos()[0].lheXSec()\n",
    "                    xsec.append(xs.value())\n",
    "                    xsec_err.append(xs.error())\n",
    "            except TimeoutError:\n",
    "                skippedFiles.append(fileName)\n",
    "    print 'Skipped {} files for timeout'.format(len(skippedFiles))\n",
    "    \n",
    "    xsec = np.array(xsec)\n",
    "    xsec_err = np.array(xsec_err)\n",
    "    s2 = np.square(xsec_err)\n",
    "    num = np.sum(xsec/s2)\n",
    "    den = np.sum(1./s2)\n",
    "    xsec = 1e3*num/den\n",
    "    xsec_err = 1e3*np.sqrt(1/den)\n",
    "    print 'Xsec: {:1.4e} +/- {:1.4e} fb ({:1.1e})'.format(xsec, xsec_err, xsec_err/xsec)\n",
    "    d.xsec = [xsec, xsec_err]\n",
    "    \n",
    "    e, de = getEff(N_cuts, N_gen)\n",
    "    print 'eff generator: {:1.3e} +/- {:1.3e} ({:1.1e})'.format(e,de, de/e)\n",
    "    d.effGEN = [e, de]\n",
    "    d.nTotGen = N_gen\n",
    "\n",
    "    if not os.path.isdir(d.ntuples_dir):\n",
    "        continue\n",
    "    cand_out_list = glob(os.path.join(d.ntuples_dir,'out/job*.out'))\n",
    "    N_analyzed = 0\n",
    "    N_trg = 0\n",
    "    N_cand = 0\n",
    "    print 'Analyzing {} ntuplizer jobs'.format(len(cand_out_list))\n",
    "    pb = ProgressBar(maxEntry=len(cand_out_list))\n",
    "    for ic, cand_out in enumerate(cand_out_list):\n",
    "        pb.show(ic)\n",
    "        step5_log_lines = open(cand_out).readlines()\n",
    "        eff_ln = []\n",
    "        for line in reversed(step5_log_lines):\n",
    "            if 'efficiency:' in line:\n",
    "                eff_ln.append(line)\n",
    "\n",
    "        aux = re.search('[0-9]+/[0-9]+', eff_ln[1]).group(0)\n",
    "        aux = aux.split('/')\n",
    "        N_analyzed += int(aux[1])\n",
    "        N_trg += int(aux[0])\n",
    "        \n",
    "        aux = re.search(': [0-9]+/', eff_ln[0]).group(0)\n",
    "        N_cand += int(aux[2:-1])\n",
    "    \n",
    "    e, de = getEff(N_trg, N_analyzed)\n",
    "    d.effCAND_trg = e, de\n",
    "    print 'eff candidates (trigger): {:1.3e} +/- {:1.3e} ({:1.1e})'.format(e,de, de/e)\n",
    "    \n",
    "    e, de = getEff(N_cand, N_trg)\n",
    "    d.effCAND_cand = e, de\n",
    "    print 'eff candidates (cand): {:1.3e} +/- {:1.3e} ({:1.1e})'.format(e,de, de/e)\n",
    "    \n",
    "    e, de = getEff(N_cand, N_analyzed)\n",
    "    d.effCAND = e, de\n",
    "    print 'eff candidates: {:1.3e} +/- {:1.3e} ({:1.1e})'.format(e,de, de/e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n, d in outDic.iteritems():\n",
    "    dump_dic = {'nTotGen': int(d.nTotGen)}\n",
    "    for k in ['xsec', 'effGEN', 'effCAND', 'effCAND_trg', 'effCAND_cand']:\n",
    "        aux = getattr(d, k)\n",
    "        dump_dic[k] = [float(aux[0]), float(aux[1])]\n",
    "    outdir = os.path.join(d.candLoc, d.full_name)\n",
    "    if not os.path.isdir(outdir):\n",
    "        os.makedirs(outdir)\n",
    "    with open(os.path.join(outdir,'effMC.yaml'), 'w') as dumpF:\n",
    "        f.write(yaml.dump(dump_dic, default_flow_style=False, default_style=''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
