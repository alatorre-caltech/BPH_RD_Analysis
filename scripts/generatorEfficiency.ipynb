{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook to collect the information of the generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-04T23:00:57.326302Z",
     "start_time": "2019-11-04T23:00:57.319852Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys, os, re, yaml, pickle\n",
    "import commands\n",
    "from glob import glob\n",
    "from prettytable import PrettyTable\n",
    "sys.path.append('../lib')\n",
    "\n",
    "import time, datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import signal\n",
    "\n",
    "class TimeoutError(Exception):\n",
    "    pass\n",
    "\n",
    "class timeout:\n",
    "    def __init__(self, seconds=1, error_message='Timeout'):\n",
    "        self.seconds = seconds\n",
    "        self.error_message = error_message\n",
    "    def handle_timeout(self, signum, frame):\n",
    "        raise TimeoutError(self.error_message)\n",
    "    def __enter__(self):\n",
    "        signal.signal(signal.SIGALRM, self.handle_timeout)\n",
    "        signal.alarm(self.seconds)\n",
    "    def __exit__(self, type, value, traceback):\n",
    "        signal.alarm(0)\n",
    "\n",
    "# with timeout(seconds=1):\n",
    "#     try:\n",
    "#         time.sleep(2)\n",
    "#     except TimeoutError:\n",
    "#         print 'Got it'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-04T23:00:57.880990Z",
     "start_time": "2019-11-04T23:00:57.535016Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import mode\n",
    "import matplotlib.pyplot as plt\n",
    "from prettytable import PrettyTable\n",
    "from progressBar import ProgressBar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-04T23:00:59.175644Z",
     "start_time": "2019-11-04T23:00:57.885084Z"
    }
   },
   "outputs": [],
   "source": [
    "import uproot as ur\n",
    "import ROOT as rt\n",
    "rt.gErrorIgnoreLevel = rt.kError\n",
    "rt.RooMsgService.instance().setGlobalKillBelow(rt.RooFit.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load FWLite C++ libraries\n",
    "rt.gSystem.Load(\"libFWCoreFWLite.so\");\n",
    "rt.gSystem.Load(\"libDataFormatsFWLite.so\");\n",
    "rt.FWLiteEnabler.enable()\n",
    "\n",
    "# load FWlite python libraries\n",
    "from DataFormats.FWLite import Lumis\n",
    "from DataFormats.FWLite import Handle\n",
    "# import commands"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "site_loc_conf = '/mnt/hadoop/store/user/ocerri'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampleFile = '/storage/user/ocerri/work/CMSSW_10_2_3/src/ntuplizer/BPH_RDntuplizer/production/samples.yml'\n",
    "samples = yaml.load(open(sampleFile))['samples']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-04T23:00:59.195419Z",
     "start_time": "2019-11-04T23:00:59.179871Z"
    }
   },
   "outputs": [],
   "source": [
    "class Bauble(object):\n",
    "    def __init__(self, in_sample, \n",
    "                 candLoc='/storage/user/ocerri/BPhysics/data/cmsMC_private/', \n",
    "                 candDir='ntuples_B2DstMu'):\n",
    "        if not in_sample in samples.keys():\n",
    "            raise\n",
    "        self.sample = in_sample\n",
    "        self.candLoc = candLoc\n",
    "        self.candDir = candDir\n",
    "        \n",
    "        self.MINIAOD_dirs = []\n",
    "        for part in samples[self.sample]['parts']:\n",
    "            aux = glob(part)\n",
    "            if len(aux) > 0:\n",
    "                aux = [os.path.dirname(part)]\n",
    "            else:\n",
    "                aux = glob(site_loc_conf + part[:-38].replace('ocerri-','') + '/*/*')\n",
    "            self.MINIAOD_dirs += aux\n",
    "\n",
    "        self.full_name = samples[self.sample]['dataset']\n",
    "        self.ntuples_dir = glob(os.path.join(self.candLoc, self.full_name, self.candDir))[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Max 3 dataset per time otherwise run out of memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-04T23:01:19.700694Z",
     "start_time": "2019-11-04T23:01:19.684231Z"
    }
   },
   "outputs": [],
   "source": [
    "outDic = {}\n",
    "\n",
    "# outDic['mu_0'] = Bauble('B0_MuNuDmst_PU0')\n",
    "# outDic['mu_20'] = Bauble('B0_MuNuDmst_PU20')\n",
    "# outDic['mu_35'] = Bauble('B0_MuNuDmst_PU35')\n",
    "# outDic['muHQET_0'] = Bauble('B0_MuNuDmst_HQETcentral_PU0')\n",
    "\n",
    "outDic['tau'] = Bauble('B0_TauNuDmst_PU20')\n",
    "\n",
    "outDic['Hc'] = Bauble('B0_DmstHc_PU20')\n",
    "\n",
    "outDic['Dstst'] = Bauble('Bp_MuNuDstst_PU20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-04T23:01:19.700694Z",
     "start_time": "2019-11-04T23:01:19.684231Z"
    }
   },
   "outputs": [],
   "source": [
    "# outDic['JPsiKst_0'] = Bauble('B0_JpsiKst_PU0', candDir='ntuples_B2JpsiKst')\n",
    "# outDic['JPsiKst_20'] = Bauble('B0_JpsiKst_PU20', candDir='ntuples_B2JpsiKst')\n",
    "# outDic['JPsiKst_35'] = Bauble('B0_JpsiKst_PU35', candDir='ntuples_B2JpsiKst')\n",
    "\n",
    "# outDic['JPsiKstFSR_20'] = Bauble('B0_JpsiKstFSR_PU20', candDir='ntuples_B2JpsiKst')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-04T23:01:20.322756Z",
     "start_time": "2019-11-04T23:01:20.307921Z"
    }
   },
   "outputs": [],
   "source": [
    "def getEff(k,N):\n",
    "    e = k/float(N)\n",
    "    de = np.sqrt(e*(1-e)/N)\n",
    "    return [e, de]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator Efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "handle = {}\n",
    "handle['genFilter'] = [Handle('GenFilterInfo'), ('genFilterEfficiencyProducer', '', 'SIM')]\n",
    "handle['genProduct'] = [Handle('GenLumiInfoProduct'), ('generator', '', 'SIM')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyzeMINIAODs(fileList):  \n",
    "    print 'Analizing', len(fileList), 'MINIAOD'\n",
    "    N_gen = 0\n",
    "    N_cuts = 0\n",
    "    xsec = []\n",
    "    xsec_err = []\n",
    "    pb = ProgressBar(maxEntry=len(fileList))\n",
    "    skippedFiles = []\n",
    "    for i_j, fileName in enumerate(fileList):\n",
    "        pb.show(i_j)\n",
    "        with timeout(seconds=1):\n",
    "            try:\n",
    "#                 cmd = 'python generatorEfficiency_MINIAODSIM.py ' + fileName\n",
    "#                 status, output = commands.getstatusoutput(cmd)\n",
    "#                 aux = output.split(' ')\n",
    "#                 N_gen += float(aux[0])\n",
    "#                 N_cuts += float(aux[1])\n",
    "#                 xsec.append(float(aux[2]))\n",
    "#                 xsec_err.append(float(aux[4]))\n",
    "                for lumi in Lumis(fileName):\n",
    "                    prods = {}\n",
    "                    for k,v in handle.iteritems():\n",
    "                        lumi.getByLabel(v[1], v[0])\n",
    "                        prods[k] = v[0].product()\n",
    "                    N_cuts += prods['genFilter'].numEventsPassed()\n",
    "                    N_gen += prods['genFilter'].numEventsTotal()\n",
    "                    xs = prods['genProduct'].getProcessInfos()[0].lheXSec()\n",
    "                    xsec.append(xs.value())\n",
    "                    xsec_err.append(xs.error())\n",
    "            except TimeoutError:\n",
    "                skippedFiles.append(fileName)\n",
    "    print 'Skipped {} files'.format(len(skippedFiles))\n",
    "    \n",
    "    xsec = np.array(xsec)\n",
    "    xsec_err = np.array(xsec_err)\n",
    "    return N_gen, N_cuts, xsec, xsec_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_max = 1000\n",
    "recreate = [] #outDic.keys()\n",
    "for n, d in outDic.iteritems():\n",
    "    print '\\n\\n--> ' + d.sample\n",
    "    \n",
    "    outdir = os.path.join(d.candLoc, d.full_name)\n",
    "    outyamlFile = os.path.join(outdir,'effMCgenerator.yaml')\n",
    "    if os.path.isfile(outyamlFile) and not n in recreate:\n",
    "        print 'Already present'\n",
    "        continue\n",
    "        \n",
    "    fileList = []\n",
    "    for directory in d.MINIAOD_dirs:\n",
    "        fileList += glob(directory + '/out_MINIAODSIM_*.root')\n",
    "    if N_max > 0 and N_max < len(fileList):\n",
    "        fileList = np.random.choice(fileList, N_max)\n",
    "    \n",
    "    N_gen, N_cuts, xsec, xsec_err = analyzeMINIAODs(fileList)\n",
    "    s2 = np.square(xsec_err)\n",
    "    num = np.sum(xsec/s2)\n",
    "    den = np.sum(1./s2)\n",
    "    xsec = 1e3*num/den\n",
    "    xsec_err = 1e3*np.sqrt(1/den)\n",
    "    print 'Xsec: {:1.4e} +/- {:1.4e} fb ({:1.1e})'.format(xsec, xsec_err, xsec_err/xsec)\n",
    "    d.xsec = [xsec, xsec_err]\n",
    "    \n",
    "    e, de = getEff(N_cuts, N_gen)\n",
    "    print 'eff generator: {:1.3e} +/- {:1.3e} ({:1.1e})'.format(e,de, de/e)\n",
    "    d.effGEN = [e, de]\n",
    "\n",
    "    dump_dic = {}\n",
    "    for k in ['xsec', 'effGEN']:\n",
    "        aux = getattr(d, k)\n",
    "        dump_dic[k] = [float(aux[0]), float(aux[1])]\n",
    "    if not os.path.isdir(outdir):\n",
    "        os.makedirs(outdir)\n",
    "    with open(outyamlFile, 'w') as dumpF:\n",
    "        dumpF.write(yaml.dump(dump_dic, default_flow_style=False, default_style=''))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ntuplizer efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-04T23:02:17.419301Z",
     "start_time": "2019-11-04T23:02:09.765091Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "for d in outDic.values():\n",
    "    print '\\n\\n--> ' + d.sample\n",
    "\n",
    "    if not os.path.isdir(d.ntuples_dir):\n",
    "        continue\n",
    "    cand_out_list = glob(os.path.join(d.ntuples_dir,'out/job*.out'))\n",
    "    N_analyzed = 0\n",
    "    N_trg = 0\n",
    "    N_cand = 0\n",
    "    print 'Analyzing {} ntuplizer job logs'.format(len(cand_out_list))\n",
    "    pb = ProgressBar(maxEntry=len(cand_out_list))\n",
    "    for ic, cand_out in enumerate(cand_out_list):\n",
    "        pb.show(ic)\n",
    "        eff_ln = []\n",
    "        counters = []\n",
    "        takingCounters = False\n",
    "        for line in open(cand_out).readlines():\n",
    "            if 'efficiency:' in line:\n",
    "                eff_ln.append(line)\n",
    "            elif 'counters:' in line:\n",
    "                    takingCounters = True\n",
    "            elif takingCounters and line[:-1].isdigit():\n",
    "                counters.append(int(line[:-1]))\n",
    "            elif takingCounters:\n",
    "                takingCounters = False\n",
    "\n",
    "        aux = re.search('[0-9]+/[0-9]+', eff_ln[0]).group(0)\n",
    "        aux = aux.split('/')\n",
    "        N_analyzed += int(aux[1])\n",
    "        N_trg += int(aux[0])\n",
    "        \n",
    "        aux = re.search(': [0-9]+/', eff_ln[1]).group(0)\n",
    "        N_cand += int(aux[2:-1])\n",
    "        \n",
    "        counters=np.array(counters)\n",
    "        if not hasattr(d, 'counters'):\n",
    "            d.counters = counters\n",
    "        else:\n",
    "            d.counters += counters\n",
    "        \n",
    "    d.nTotMINIAOD = N_analyzed\n",
    "    d.nTotCAND = N_cand\n",
    "    print 'Total MINIAOD:', N_analyzed\n",
    "    print 'Total candidates:', N_cand\n",
    "    \n",
    "    e, de = getEff(N_trg, N_analyzed)\n",
    "    d.effCAND_trg = e, de\n",
    "    print 'eff candidates (trigger): {:1.3e} +/- {:1.3e} ({:1.1e})'.format(e,de, de/e)\n",
    "    \n",
    "    e, de = getEff(N_cand, N_trg)\n",
    "    d.effCAND_cand = e, de\n",
    "    print 'eff candidates (cand): {:1.3e} +/- {:1.3e} ({:1.1e})'.format(e,de, de/e)\n",
    "    \n",
    "    e, de = getEff(N_cand, N_analyzed)\n",
    "    d.effCAND = e, de\n",
    "    print 'eff candidates: {:1.3e} +/- {:1.3e} ({:1.1e})'.format(e,de, de/e)\n",
    "    \n",
    "    print 'Getting the total rates (if existing)'\n",
    "    try:\n",
    "        fCandLoc = glob(os.path.join(d.ntuples_dir,'out_CAND_*.root'))[0]\n",
    "        fCand = ur.open(fCandLoc)\n",
    "        Trate = fCand['p']['Trate']\n",
    "        d.rate = {}\n",
    "        for k in Trate.keys():\n",
    "            r = Trate.array(k)[0]\n",
    "            r *= 1e12 #GeV -> meV\n",
    "            d.rate[str(k)] = r\n",
    "        print 'Done'\n",
    "    except:\n",
    "        print 'Not found'\n",
    "    \n",
    "    dump_dic = {'nTotMINIAOD': int(d.nTotMINIAOD), 'nTotCAND': int(d.nTotCAND)}\n",
    "    for k in ['effCAND', 'effCAND_trg', 'effCAND_cand']:\n",
    "        aux = getattr(d, k)\n",
    "        dump_dic[k] = [float(aux[0]), float(aux[1])]\n",
    "    if hasattr(d, 'rate'):\n",
    "        for k, v in d.rate.iteritems():\n",
    "            dump_dic['rate_'+k] = float(v)\n",
    "    with open(os.path.join(d.ntuples_dir,'effCAND.yaml'), 'w') as dumpF:\n",
    "        dumpF.write(yaml.dump(dump_dic, default_flow_style=False, default_style=''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = PrettyTable()\n",
    "t.field_names = ['Sample'] + [str(i) for i in range(d.counters.shape[0])]\n",
    "for n, d in outDic.iteritems():\n",
    "    eff = np.zeros((d.counters.shape[0], 2))\n",
    "    eff[0] = d.effCAND_trg\n",
    "    for i in range(d.counters[1:].shape[0]):\n",
    "        eff[i+1] = getEff(d.counters[i+1], d.nTotMINIAOD)\n",
    "    t.add_row([n] + ['{:.2f}'.format(100*e[0]) for e in eff])\n",
    "    x = np.arange(eff.shape[0])\n",
    "    p = plt.errorbar(x, eff[:, 0], eff[:,1], lw=0, elinewidth=5, label=n)\n",
    "    \n",
    "#     plt.plot(x[[0,-1]], 2*[d.effCAND[0]], '-', color=p[0].get_color())\n",
    "#     plt.fill_between(x[[0,-1]], 2*[d.effCAND[0]-d.effCAND[1]], 2*[d.effCAND[0]+d.effCAND[1]], color=p[0].get_color(), alpha=0.2)\n",
    "print t\n",
    "plt.rcParams.update({'font.size': 20})\n",
    "plt.xlabel('Counter')\n",
    "plt.ylabel('Efficiency')\n",
    "plt.legend(loc='best', numpoints=1)\n",
    "plt.ylim(0.01,1.05)\n",
    "plt.xlim(-1, eff.shape[0])\n",
    "plt.grid(True, which='both')\n",
    "plt.yscale('log')\n",
    "plt.gcf().set_size_inches(10, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
