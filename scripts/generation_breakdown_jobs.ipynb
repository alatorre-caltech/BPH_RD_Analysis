{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook to collect the information of the generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-04T23:00:57.326302Z",
     "start_time": "2019-11-04T23:00:57.319852Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys, os, re\n",
    "import commands\n",
    "import pickle\n",
    "from glob import glob\n",
    "sys.path.append('../lib')\n",
    "\n",
    "from progressBar import ProgressBar\n",
    "import time, datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-04T23:00:57.880990Z",
     "start_time": "2019-11-04T23:00:57.535016Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import mode\n",
    "import matplotlib.pyplot as plt\n",
    "for style in plt.style.available:\n",
    "        plt.style.use(style)\n",
    "        if style == 'seaborn-bright': \n",
    "            break\n",
    "# plt.style.use('seaborn-bright')\n",
    "from prettytable import PrettyTable\n",
    "import humanfriendly\n",
    "from progressBar import ProgressBar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-04T23:00:59.175644Z",
     "start_time": "2019-11-04T23:00:57.885084Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to JupyROOT 6.12/07\n"
     ]
    }
   ],
   "source": [
    "import uproot as ur\n",
    "import ROOT as rt\n",
    "rt.gErrorIgnoreLevel = rt.kError\n",
    "rt.RooMsgService.instance().setGlobalKillBelow(rt.RooFit.ERROR)\n",
    "import root_numpy as rtnp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-04T23:00:59.195419Z",
     "start_time": "2019-11-04T23:00:59.179871Z"
    }
   },
   "outputs": [],
   "source": [
    "class Bauble: \n",
    "    def __init__(self, d, ntuples, jo='jobs_out/'):\n",
    "        if not d[:-1]=='/':\n",
    "            d += '/'\n",
    "        if not jo[:-1]=='/':\n",
    "            jo += '/'\n",
    "        if jo[0] == '/':\n",
    "            jo = jo[1:]\n",
    "        if not ntuples[:-1]=='/':\n",
    "            ntuples += '/'\n",
    "        if ntuples[0] == '/':\n",
    "            ntuples = ntuples[1:]\n",
    "        self.dir = d\n",
    "        self.jo = jo\n",
    "        self.dir_jo = d + jo\n",
    "        self.dir_ntuples = d + ntuples\n",
    "outDic = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-04T23:01:19.700694Z",
     "start_time": "2019-11-04T23:01:19.684231Z"
    }
   },
   "outputs": [],
   "source": [
    "# outDic['DoubleCore'] = Bauble('../data/cmsMC_private/BPH_Tag-B0_MuNuDmst-pD0bar-kp_13TeV-pythia8_Hardbbbar_PTFilter5_0p0-evtgen_ISGW2_PU20_10-2-3/')\n",
    "# outDic['SignleCore'] = Bauble('../data/cmsMC_private/BPH_Tag-B0_MuNuDmst-pD0bar-kp_13TeV-pythia8_Hardbbbar_PTFilter5_0p0-evtgen_ISGW2_PU20_10-2-3/',\n",
    "#                               jo='jobs_out_singleCore'\n",
    "#                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "outDic['B2JspiKst'] = Bauble('../data/cmsMC_private/BPH_Tag-Probe_B0_JpsiKst-mumuKpi-kp_13TeV-pythia8_Hardbbbar_PTFilter5_0p0-evtgen_SVV_PU20_10-2-3/',\n",
    "                             ntuples='ntuples_B2JpsiKst'\n",
    "                            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-04T23:01:20.322756Z",
     "start_time": "2019-11-04T23:01:20.307921Z"
    }
   },
   "outputs": [],
   "source": [
    "def getEff(k,N):\n",
    "    e = k/float(N)\n",
    "    de = np.sqrt(e*(1-e)/N)\n",
    "    return [e, de]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--> B2JspiKst\n",
      "[####################]  100% - Tot. time: 1.5 s\n",
      "Xsec: 1.4879e+11 +/- 3.2637e+07 fb (2.2e-04)\n",
      "CMSSW eff: 9.992e-03 +/- 4.528e-05 (4.5e-03)\n",
      "Ntuplizer eff: 7.094e-02 +/- 9.392e-05 (1.3e-03)\n",
      "\tTrg eff: 3.018e-01 +/- 1.679e-04 (5.6e-04)\n",
      "\tDecay tree eff: 2.351e-01 +/- 2.824e-04 (1.2e-03)\n"
     ]
    }
   ],
   "source": [
    "for name, d in outDic.iteritems():\n",
    "    print '\\n--> ' + name\n",
    "    dicOut = {}\n",
    "    #Get CMSSW step info\n",
    "    N_gen = 0\n",
    "    N_cuts = 0\n",
    "    xsec = []\n",
    "    xsec_err = []\n",
    "    job_dir_list = glob(d.dir_jo + 'out_*[0-9]')[:100]\n",
    "    pb = ProgressBar(len(job_dir_list))\n",
    "    for i_j, job_dir in enumerate(job_dir_list):\n",
    "        pb.show(i_j)\n",
    "        if not os.path.isfile(job_dir + '/step1.log'): \n",
    "            continue\n",
    "        cmd = 'tail -n 40 ' + job_dir + '/step1.log'\n",
    "        status, step1_log_lines = commands.getstatusoutput(cmd)\n",
    "        for il, line in enumerate(step1_log_lines.split('\\n')):\n",
    "            if line.startswith('Before Filter: total cross section'):\n",
    "                aux = line[37:-3].split(' +- ')\n",
    "                xsec.append(float(aux[0]))\n",
    "                xsec_err.append(float(aux[1]))\n",
    "            elif line.startswith('Filter efficiency (event-level)='):\n",
    "                l=line[34:-24]\n",
    "                l = l.split(') = ')[0]\n",
    "                l = l.split(') / (')\n",
    "                N_cuts += int(l[0])\n",
    "                N_gen += int(l[1])\n",
    "                break\n",
    "        e, de = getEff(N_cuts, N_gen)\n",
    "\n",
    "    xsec = np.array(xsec)\n",
    "    xsec_err = np.array(xsec_err)\n",
    "    s2 = np.square(xsec_err)\n",
    "    num = np.sum(xsec/s2)\n",
    "    den = np.sum(1./s2)\n",
    "    xsec = 1e3*num/den\n",
    "    xsec_err = 1e3*np.sqrt(1/den)\n",
    "    print 'Xsec: {:1.4e} +/- {:1.4e} fb ({:1.1e})'.format(xsec, xsec_err, xsec_err/xsec)\n",
    "    dicOut['xsec'] = [xsec, xsec_err]\n",
    "    \n",
    "    e, de = getEff(N_cuts, N_gen)\n",
    "    print 'CMSSW eff: {:1.3e} +/- {:1.3e} ({:1.1e})'.format(e,de, de/e)\n",
    "    dicOut['CMSSWFilterEff'] = [e, de]\n",
    "    \n",
    "    N_an = 0\n",
    "    N_trg = 0\n",
    "    N_cand = 0\n",
    "    cand_out_list = glob(d.dir_ntuples + 'out/job*.out')\n",
    "    for cand_out in cand_out_list:\n",
    "        step5_log_lines = open(cand_out).readlines()\n",
    "        eff_ln = []\n",
    "        for line in step5_log_lines:\n",
    "            if 'efficiency:' in line:\n",
    "                eff_ln.append(line)\n",
    "        if len(eff_ln) != 2:\n",
    "            continue\n",
    "            \n",
    "        aux = re.search('[0-9]+/[0-9]+', eff_ln[0]).group(0)\n",
    "        aux = aux.split('/')\n",
    "        N_an += int(aux[1])\n",
    "        N_trg += int(aux[0])\n",
    "        \n",
    "        aux = re.search(': [0-9]+/', eff_ln[1]).group(0)\n",
    "        N_cand += int(aux[2:-1])\n",
    "    \n",
    "    e, de = getEff(N_cand, N_an)\n",
    "    print 'Ntuplizer eff: {:1.3e} +/- {:1.3e} ({:1.1e})'.format(e,de, de/e)\n",
    "    dicOut['ntupplizerEff'] = [e, de]\n",
    "\n",
    "    e, de = getEff(N_trg, N_an)\n",
    "    print '\\tTrg eff: {:1.3e} +/- {:1.3e} ({:1.1e})'.format(e,de, de/e)\n",
    "\n",
    "    e, de = getEff(N_cand, N_trg)\n",
    "    print '\\tDecay tree eff: {:1.3e} +/- {:1.3e} ({:1.1e})'.format(e,de, de/e)\n",
    "    \n",
    "#     pickle.dump(dicOut, open(d.dir + 'efficiency.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_cand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-04T23:02:17.419301Z",
     "start_time": "2019-11-04T23:02:09.765091Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "for name, d in outDic.iteritems():\n",
    "    print '\\n--> ' + name\n",
    "    N_gen = {}\n",
    "    N_gen_cuts = {}\n",
    "    N_acc = {}\n",
    "    \n",
    "    job_dir_list = glob(d.dir_jo + 'out_*[0-9]')\n",
    "    pb = ProgressBar(maxEntry=len(job_dir_list))\n",
    "    for i_j, job_dir in enumerate(job_dir_list):\n",
    "        pb.show(i_j)\n",
    "        aux = os.path.basename(job_dir)\n",
    "        n_job = int(aux[4:])\n",
    "        if not os.path.isfile(job_dir + '/step1.log'): \n",
    "            continue\n",
    "        fname_MINI = d.dir_jo + 'out_MINIAODSIM_{}.root'.format(n_job)\n",
    "        if not os.path.isfile(fname_MINI): continue\n",
    "        try:\n",
    "            f = rt.TFile(fname_MINI, 'READ')\n",
    "            t = f.Get('Events')\n",
    "            N_acc[n_job] = int(t.GetEntries())\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "        step1_log_lines = open(job_dir + '/step1.log').readlines()\n",
    "\n",
    "        for line in reversed(step1_log_lines):\n",
    "            if 'Pythia::next():' in line:\n",
    "                break\n",
    "        N_gen[n_job] = int(line[17:-29])\n",
    "\n",
    "        for line in reversed(step1_log_lines):\n",
    "            if 'Begin processing the ' in line:\n",
    "                break\n",
    "        aux = re.search(r', Event [0-9]+,', line).group(0)\n",
    "        N_gen_cuts[n_job] = int(aux[8:-1]) + 49\n",
    "    \n",
    "    d.N_gen = np.array(N_gen.values())\n",
    "    d.dic_N_gen = N_gen\n",
    "    print 'Avg gen:', np.mean(N_gen.values()).astype(np.int)\n",
    "    \n",
    "    d.N_gen_cuts = np.array(N_gen_cuts.values())\n",
    "    d.dic_N_gen_cuts = N_gen_cuts\n",
    "    print 'Avg gen_cuts:', np.mean(N_gen_cuts.values()).astype(np.int)\n",
    "    \n",
    "    d.N_acc = np.array(N_acc.values())\n",
    "    print 'Avg acc:', np.mean(N_acc.values()).astype(np.int)\n",
    "    \n",
    "    cand_out_list = glob(d.dir + 'jo*_B*/out/job*.out')\n",
    "    N_trg = []\n",
    "    N_cand = []\n",
    "    for cand_out in cand_out_list:\n",
    "        step5_log_lines = open(cand_out).readlines()\n",
    "        eff_ln = []\n",
    "        for line in reversed(step5_log_lines):\n",
    "            if 'efficiency:' in line:\n",
    "                eff_ln.append(line)\n",
    "\n",
    "        aux = re.search(': [0-9]+/', eff_ln[1]).group(0)\n",
    "        N_trg.append(int(aux[2:-1]))\n",
    "\n",
    "        aux = re.search(': [0-9]+/', eff_ln[0]).group(0)\n",
    "        N_cand.append(int(aux[2:-1]))\n",
    "    d.N_trg = np.array(N_trg)\n",
    "    print 'Avg N_trg:', np.sum(N_trg) / outDic[name].N_acc.shape[0]\n",
    "    d.N_cand = np.array(N_cand)\n",
    "    print 'Avg N_cand:', np.sum(N_cand) / outDic[name].N_acc.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for name, d in outDic.iteritems():\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(12,4))\n",
    "    fig.suptitle(name)\n",
    "    ax[0].hist(d.N_gen_cuts)\n",
    "    ax[0].set_xlabel('Events after gen cuts')\n",
    "    ax[1].hist(d.N_acc)\n",
    "    ax[1].set_xlabel('Events accepted')\n",
    "\n",
    "    m = mode(d.N_gen_cuts).mode[0]\n",
    "    for i_j, N_gen_cuts in d.dic_N_gen_cuts.iteritems():\n",
    "        if m != N_gen_cuts:\n",
    "            print 'Job',i_j, 'stopped after', N_gen_cuts, 'events'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-04T23:02:37.880908Z",
     "start_time": "2019-11-04T23:02:20.380651Z"
    }
   },
   "outputs": [],
   "source": [
    "for name, d in outDic.iteritems():\n",
    "    print '\\n--> ' + name\n",
    "    d.driver_time = []\n",
    "    d.run_time =[]\n",
    "    d.tot_time =[]\n",
    "    \n",
    "    job_dir_list = glob(d.dir_jo + 'out_*[0-9]')\n",
    "    pb = ProgressBar(maxEntry=len(job_dir_list))\n",
    "    for i_j, job_dir in enumerate(job_dir_list):\n",
    "        pb.show(i_j)\n",
    "        aux = os.path.basename(job_dir)\n",
    "        n_job = int(aux[4:])\n",
    "        \n",
    "        fn = glob(job_dir + '/out.log'.format(n_job-1))\n",
    "        if len(fn) == 0:\n",
    "            continue\n",
    "        else:\n",
    "            fn = fn[0]\n",
    "#         if not os.path.isfile(fn): continue\n",
    "        test_log_lines = open(fn).readlines()\n",
    "        \n",
    "        try:\n",
    "            crono = [[],[],[],[],[]]\n",
    "            for i, ln in enumerate(test_log_lines):\n",
    "                for j in range(1,5):\n",
    "                    if 'Step '+str(j) in ln or 'Running step '+str(j) in ln:\n",
    "                        try:\n",
    "                            crono[j-1].append(float(test_log_lines[i+1][:-1]))\n",
    "                        except:\n",
    "                            print '\\nError in job', n_job\n",
    "                            crono[j-1].append(crono[j-1][-1])\n",
    "            crono[4].append(float(test_log_lines[-1][:-1]))\n",
    "\n",
    "            driver_time = []\n",
    "            run_time = []\n",
    "            for i in range(4):\n",
    "                driver_time.append(crono[i][1] - crono[i][0])\n",
    "                run_time.append(crono[i+1][0] - crono[i][1])\n",
    "            tot_time = crono[4][0] - crono[0][0]\n",
    "\n",
    "            d.driver_time.append(driver_time)\n",
    "            d.run_time.append(run_time)\n",
    "            d.tot_time.append(tot_time)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "    d.driver_time = np.array(d.driver_time)\n",
    "    d.run_time = np.array(d.run_time)\n",
    "    d.tot_time = np.array(d.tot_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-04T23:02:38.054400Z",
     "start_time": "2019-11-04T23:02:37.885162Z"
    }
   },
   "outputs": [],
   "source": [
    "for name, d in outDic.iteritems():\n",
    "    fig, ax = plt.subplots(1, 5, figsize=(16,4))\n",
    "    fig.suptitle(name)\n",
    "    bins = ax[0].hist(d.tot_time/3600, label='cmsRun')\n",
    "    x = np.percentile(d.tot_time, 90)/3600\n",
    "    ax[0].plot([x,x], [0,np.max(bins[0])], 'm--', lw=3)\n",
    "    ax[0].set_xlabel('Total time [h]'.format(i))\n",
    "    for i in range(1,5):\n",
    "        m = min(np.min(d.run_time[:,i-1]), np.min(d.driver_time[:,i-1]))/3600\n",
    "        M = max(np.max(d.run_time[:,i-1]), np.max(d.driver_time[:,i-1]))/3600\n",
    "        bins = np.logspace(np.log10(0.5*m), np.log10(5*M), 50)\n",
    "        ax[i].hist(d.run_time[:,i-1]/3600, bins=bins, label='cmsRun')\n",
    "        ax[i].hist(d.driver_time[:,i-1]/3600, bins=bins, label='cmsDriver')\n",
    "        ax[i].set_xlabel('Step {} time [h]'.format(i))\n",
    "        ax[i].legend(loc='best')\n",
    "        ax[i].set_xscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-04T23:02:38.109083Z",
     "start_time": "2019-11-04T23:02:38.057315Z"
    }
   },
   "outputs": [],
   "source": [
    "for name in outDic.keys():\n",
    "    print '\\n--> ' + name\n",
    "    master_dir = outDic[name].dir + '/'\n",
    "    d = outDic[name]\n",
    "    d.MINIAOD_size = []\n",
    "    \n",
    "    job_dir_list = glob(master_dir + 'jobs_out/out_*[0-9]')\n",
    "    pb = ProgressBar(maxEntry=len(job_dir_list))\n",
    "    for i_j, job_dir in enumerate(job_dir_list):\n",
    "        pb.show(i_j)\n",
    "        aux = os.path.basename(job_dir)\n",
    "        n_job = int(aux[4:])\n",
    "        if not os.path.isfile(job_dir + '/step1.log'): continue\n",
    "        fname_MINI = master_dir + 'jobs_out/out_MINIAODSIM_{}.root'.format(n_job)\n",
    "        if not os.path.isfile(fname_MINI): continue\n",
    "        d.MINIAOD_size.append(os.path.getsize(fname_MINI))\n",
    "    \n",
    "    d.MINIAOD_size = np.array(d.MINIAOD_size)\n",
    "    print 'Avg MINIAOD size:', humanfriendly.format_size(np.mean(d.MINIAOD_size), binary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-04T23:02:38.200211Z",
     "start_time": "2019-11-04T23:02:38.113666Z"
    }
   },
   "outputs": [],
   "source": [
    "for n, d in outDic.iteritems():\n",
    "    table = PrettyTable()\n",
    "    table.field_names = ['Step', 'Sub', 'Eff [%]', 'Driver time [s]', 'Running time/evt [s]']\n",
    "    \n",
    "    e, de = getEff(np.sum(d.N_acc), np.sum(d.N_gen_cuts))\n",
    "    dt = np.mean(d.driver_time[:, 0])\n",
    "    dr_ev = np.mean(d.run_time[:, 0]/d.N_acc)\n",
    "    table.add_row(['GEN-SIM', '-', '{:.2f} +/- {:.2f}'.format(100*e, 100*de), '{:.1f}'.format(dt), '{:.1f}'.format(dr_ev)])\n",
    "    \n",
    "    e, de = getEff(np.sum(d.N_gen_cuts), np.sum(d.N_gen))\n",
    "    table.add_row(['', 'Pythia Gen', 'x {:.1f}'.format(1./e), '-', '-'])\n",
    "    table.add_row(['', 'Gen Filter', '100.0', '-', '-'])\n",
    "    e, de = getEff(np.sum(d.N_acc), np.sum(d.N_gen_cuts))\n",
    "    table.add_row(['', 'CMSSW Filter', '{:.2f} +/- {:.2f}'.format(100*e, 100*de), '-', '-'])\n",
    "\n",
    "    table.add_row(['RAW', '-', '100.0', '{:.1f}'.format(np.mean(d.driver_time[:,1])), '{:.1f}'.format(np.mean(d.run_time[:,1]/d.N_acc))])\n",
    "    table.add_row(['AOD', '-', '100.0', '{:.1f}'.format(np.mean(d.driver_time[:,2])), '{:.1f}'.format(np.mean(d.run_time[:,2]/d.N_acc))])\n",
    "    table.add_row(['MINIAOD', '-', '100.0', '{:.1f}'.format(np.mean(d.driver_time[:,3])), '{:.1f}'.format(np.mean(d.run_time[:,3]/d.N_acc))])\n",
    "    \n",
    "    e, de = getEff(np.sum(d.N_cand), np.sum(d.N_acc))\n",
    "    table.add_row(['CAND', '-', '{:.2f} +/- {:.2f}'.format(100*e, 100*de), '-', '-'])\n",
    "    e, de = getEff(np.sum(d.N_trg), np.sum(d.N_acc))\n",
    "    table.add_row(['', 'BPH Trg', '{:.2f} +/- {:.2f}'.format(100*e, 100*de), '-', '-'])\n",
    "    e, de = getEff(np.sum(d.N_cand), np.sum(d.N_trg))\n",
    "    table.add_row(['', 'Cand. sel.', '{:.2f} +/- {:.2f}'.format(100*e, 100*de), '-', '-'])\n",
    "    \n",
    "    table.add_row(len(table.field_names)*[''])\n",
    "    \n",
    "    e, de = getEff(np.sum(d.N_cand), np.sum(d.N_gen_cuts))\n",
    "    table.add_row(['Tot', '', '{:.3f} +/- {:.3f}'.format(100*e, 100*de), '{:.1f}'.format(np.mean(np.sum(d.driver_time, axis=1))), '{:.1f}(*)'.format(np.mean(np.sum(d.run_time, axis=1)/d.N_acc))])\n",
    "\n",
    "    print n\n",
    "    print table.get_string()\n",
    "    \n",
    "    tabsum = PrettyTable()\n",
    "    tabsum.field_names = ['Evts req.', '# MINIAOD Evts', '# Cand.', 'Tot. Time [h]']\n",
    "    \n",
    "    MINIAOD_size = humanfriendly.format_size(np.mean(d.MINIAOD_size), binary=True)\n",
    "    tabsum.add_row(['{:.0f}k'.format(1e-3*np.mean(d.N_gen_cuts)), '{:.0f} ({})'.format(np.mean(d.N_acc), MINIAOD_size), '{:.0f}'.format(np.sum(d.N_cand) / d.N_acc.shape[0]), '{:.1f}'.format(np.mean(d.tot_time)/3600.)])\n",
    "    print tabsum.get_string()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
