{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utility notebook to skim candidates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, pickle, time, re\n",
    "from glob import glob\n",
    "sys.path.append('../lib')\n",
    "sys.path.append('../analysis')\n",
    "import itertools\n",
    "import json\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-14T01:36:12.149848Z",
     "start_time": "2019-05-14T01:36:11.232339Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to JupyROOT 6.12/07\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from scipy.interpolate import interp1d\n",
    "from array import array\n",
    "\n",
    "import uproot as ur\n",
    "import ROOT as rt\n",
    "rt.gErrorIgnoreLevel = rt.kError\n",
    "rt.RooMsgService.instance().setGlobalKillBelow(rt.RooFit.ERROR)\n",
    "import root_numpy as rtnp\n",
    "\n",
    "from analysis_utilities import drawOnCMSCanvas, getEff\n",
    "from histo_utilities import create_TH1D, create_TH2D, std_color_list, SetMaxToMaxHist\n",
    "from cebefo_style import Set_2D_colz_graphics\n",
    "from gridVarQ2Plot import col_dic, plot_gridVarQ2\n",
    "from progressBar import ProgressBar\n",
    "from categoriesDef import categories\n",
    "from B02DstMu_selection import candidate_selection, trigger_selection, candidateSelection_stringList, candidateSelection_nameList\n",
    "\n",
    "import CMS_lumi, tdrstyle\n",
    "tdrstyle.setTDRStyle()\n",
    "CMS_lumi.writeExtraText = 1\n",
    "\n",
    "\n",
    "CMS_lumi.extraText = \"     Simulation Internal\"\n",
    "\n",
    "donotdelete = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create histograms file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_loc = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "MCloc = '../data/cmsMC_private/BPH_Tag-'\n",
    "loc = {\n",
    "# 'mu_PU0' : MCloc+'B0_MuNuDmst-pD0bar-kp_13TeV-pythia8_Hardbbbar_PTFilter5_0p0-evtgen_ISGW2_PU0_10-2-3/ntuples_B2DstMu/out_CAND_*.root',    \n",
    "'mu_PU20': MCloc+'B0_MuNuDmst-pD0bar-kp_13TeV-pythia8_Hardbbbar_PTFilter5_0p0-evtgen_ISGW2_PU20_10-2-3/ntuples_B2DstMu/out_CAND_*.root',\n",
    "# 'mu_PU35': MCloc+'B0_MuNuDmst-pD0bar-kp_13TeV-pythia8_Hardbbbar_PTFilter5_0p0-evtgen_ISGW2_PU35_10-2-3/ntuples_B2DstMu/out_CAND_*.root',\n",
    "# 'mu_HQETPU0': MCloc+'B0_MuNuDmst-pD0bar-kp_13TeV-pythia8_Hardbbbar_PTFilter5_0p0-evtgen_HQET2_central_PU0_10-2-3/ntuples_B2DstMu/out_CAND_*.root',\n",
    "# 'tau_PU0': MCloc+'B0_TauNuDmst-pD0bar-kp-t2mnn_pythia8_Hardbbbar_PTFilter5_0p0-evtgen_ISGW2_PU0_10-2-3/ntuples_B2DstMu/out_CAND_*.root',\n",
    "# 'tau'   : MCloc+'B0_TauNuDmst-pD0bar-kp-t2mnn_pythia8_Hardbbbar_PTFilter5_0p0-evtgen_ISGW2_PU20_10-2-3/ntuples_B2DstMu/out_CAND_*.root',\n",
    "# 'Hc'    : MCloc+'B0_DmstHc-pD0bar-kp-Hc2mu_13TeV-pythia8_Hardbbbar_PTFilter5_0p0-evtgen_PU20_10-2-3/ntuples_B2DstMu/out_CAND_*.root',\n",
    "# 'Dstst' : MCloc+'Bp_MuNuDstst_DmstPi_13TeV-pythia8_Hardbbbar_PTFilter5_0p0-evtgen_ISGW2_PU20_10-2-3/ntuples_B2DstMu/out_CAND_*.root',\n",
    "}\n",
    "file_loc.update(loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "RDloc = '../data/cmsRD/ParkingBPH*/'\n",
    "loc = {\n",
    "# 'dataB2DstMu': RDloc+'*_RDntuplizer_B2DstMu_200304_CAND.root'\n",
    "'dataB2DstMu': RDloc+'*_RDntuplizer_B2DstMu_200327_CAND.root'\n",
    "# 'dataB2DstMu': RDloc+'Run2018D-05May2019promptD-v1_RDntuplizer_B2DstMu_200320_CAND.root',\n",
    "# 'dataCombDmstMum': RDloc + 'Run2018D-05May2019promptD-v1_RDntuplizer_combDmstMum_200320_CAND.root'\n",
    "}\n",
    "file_loc.update(loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "RDjobs = '/mnt/hadoop/store/user/ocerri/'\n",
    "# file_loc = {\n",
    "# 'dataB2DstMu': RDjobs + 'ParkingBPH*/*_B2DstMu_200320/*/*/*_CAND_*.root',\n",
    "# 'dataCombDmstMum': RDjobs + 'ParkingBPH*/*_combDmstMum_200320/*/*/*_CAND_*.root'\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTLVfromField(ev, n, idx, mass):\n",
    "    v = rt.TLorentzVector()\n",
    "    v.SetPtEtaPhiM(getattr(ev, n+'_pt')[idx], \n",
    "                   getattr(ev, n+'_eta')[idx], \n",
    "                   getattr(ev, n+'_phi')[idx], \n",
    "                   mass)\n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeSelection(inputs):\n",
    "    tag, filepath, leafs_names, cat, idxInt, skipCut, serial = inputs\n",
    "    N_accepted_cand = []\n",
    "    N_accepted_tot = 0\n",
    "    \n",
    "    tree = rt.TChain('outA/Tevts')\n",
    "    lastIdxDisc = -1\n",
    "    for fn in glob(filepath):\n",
    "        tree.Add(fn)\n",
    "        if tree.GetEntries() + lastIdxDisc < idxInt[0]:\n",
    "            lastIdxDisc += tree.GetEntries()\n",
    "            tree = rt.TChain('outA/Tevts')\n",
    "        elif tree.GetEntries() + lastIdxDisc > idxInt[1]:\n",
    "            break\n",
    "    \n",
    "    nDiscEvts = lastIdxDisc + 1\n",
    "            \n",
    "        \n",
    "    if serial:\n",
    "        pb = ProgressBar(maxEntry=idxInt[1]+1)\n",
    "    else:\n",
    "        perc = int((idxInt[1]-idxInt[0])*0.3)\n",
    "    \n",
    "    output = np.zeros((int(1.5*(idxInt[1]-idxInt[0]+1)), len(leafs_names)))\n",
    "    \n",
    "    for i_ev, ev in enumerate(tree):\n",
    "        i_ev += nDiscEvts\n",
    "        if i_ev < idxInt[0]:\n",
    "            continue\n",
    "        if i_ev > idxInt[1]:\n",
    "            break\n",
    "            \n",
    "        if serial:\n",
    "            pb.show(i_ev-idxInt[0])\n",
    "        elif (i_ev-idxInt[0]) % perc == 0:\n",
    "            print tag, ': {:.0f}%'.format(100*(i_ev+1-idxInt[0])/(idxInt[1]-idxInt[0]))\n",
    "        N_acc = 0\n",
    "\n",
    "        ev_output = []\n",
    "        for j in range(ev.pval_piK.size()):\n",
    "            idxTrg = int(ev.mu_trgMu_idx[j])\n",
    "            if not skipCut == 'all':\n",
    "                if not candidate_selection(j, ev, skipCut):\n",
    "                    continue\n",
    "            \n",
    "            if not cat is None:\n",
    "                if not trigger_selection(idxTrg, ev, cat): \n",
    "                    continue\n",
    "\n",
    "            N_acc += 1\n",
    "            \n",
    "            idx_st = 0\n",
    "            for jjj in range(j):\n",
    "                idx_st += int(ev.nTksAdd[jjj])\n",
    "\n",
    "            N_lowMassAddTks = 0\n",
    "            tkMassHad = np.zeros(2)\n",
    "            tkMassMuTk = np.zeros(2)\n",
    "            tkMassVis = np.zeros(2)\n",
    "            tkPt = np.zeros(2)\n",
    "            idx_stop = int(idx_st + ev.nTksAdd[j])\n",
    "#             addTrksTLV = rt.TLorentzVector(0,0,0,0)\n",
    "            for jj in range(idx_st, idx_stop):\n",
    "                if ev.tksAdd_massVis[jj] < 5.28 and ev.tksAdd_cos_PV[jj]>0.95:\n",
    "                    if N_lowMassAddTks < 2:\n",
    "                        tkMassHad[N_lowMassAddTks] = ev.tksAdd_massHad[jj]\n",
    "                        tkPt[N_lowMassAddTks] = ev.tksAdd_pt[jj]\n",
    "                        tkMassMuTk[N_lowMassAddTks] = ev.tksAdd_massMuTk[jj]\n",
    "                        tkMassVis[N_lowMassAddTks] = ev.tksAdd_massVis[jj]\n",
    "#                         addTrksTLV += getTLVfromField(ev, 'tksAdd', jj, 0.13957018)\n",
    "                    N_lowMassAddTks += 1\n",
    "            idxO = np.argsort(-tkPt)\n",
    "            tkMassHad = tkMassHad[idxO]\n",
    "            tkMassMuTk = tkMassMuTk[idxO]\n",
    "            tkMassVis = tkMassVis[idxO]\n",
    "            tkPt = tkPt[idxO]\n",
    "#             selVisTLV = addTrksTLV\n",
    "#             selVisTLV += getTLVfromField(ev, 'D0_refitD0pismu', j, 1.86484)\n",
    "#             selVisTLV += getTLVfromField(ev, 'pis_refitD0pismu', j, 0.13957018)\n",
    "#             selVisTLV += getTLVfromField(ev, 'mu_refitD0pismu', j, 0.105658375)\n",
    "\n",
    "            aux = (ev.q2_D0pismu[j], ev.Est_mu_D0pismu[j], ev.M2_miss_D0pismu[j],\n",
    "                   ev.trgMu_pt[idxTrg], ev.trgMu_eta[idxTrg], ev.trgMu_phi[idxTrg], ev.trgMu_sigdxy[idxTrg],\n",
    "                   ev.B_D0pismu_pt[j], ev.B_D0pismu_eta[j], ev.B_D0pismu_phi[j],\n",
    "                   ev.Dst_refitD0pismu_pt[j], ev.Dst_refitD0pismu_eta[j], ev.Dst_refitD0pismu_phi[j],\n",
    "                   ev.D0_refitD0pismu_pt[j], ev.D0_refitD0pismu_eta[j], ev.D0_refitD0pismu_phi[j],\n",
    "                   ev.pi_refitpiK_pt[j], ev.pi_refitpiK_eta[j], ev.pi_refitpiK_phi[j], ev.sigdxy_pi_PV[j],\n",
    "                   ev.K_refitpiK_pt[j], ev.K_refitpiK_eta[j], ev.K_refitpiK_phi[j], ev.sigdxy_K_PV[j],\n",
    "                   ev.pval_piK[j], ev.sigdxy_vtxD0_PV[j],\n",
    "                   ev.pis_refitD0pismu_pt[j], ev.pis_refitD0pismu_eta[j], ev.pis_refitD0pismu_phi[j], ev.sigdxy_pis_PV[j],\n",
    "                   ev.pval_D0pis[j],\n",
    "                   ev.mass_piK[j], ev.mass_D0pis[j], ev.mass_D0pismu[j],\n",
    "                   ev.pval_D0pismu[j], ev.cos_D0pismu_PV[j], ev.cosT_D0pismu_PV[j],\n",
    "                   N_lowMassAddTks,\n",
    "                   tkMassHad[0], tkMassHad[1],\n",
    "                   tkMassMuTk[0], tkMassMuTk[1],\n",
    "                   tkMassVis[0], tkMassVis[1],\n",
    "                   tkPt[0], tkPt[1],\n",
    "#                    selVisTLV.M(),\n",
    "                   trigger_selection(idxTrg, ev, categories['low']),\n",
    "                   trigger_selection(idxTrg, ev, categories['mid']),\n",
    "                   trigger_selection(idxTrg, ev, categories['high']),\n",
    "                   ev.N_vertexes\n",
    "                  )\n",
    "            if not 'data' in n:\n",
    "                aux += (ev.MC_q2, ev.MC_Est_mu, ev.MC_M2_miss,\n",
    "                        ev.MC_B_pt, ev.MC_B_eta, ev.MC_B_phi,\n",
    "                        ev.MC_Dst_pt, ev.MC_Dst_eta, ev.MC_Dst_phi,\n",
    "                        ev.MC_mu_pt, ev.MC_mu_eta, ev.MC_mu_phi, ev.MC_mu_IP,\n",
    "                        ev.MC_pi_pt, ev.MC_pi_eta, ev.MC_pi_phi,\n",
    "                        ev.MC_K_pt, ev.MC_K_eta, ev.MC_K_phi,\n",
    "                        ev.MC_pis_pt, ev.MC_pis_eta, ev.MC_pis_phi,\n",
    "                        ev.MC_idxCand == j\n",
    "                       )\n",
    "            if 'mu' in n or 'tau' in n:\n",
    "                aux += (ev.wh_CLNCentral,\n",
    "                        ev.wh_CLNR0Down, ev.wh_CLNR0Up,\n",
    "                        ev.wh_CLNR1Down, ev.wh_CLNR1Up,\n",
    "                        ev.wh_CLNR2Down, ev.wh_CLNR2Up,\n",
    "                        ev.wh_CLNRhoSqDown, ev.wh_CLNRhoSqUp,\n",
    "                       )\n",
    "            ev_output.append(aux)\n",
    "            \n",
    "        N_acc = len(ev_output)\n",
    "        idx = 0\n",
    "        if N_acc > 1:\n",
    "            if 'data' in n:\n",
    "                idx = np.random.randint(len(ev_output))\n",
    "            else:\n",
    "                #Get matched can preferably\n",
    "                varIdx = leafs_names.index('MC_idxMatch')\n",
    "                goodIdx = np.nonzero([o[varIdx] for o in ev_output])[0]\n",
    "                if goodIdx.shape[0] > 0:\n",
    "                    auxIdx = np.random.randint(goodIdx.shape[0])\n",
    "                    idx = goodIdx[auxIdx]\n",
    "                else:\n",
    "                    idx = np.random.randint(len(ev_output))\n",
    "        if N_acc > 0:\n",
    "            output[N_accepted_tot] = ev_output[idx]\n",
    "            N_accepted_tot += 1\n",
    "            N_accepted_cand.append(N_acc)\n",
    "\n",
    "    output = output[:N_accepted_tot]\n",
    "    if not serial:\n",
    "        print tag, ': done'\n",
    "    return [output, N_accepted_cand]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dSet(n, filepath, cat, skipCut=[], maxEntries=1e15):  \n",
    "    if cat is None:\n",
    "        catName = 'None'\n",
    "    else:\n",
    "        catName = cat.name\n",
    "    print n, catName\n",
    "    if 'data' in n:\n",
    "        loc = '../data/cmsRD/skimmed/'+ n.replace('data', '')\n",
    "        out = re.search('20[01][1-9][0-3][0-9]', filepath)\n",
    "        if out is None:\n",
    "            print filepath\n",
    "            raise\n",
    "        fskimmed_name = loc + '_' + out.group(0) + '_' + catName \n",
    "        N_evts_per_job = 400000\n",
    "    else:\n",
    "        d = os.path.dirname(filepath) + '/skimmed/'\n",
    "        if not os.path.isdir(d):\n",
    "            os.makedirs(d)\n",
    "        fskimmed_name = d + catName \n",
    "        N_evts_per_job = 40000\n",
    "    if not skipCut == []:\n",
    "        print 'Skipping cut(s)', skipCut\n",
    "        if skipCut == 'all':\n",
    "            fskimmed_name += '_skipall'\n",
    "        else:\n",
    "            fskimmed_name += '_skip'+'-'.join([str(i) for i in skipCut])\n",
    "    fskimmed_name += '.root'\n",
    "    logfile = fskimmed_name.replace('.root', '.log')\n",
    "    if os.path.isfile(fskimmed_name) and not n in recreate:\n",
    "        print 'Already present'\n",
    "    else:\n",
    "        tree = rt.TChain('outA/Tevts')\n",
    "        for fn in glob(filepath):\n",
    "            tree.Add(fn)\n",
    "        print 'Computing events from {} files'.format(tree.GetNtrees())\n",
    "        N_cand_in = min(maxEntries, tree.GetEntries())\n",
    "        print n, ': Total number of candidate events =', N_cand_in\n",
    "            \n",
    "        leafs_names = ['q2', 'Est_mu', 'M2_miss',\n",
    "                       'mu_pt', 'mu_eta', 'mu_phi', 'mu_sigdxy',\n",
    "                       'B_pt', 'B_eta', 'B_phi',\n",
    "                       'Dst_pt', 'Dst_eta', 'Dst_phi',\n",
    "                       'D0_pt', 'D0_eta', 'D0_phi',\n",
    "                       'pi_pt', 'pi_eta', 'pi_phi', 'pi_IP',\n",
    "                       'K_pt', 'K_eta', 'K_phi', 'K_IP',\n",
    "                       'pval_piK', 'sigdxy_vtxD0_PV',\n",
    "                       'pis_pt', 'pis_eta', 'pis_phi', 'pis_IP',\n",
    "                       'pval_D0pis',\n",
    "                       'mass_piK', 'mass_D0pis', 'mass_D0pismu',\n",
    "                       'pval_D0pismu', 'cos_D0pismu_PV', 'cosT_D0pismu_PV',\n",
    "                       'N_lowMassAddTks',\n",
    "                       'tkMassHad_0', 'tkMassHad_1',\n",
    "                       'tkMassMuTk_0', 'tkMassMuTk_1',\n",
    "                       'tkMassVis_0', 'tkMassVis_1',\n",
    "                       'tkPt_0', 'tkPt_1',\n",
    "#                        'selTotVisMass',\n",
    "                       'cat_low', 'cat_mid', 'cat_high',\n",
    "                       'N_vtx'\n",
    "                      ]\n",
    "        if not 'data' in n:\n",
    "            leafs_names += ['MC_q2', 'MC_Est_mu', 'MC_M2_miss',\n",
    "                            'MC_B_pt', 'MC_B_eta', 'MC_B_phi',\n",
    "                            'MC_Dst_pt', 'MC_Dst_eta', 'MC_Dst_phi',\n",
    "                            'MC_mu_pt', 'MC_mu_eta', 'MC_mu_phi', 'MC_mu_IP',\n",
    "                            'MC_pi_pt', 'MC_pi_eta', 'MC_pi_phi',\n",
    "                            'MC_K_pt', 'MC_K_eta', 'MC_K_phi',\n",
    "                            'MC_pis_pt', 'MC_pis_eta', 'MC_pis_phi',\n",
    "                            'MC_idxMatch'\n",
    "                           ]\n",
    "        if 'mu' in n or 'tau' in n:\n",
    "            leafs_names += ['wh_CLNCentral', \n",
    "                            'wh_CLNR0Down', 'wh_CLNR0Up', \n",
    "                            'wh_CLNR1Down', 'wh_CLNR1Up', \n",
    "                            'wh_CLNR2Down', 'wh_CLNR2Up', \n",
    "                            'wh_CLNRhoSqDown', 'wh_CLNRhoSqUp']\n",
    "        \n",
    "        if N_cand_in < 1.5*N_evts_per_job:\n",
    "            output, N_accepted_cand = makeSelection(['', filepath, leafs_names, cat, \n",
    "                                                     [0, N_cand_in-1], skipCut, True])\n",
    "        else:\n",
    "            pdiv = list(np.arange(0, N_cand_in, N_evts_per_job))\n",
    "            if not pdiv[-1] == N_cand_in: \n",
    "                pdiv.append(N_cand_in)\n",
    "            print 'Will be divided into ' + str(len(pdiv)-1) + ' jobs'\n",
    "            inputs = []\n",
    "            for i in range(1, len(pdiv)):\n",
    "                corr = 0\n",
    "                if i == 1:\n",
    "                    corr = -1\n",
    "                inputs.append([str(i), filepath, leafs_names, cat, [pdiv[i-1]+1+corr, pdiv[i]], skipCut, False])\n",
    "            print ' '\n",
    "            \n",
    "            start = time.time()\n",
    "            p = Pool(min(20,len(inputs)))\n",
    "            outputs = p.map(makeSelection, inputs)\n",
    "            output = np.concatenate(tuple([o[0] for o in outputs]))\n",
    "            N_accepted_cand = []\n",
    "            for o in outputs: N_accepted_cand += o[1]\n",
    "            print 'Total time: {:.1f} min'.format((time.time()-start)/60.)\n",
    "                \n",
    "        \n",
    "        dset = pd.DataFrame(output, columns=leafs_names)\n",
    "        if not os.path.isdir(os.path.dirname(fskimmed_name)):\n",
    "            os.makedirs(os.path.dirname(fskimmed_name))\n",
    "        rtnp.array2root(dset.to_records(), fskimmed_name, treename='Tevts', mode='RECREATE')\n",
    "        \n",
    "        with open(logfile, 'w') as f:\n",
    "            ln = 'Number of candidates per events\\n{'\n",
    "            ln += ', '.join(['{}:{}'.format(i, N_accepted_cand.count(i)) for i in range(1, np.max(N_accepted_cand)+1)])\n",
    "            ln += '}\\n'\n",
    "            f.write(ln)\n",
    "            f.write('N_analyzed: '+str(N_cand_in)+'\\n')\n",
    "            f.write('N_accepted: '+str(dset.shape[0])+'\\n')\n",
    "            e = getEff(dset.shape[0], N_cand_in)\n",
    "            f.write('Eff: {:.3f} +/- {:.3f} %'.format(1e2*e[0], 1e2*e[1])+'\\n')\n",
    "         \n",
    "    os.system('echo '+logfile+';cat '+logfile + ';echo ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataB2DstMu Low\n",
      "Already present\n",
      "mu_PU20 Low\n",
      "Already present\n",
      "dataB2DstMu Mid\n",
      "Already present\n",
      "mu_PU20 Mid\n",
      "Already present\n",
      "dataB2DstMu High\n",
      "Computing events from 5 files\n",
      "dataB2DstMu : Total number of candidate events = 62893165\n",
      "Will be divided into 158 jobs\n",
      " \n",
      "1 : 0%\n",
      "33 : 0%\n",
      "3 : 0%\n",
      "35 : 0%\n",
      "1 : 30%\n",
      "33 : 30%\n",
      "5 : 0%\n",
      "3 : 30%\n",
      "37 : 0%\n",
      "1 : 60%\n",
      "35 : 30%\n",
      "33 : 59%\n",
      "7 : 0%\n",
      "5 : 30%\n",
      "39 : 0%\n",
      "3 : 59%\n",
      "37 : 30%\n",
      "1 : 90%\n",
      "35 : 59%\n",
      "33 : 89%\n",
      "1 : done\n",
      "9 : 0%\n",
      "33 : done\n",
      "7 : 30%\n",
      "39 : 30%\n",
      "3 : 89%\n",
      "2 : 0%\n",
      "5 : 59%\n",
      "37 : 59%\n",
      "3 : done\n",
      "35 : 89%\n",
      "34 : 0%\n",
      "11 : 0%\n",
      "35 : done\n",
      "9 : 30%\n",
      "7 : 59%\n",
      "39 : 59%\n",
      "2 : 30%\n",
      "5 : 89%\n",
      "37 : 89%\n",
      "5 : done\n",
      "37 : done\n",
      "13 : 0%\n",
      "34 : 30%\n",
      "11 : 30%\n",
      "4 : 0%\n",
      "9 : 59%\n",
      "7 : 89%\n",
      "39 : 89%\n",
      "2 : 59%\n",
      "7 : done\n",
      "36 : 0%\n",
      "39 : done\n",
      "15 : 0%\n",
      "13 : 30%\n",
      "34 : 59%\n",
      "11 : 59%\n",
      "4 : 30%\n",
      "9 : 89%\n",
      "9 : done\n",
      "17 : 0%\n",
      "2 : 89%\n",
      "36 : 30%\n",
      "15 : 30%\n",
      "2 : done\n",
      "6 : 0%\n",
      "13 : 59%\n",
      "34 : 89%\n",
      "11 : 89%\n",
      "4 : 59%\n",
      "19 : 0%\n",
      "34 : done\n",
      "38 : 0%\n",
      "11 : done\n",
      "17 : 30%\n",
      "36 : 59%\n",
      "15 : 59%\n",
      "6 : 30%\n",
      "13 : 89%\n",
      "4 : 89%\n",
      "19 : 30%\n",
      "21 : 0%\n",
      "13 : done\n",
      "38 : 30%\n",
      "4 : done\n",
      "8 : 0%\n",
      "17 : 59%\n",
      "36 : 89%\n",
      "15 : 89%\n",
      "6 : 59%\n",
      "23 : 0%\n",
      "36 : done\n",
      "40 : 0%\n",
      "19 : 59%\n",
      "21 : 30%\n",
      "15 : done\n",
      "38 : 59%\n",
      "8 : 30%\n",
      "17 : 89%\n",
      "25 : 0%\n",
      "6 : 89%\n",
      "23 : 30%\n",
      "17 : done\n",
      "40 : 30%\n",
      "19 : 89%\n",
      "6 : done\n",
      "21 : 59%\n",
      "38 : 89%\n",
      "10 : 0%\n",
      "19 : done\n",
      "27 : 0%\n",
      "8 : 59%\n",
      "38 : done\n",
      "25 : 30%\n",
      "41 : 0%\n",
      "23 : 59%\n",
      "40 : 59%\n",
      "21 : 89%\n",
      "29 : 0%\n",
      "27 : 30%\n",
      "10 : 30%\n",
      "8 : 89%\n",
      "21 : done\n",
      "25 : 59%\n",
      "41 : 30%\n",
      "8 : done\n",
      "31 : 0%\n",
      "23 : 89%\n",
      "40 : 89%\n",
      "29 : 30%\n",
      "43 : 0%\n",
      "12 : 0%\n",
      "40 : done\n",
      "23 : done\n",
      "27 : 59%\n",
      "10 : 59%\n",
      "25 : 89%\n",
      "41 : 59%\n",
      "25 : done\n",
      "31 : 30%\n",
      "29 : 59%\n",
      "12 : 30%\n",
      "43 : 30%\n",
      "27 : 89%\n",
      "10 : 89%\n",
      "27 : done\n",
      "41 : 89%\n",
      "10 : done\n",
      "14 : 0%\n",
      "31 : 59%\n",
      "45 : 0%\n",
      "41 : done\n",
      "29 : 89%\n",
      "12 : 59%\n",
      "43 : 59%\n",
      "29 : done\n",
      "14 : 30%\n",
      "45 : 30%\n",
      "31 : 89%\n",
      "43 : 89%\n",
      "31 : done\n",
      "12 : 89%\n",
      "43 : done\n",
      "12 : done\n",
      "47 : 0%\n",
      "14 : 59%\n",
      "45 : 59%\n",
      "16 : 0%\n",
      "47 : 30%\n",
      "14 : 89%\n",
      "45 : 89%\n",
      "16 : 30%\n",
      "18 : 0%\n",
      "14 : done\n",
      "45 : done\n",
      "47 : 59%\n",
      "49 : 0%\n",
      "16 : 59%\n",
      "18 : 30%\n",
      "42 : 0%\n",
      "20 : 0%\n",
      "47 : 89%\n",
      "49 : 30%\n",
      "51 : 0%\n",
      "16 : 89%\n",
      "47 : done\n",
      "18 : 59%\n",
      "16 : done\n",
      "42 : 30%\n",
      "20 : 30%\n",
      "49 : 59%\n",
      "51 : 30%\n",
      "18 : 89%\n",
      "42 : 59%\n",
      "18 : done\n",
      "22 : 0%\n",
      "20 : 59%\n"
     ]
    }
   ],
   "source": [
    "from categoriesDef import categories\n",
    "\n",
    "# recreate = file_loc.keys()\n",
    "recreate = []\n",
    "\n",
    "# for n, fp in file_loc.iteritems():\n",
    "#     create_dSet(n, fp, None, 'all')\n",
    "\n",
    "for cn in ['low', 'mid', 'high']:\n",
    "    for n, fp in file_loc.iteritems():\n",
    "        create_dSet(n, fp, categories[cn])\n",
    "\n",
    "# for n, fp in file_loc.iteritems():\n",
    "#         create_dSet(n, fp, None)\n",
    "\n",
    "# for n, fp in file_loc.iteritems():\n",
    "#         create_dSet(n, fp, categories['low'])\n",
    "\n",
    "# skip = []\n",
    "# skip.append([21]) #Additional tracks\n",
    "# # skip.append([8, 14, 15]) #Mass D0, D* and D*-D0 (m piK)\n",
    "# # skip.append([20]) #Visible mass (m D0pismu)\n",
    "# for idx in skip:\n",
    "#     for n, fp in file_loc.iteritems():\n",
    "#         create_dSet(n, fp, categories['low'], idx, maxEntries=1e15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze selection efficiencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTree(n, filepath, cat, skipCut=None, maxEntries=1e15):  \n",
    "    if skipCut=='all' and cat is None:\n",
    "        catName = 'All'\n",
    "    else:\n",
    "        catName = cat.name\n",
    "    print n, catName, skipCut\n",
    "    if 'data' in n:\n",
    "        loc = '../data/cmsRD/skimmed/'+ n.replace('data', '')\n",
    "        out = re.search('20[01][1-9][0-3][0-9]', filepath)\n",
    "        fskimmed_name = loc + '_' + out.group(0) + '_' + catName \n",
    "        if not skipCut is None:\n",
    "            fskimmed_name += '_skip'+str(skipCut)\n",
    "        fskimmed_name += '.root'\n",
    "    else:\n",
    "        d = os.path.dirname(filepath) + '/skimmed/'\n",
    "        fskimmed_name = d + catName \n",
    "        if not skipCut is None:\n",
    "            fskimmed_name += '_skip'+str(skipCut)\n",
    "        fskimmed_name += '.root'\n",
    "    if os.path.isfile(fskimmed_name):\n",
    "        t = rt.TChain('Tevts')\n",
    "        t.Add(fskimmed_name)\n",
    "        return t\n",
    "    else: return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get efficiency per cut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = {}\n",
    "for n, fp in file_loc.iteritems():\n",
    "    aux = getTree(n, fp, None, 'all', maxEntries=1e9)\n",
    "    if not aux is None:\n",
    "        T[n] = aux\n",
    "    else:\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allCuts = ' && '.join(candidateSelection_stringList)\n",
    "eff = {}\n",
    "for n, t in T.iteritems():\n",
    "    print n\n",
    "    eff[n] = np.zeros((len(candidateSelection_stringList)+1,2))\n",
    "    Ntot = float(t.GetEntries())\n",
    "    Nsel = t.GetEntries(allCuts)\n",
    "    eff[n][0] = getEff(Nsel, Ntot)\n",
    "    pb = ProgressBar(maxEntry=len(candidateSelection_stringList))\n",
    "    for ic, c in enumerate(candidateSelection_stringList):\n",
    "        pb.show(ic)\n",
    "        eff[n][ic+1] = getEff(t.GetEntries(c), Ntot)\n",
    "\n",
    "for n in T.keys():\n",
    "    y = np.array(eff[n])\n",
    "    x = np.arange(y.shape[0])\n",
    "    plt.errorbar(x, y[:, 0], y[:,1], lw=0, elinewidth=5, label=n)\n",
    "\n",
    "plt.rcParams.update({'font.size': 20})\n",
    "plt.xlabel('Cut')\n",
    "plt.ylabel('Efficiency')\n",
    "plt.legend(loc='best', numpoints=1)\n",
    "plt.xticks(range(len(candidateSelection_nameList)+1), ['all']+candidateSelection_nameList, rotation=80)\n",
    "plt.ylim(0,1.05)\n",
    "plt.xlim(-1, len(candidateSelection_nameList)+1)\n",
    "plt.grid()\n",
    "plt.gcf().set_size_inches(10, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allCuts = ' && '.join(candidateSelection_stringList)\n",
    "cat = ['cat_low', 'cat_mid', 'cat_high']\n",
    "eff = {}\n",
    "for n, t in T.iteritems():\n",
    "    print n\n",
    "    eff[n] = np.zeros((2*len(cat), 2))\n",
    "    Ntot = float(t.GetEntries())\n",
    "    Nsel = t.GetEntries(allCuts)\n",
    "    eff[n][0] = getEff(Nsel, Ntot)\n",
    "    for ic, c in enumerate(cat):\n",
    "        eff[n][ic] = getEff(t.GetEntries(c), Ntot)\n",
    "    for ic, c in enumerate(cat):\n",
    "        eff[n][ic+len(cat)] = getEff(t.GetEntries(c + ' && ' + allCuts), Ntot)\n",
    "        print n, '{:.2f} +/- {:.2f} %'.format(*(100*eff[n][ic+len(cat)]))\n",
    "\n",
    "for n in T.keys():\n",
    "    y = np.array(eff[n])\n",
    "    x = np.arange(y.shape[0])\n",
    "    plt.errorbar(x, y[:, 0], y[:,1], lw=0, elinewidth=3, label=n)\n",
    "\n",
    "plt.rcParams.update({'font.size': 20})\n",
    "plt.xlabel('Cut')\n",
    "plt.ylabel('Efficiency')\n",
    "plt.legend(loc='best', numpoints=1)\n",
    "plt.xticks(range(2*len(cat)+1), cat+['all & '+c.replace('cat_', '') for c in cat], rotation=45)\n",
    "plt.ylim(0.7*np.min([np.min(e[:,0]) for e in eff.values()]), plt.ylim()[1])\n",
    "plt.xlim(-1,plt.xlim()[1]+1)\n",
    "# plt.yscale('log')\n",
    "plt.grid()\n",
    "plt.gcf().set_size_inches(10, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
