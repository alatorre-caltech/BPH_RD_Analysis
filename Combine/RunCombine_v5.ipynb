{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Full rate estimation ad additional systematics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "card_name = 'v5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_real_data = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "category = 'high'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, pickle\n",
    "from glob import glob\n",
    "sys.path.append('../lib')\n",
    "sys.path.append('../analysis')\n",
    "from categoriesDef import categories\n",
    "import itertools\n",
    "import json, yaml\n",
    "from IPython.display import IFrame, Image, display\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-14T01:36:12.149848Z",
     "start_time": "2019-05-14T01:36:11.232339Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to JupyROOT 6.12/07\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from array import array\n",
    "\n",
    "import uproot as ur\n",
    "import ROOT as rt\n",
    "rt.gErrorIgnoreLevel = rt.kError\n",
    "rt.RooMsgService.instance().setGlobalKillBelow(rt.RooFit.ERROR)\n",
    "import root_numpy as rtnp\n",
    "\n",
    "from analysis_utilities import drawOnCMSCanvas, DSetLoader\n",
    "from pT_calibration_reader import pTCalReader\n",
    "from histo_utilities import create_TH1D, create_TH2D, std_color_list\n",
    "from cebefo_style import Set_2D_colz_graphics\n",
    "from gridVarQ2Plot import plot_gridVarQ2\n",
    "from progressBar import ProgressBar\n",
    "from lumi_utilities import getLumiByTrigger\n",
    "\n",
    "import CMS_lumi, tdrstyle\n",
    "tdrstyle.setTDRStyle()\n",
    "CMS_lumi.writeExtraText = 1\n",
    "\n",
    "if fit_real_data:\n",
    "    CMS_lumi.extraText = \"Preliminary\"\n",
    "else:\n",
    "    CMS_lumi.extraText = \"Simulation Preliminary\"\n",
    "\n",
    "donotdelete = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = categories[category]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define binning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "binning = {\n",
    "    'q2'      : array('d', [-2, 1.5, 4, 6, 12]),\n",
    "    'M2_miss' : [\n",
    "        array('d', [-2.5] + list(np.arange(-1.8, 0.8, 0.4)) + [6] ),\n",
    "        array('d', [-2.5] + list(np.arange(-1.8, 1.6, 0.4)) + [6] ),\n",
    "        array('d', [-2.5] + list(np.arange(-1.8, 3.0, 0.4)) + [6] ),\n",
    "        array('d', [-2.5] + list(np.arange(-1.8, 5.2, 0.4)) + [6] ),\n",
    "    ],\n",
    "    'Est_mu'  : [\n",
    "        array('d', [0.5] + list(np.arange(0.8, 2.3, 0.1)) + [2.5] ),\n",
    "        array('d', [0.5] + list(np.arange(0.8, 2.5, 0.1)) + [2.5] ),\n",
    "        [20, 0.50, 2.500],\n",
    "        [20, 0.50, 2.500],\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "283859\n",
      "22431\n",
      "6876\n",
      "6884\n"
     ]
    }
   ],
   "source": [
    "MCsample = {\n",
    "'mu' : DSetLoader('B0_MuNuDmst_PU20'),\n",
    "'tau' : DSetLoader('B0_TauNuDmst_PU20'),\n",
    "'Hc' : DSetLoader('B0_DmstHc_PU20'),\n",
    "'Dstst' : DSetLoader('Bp_MuNuDstst_PU20')\n",
    "}\n",
    "dSet = {}\n",
    "for n, s in MCsample.iteritems():\n",
    "    dSet[n] = rtnp.root2array(s.skimmed_dir + '/{}.root'.format(cat.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if fit_real_data:\n",
    "    creation_date = '200304'\n",
    "    locRD = '../data/cmsRD/skimmed/B2DstMu_{}_{}.root'.format(creation_date, cat.name)\n",
    "    dSet['data'] = rtnp.root2array(locRD)\n",
    "    dataDir = '../data/cmsRD'\n",
    "    datasets_loc = glob(dataDir + '/ParkingBPH*/*RDntuplizer_B2DstMu_{}_CAND.root'.format(creation_date))\n",
    "    lumi_tot = getLumiByTrigger(datasets_loc, cat.trg, verbose=True)\n",
    "    CMS_lumi.integrated_lumi = lumi_tot\n",
    "else:\n",
    "    lumi_tot = 25 #fb^-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load all the calibrations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected ratio between RD and MC norm: 2.632 +/- 0.063\n"
     ]
    }
   ],
   "source": [
    "r = np.zeros((3,2))\n",
    "for i, fn in enumerate(glob('../data/calibration/totalRate/ratioB02JPsiKst_*.txt')):\n",
    "    with open(fn, 'r') as faux:\n",
    "        aux = faux.readlines()[0][:-1].split(' ')\n",
    "        r[i] = [float(aux[0]), float(aux[1])]\n",
    "s2 = np.square(r[:,1])\n",
    "num = np.sum(r[:,0]/s2)\n",
    "den = np.sum(1./s2)\n",
    "RDoMC_normRatio = [num/den, np.sqrt(1/den)]\n",
    "print 'Expected ratio between RD and MC norm: {:.3f} +/- {:.3f}'.format(RDoMC_normRatio[0], RDoMC_normRatio[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "decayBR = pickle.load(open('../data/forcedDecayChannelsFactors.pickle', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc = '../data/calibration/triggerScaleFactors/'\n",
    "fTriggerSF = rt.TFile.Open(loc + 'HLT_' + cat.trg + '_SF.root', 'READ')\n",
    "hTriggerSF = fTriggerSF.Get('hSF_HLT_' + cat.trg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeTrgSF():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "fMuonIDSF = rt.TFile.Open('../data/calibration/muonIDscaleFactors/Run2018ABCD_SF_MuonID_Jpsi.root', 'READ')\n",
    "hMuonIDSF = fMuonIDSF.Get('NUM_SoftID_DEN_genTracks_pt_abseta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cal_pT = pTCalReader(calibration_file='../data/calibration/B0pTspectrum/pwWeights_{}.txt'.format(cat.name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create MC histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "-----------> mu <-------------\n",
      "N tot selected: 283.9k\n",
      "N tot expected: 404.3k\n",
      "\n",
      "\n",
      "-----------> tau <-------------\n",
      "N tot selected: 22.4k\n",
      "N tot expected: 11.8k\n",
      "\n",
      "\n",
      "-----------> Hc <-------------\n",
      "N tot selected: 6.9k\n",
      "N tot expected: 2.0k\n",
      "\n",
      "\n",
      "-----------> Dstst <-------------\n",
      "N tot selected: 6.9k\n",
      "N tot expected: 6.8k\n"
     ]
    }
   ],
   "source": [
    "histo = {}\n",
    "for n, ds in dSet.iteritems():\n",
    "    print '\\n'\n",
    "    print '----------->', n, '<-------------'\n",
    "    sMC = MCsample[n]\n",
    "    \n",
    "    nTotSelected = ds['q2'].shape[0]\n",
    "    print 'N tot selected: {:.1f}k'.format(1e-3*nTotSelected)\n",
    "    nGenExp = sMC.effMCgen['xsec'][0] * lumi_tot * RDoMC_normRatio[0] #uncertainty will be set in fit\n",
    "    eff = [1, 0]\n",
    "    for f, df in [sMC.effMCgen['effGEN'], decayBR[n], sMC.effCand['effCAND'], sMC.getSkimEff(cat.name)]:\n",
    "        eff[0] *= f\n",
    "        eff[1] += np.square(df/f)\n",
    "    eff[1] = eff[0] * np.sqrt(eff[1])\n",
    "    print 'N tot expected: {:.1f}k'.format(1e-3*nGenExp*eff[0])\n",
    "    \n",
    "    wVar = {}\n",
    "    \n",
    "    trgSF = np.ones(nTotSelected)\n",
    "    trgSFUnc = np.ones(nTotSelected)\n",
    "    x = np.column_stack((ds['trgMu_pt'], ds['trgMu_eta'], ds['trgMu_sigdxy'])\n",
    "    for i, (pt, eta, ip) in enumerate(x):\n",
    "        ix = hTriggerSF.GetXaxis().FindBin(pt)\n",
    "        iy = hTriggerSF.GetYaxis().FindBin(ip)\n",
    "        iz = hTriggerSF.GetZaxis().FindBin(np.abs(eta))\n",
    "        trgSF[i] = hTriggerSF.GetBinContent(ix, iy, iz)\n",
    "        trgSFUnc[i] = hTriggerSF.GetBin(ix, iy, iz)\n",
    "        trgSFUnc[i] = hTriggerSF.GetBinError(trgSF[i] + hTriggerSF.GetBinError(ib))\n",
    "    # Divide them for the weight so later you can simply multiply back to get the value\n",
    "    wVar['trgSFUp'] = 1 + trgSFUnc[i]/trgSF\n",
    "    wVar['trgSFDown'] = 1 - trgSFUnc[i]/trgSF\n",
    "    \n",
    "    \n",
    "    auxArrMC = rtnp.tree2array(tMC_skimmed, branches=['MC_mup_pt', 'MC_mup_eta', 'MC_mum_pt', 'MC_mum_eta'])\n",
    "muonSF = np.ones(auxArrMC.shape[0])\n",
    "for i, (ptp, etap, ptm, etam) in enumerate(auxArrMC):\n",
    "ix = hMuonIDSF.GetXaxis().FindBin(ptp)\n",
    "iy = hMuonIDSF.GetYaxis().FindBin(np.abs(etap))\n",
    "wp = hMuonIDSF.GetBinContent(ix, iy)\n",
    "ix = hMuonIDSF.GetXaxis().FindBin(ptm)\n",
    "iy = hMuonIDSF.GetYaxis().FindBin(np.abs(etam))\n",
    "wm = hMuonIDSF.GetBinContent(ix, iy)\n",
    "muonSF[i] = wp * wm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-2896003cd9c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'trgMu_pt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'trgMu_eta'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'trgMu_sigdxy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices"
     ]
    }
   ],
   "source": [
    "ds['trgMu_pt', 'trgMu_eta', 'trgMu_sigdxy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "histo = {}\n",
    "for i_q2 in range(len(binning['q2'])-1):\n",
    "    q2_l = binning['q2'][i_q2]\n",
    "    q2_h = binning['q2'][i_q2 + 1]\n",
    "\n",
    "    for var in ['M2_miss', 'Est_mu']:\n",
    "        cat_name = var+'_q2bin'+str(i_q2)\n",
    "        histo[cat_name] = {}\n",
    "        for k, d in dSet.iteritems():          \n",
    "            q2_bin = np.logical_and(d['q2'] > q2_l, d['q2'] < q2_h)\n",
    "            \n",
    "            if k in ['mu', 'tau']:\n",
    "                for k_wpT in ['C', 'Up', 'Down']:\n",
    "                    pFF_list = ['Central']\n",
    "                    if k_wpT == 'C':\n",
    "                        pFF_list += ['R0', 'R1', 'R2', 'RhoSq']\n",
    "                    for n_pFF in pFF_list:\n",
    "                        var_pFF_list = [''] if n_pFF == 'Central' else ['Up', 'Down']\n",
    "                        for var_pFF in var_pFF_list:\n",
    "                            h_name = k\n",
    "                            if k_wpT != 'C':\n",
    "                                h_name += '__B0pT' + k_wpT\n",
    "                            elif n_pFF != 'Central':\n",
    "                                h_name += '__B2DstCLN' + n_pFF + var_pFF\n",
    "\n",
    "                            w = cal_pT.f[k_wpT](d['MC_B_pt'])\n",
    "                            w *= d['wh_CLN'+n_pFF+var_pFF]\n",
    "                            norm = np.sum(w)\n",
    "                            w = w[q2_bin]\n",
    "                            \n",
    "                            h = create_TH1D(d[var][q2_bin], name=h_name, title=h_name, \n",
    "                                            binning=binning[var][i_q2], \n",
    "                                            opt='underflow,overflow',\n",
    "                                            weights=w,\n",
    "                                            scale_histo=1./norm,\n",
    "                                           )\n",
    "\n",
    "                            histo[cat_name][h_name] = h\n",
    "            elif k in ['Hc']:\n",
    "                for k_wpT in ['C', 'Up', 'Down']:\n",
    "                    h_name = k\n",
    "                    if k_wpT != 'C':\n",
    "                        h_name += '__B0pT' + k_wpT\n",
    "                        \n",
    "                    w = cal_pT.f[k_wpT](d['MC_B_pt'][q2_bin])\n",
    "                    \n",
    "                    norm = np.sum(cal_pT.f[k_wpT](d['MC_B_pt']))\n",
    "                    h = create_TH1D(d[var][q2_bin], name=h_name, title=h_name, \n",
    "                                    binning=binning[var][i_q2], \n",
    "                                    opt='underflow,overflow',\n",
    "                                    weights=w,\n",
    "                                    scale_histo=1./norm,\n",
    "                                   )\n",
    "                    \n",
    "                    histo[cat_name][h_name] = h\n",
    "            elif k in ['Dstst']:\n",
    "                norm = float(d[var].shape[0])\n",
    "                h = create_TH1D(d[var][q2_bin], name=k, title=k, \n",
    "                                binning=binning[var][i_q2], \n",
    "                                opt='underflow,overflow',\n",
    "                                scale_histo=1./norm,\n",
    "                               )\n",
    "                histo[cat_name][k] = h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate Pseudo-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_evts = {}\n",
    "for n in dSet.keys():\n",
    "    if n == 'data': continue\n",
    "    print '--->', n\n",
    "    xsec_eff = dic_MCeff[n]['xsec']\n",
    "    print 'Pythia xsec: {:1.2e} pb'.format(xsec_eff)\n",
    "    xsec_eff *= dic_decayBR[n][0]\n",
    "    print 'Forced decays BR: {:1.2e}'.format(dic_decayBR[n][0])\n",
    "    xsec_eff *= dic_MCeff[n]['CMSSWFilterEff']\n",
    "    print'Eff CMSSW filter: {:1.2e}'.format(dic_MCeff[n]['CMSSWFilterEff'])\n",
    "    xsec_eff *= dic_MCeff[n]['ntupplizerEff']\n",
    "    print'Eff ntuplizer: {:1.2e}'.format(dic_MCeff[n]['ntupplizerEff'])\n",
    "    xsec_eff *= dic_MCeff[n]['analysisSelEff']\n",
    "    print'Eff selection: {:1.2e}'.format(dic_MCeff[n]['analysisSelEff'])\n",
    "    xsec_eff *= 1e3 # pb -> fb\n",
    "    print '\\nExpected evts/fb: {:.0f}'.format(xsec_eff)\n",
    "    print '\\n'\n",
    "    expected_evts[n] = xsec_eff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create (pseudo-)data histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i_q2 in range(len(binning['q2'])-1):\n",
    "    q2_l = binning['q2'][i_q2]\n",
    "    q2_h = binning['q2'][i_q2 + 1]\n",
    "\n",
    "    for var in ['M2_miss', 'Est_mu']:\n",
    "        cat_name = var+'_q2bin'+str(i_q2)\n",
    "        histo[cat_name] = {}\n",
    "        for k, d in dSet.iteritems():          \n",
    "            q2_bin = np.logical_and(d['q2'] > q2_l, d['q2'] < q2_h)\n",
    "            \n",
    "            if k == 'data':\n",
    "                histo[cat_name][k] = create_TH1D(d[var][q2_bin], \n",
    "                                                 name='data_obs', title='Data Obs',\n",
    "                                                 binning=binning[var][i_q2],\n",
    "                                                 opt='underflow,overflow'\n",
    "                                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "SM_RDst = 0.26\n",
    "rawR_exp = SM_RDst*expected_evts['tau']/expected_evts['mu']\n",
    "print 'Raw ratio: {:1.2e}'.format(rawR_exp)\n",
    "f_Hc = expected_evts['Hc']/np.sum(expected_evts.values())\n",
    "print 'f_Hc: {:1.2e}'.format(f_Hc)\n",
    "f_Dstst = expected_evts['Dstst']/np.sum(expected_evts.values())\n",
    "print 'f_Dstst: {:1.2e}'.format(f_Dstst)\n",
    "\n",
    "f_bkg = f_Hc + f_Dstst\n",
    "if fit_real_data:\n",
    "    from lumi_utilities import getLumiReport\n",
    "    lumi_tot, lumi_dic = getLumiReport(glob(file_loc['data']))\n",
    "else:    \n",
    "    lumi_tot = 10. #fb-1\n",
    "    if trgMu_pt_region == 'high':\n",
    "        N_exp_data = 98500\n",
    "    elif trgMu_pt_region == 'mid':\n",
    "        N_exp_data = 47000\n",
    "    N_exp = N_exp_data*lumi_tot/5.25\n",
    "    N_B2mu_inj = N_exp*(1-f_bkg)/(1+rawR_exp)\n",
    "\n",
    "    n_mu = np.random.poisson(lam=N_B2mu_inj)\n",
    "    w_mu = []\n",
    "    sum_w_mu = 0\n",
    "    idx_mu = []\n",
    "    print('Generating {:.1f}k pseudo-events of mu'.format(n_mu*1.0e-3))\n",
    "    pb = ProgressBar(n_mu)\n",
    "    while sum_w_mu < n_mu:\n",
    "        pb.show(np.ceil(sum_w_mu))\n",
    "        i = np.random.randint(0, dSet['mu']['q2'].shape[0], size=(1, ))[0]\n",
    "        w = cal_pT.f['C'](dSet['mu']['MC_B_pt'][i])\n",
    "        w *= dSet['mu']['wh_CLNCentral'][i]\n",
    "        idx_mu.append(i)\n",
    "        w_mu.append(w)\n",
    "        sum_w_mu += w\n",
    "    pb.show(n_mu-1)\n",
    "\n",
    "    n_tau = np.random.poisson(lam=N_B2mu_inj*rawR_exp)\n",
    "    w_tau = []\n",
    "    idx_tau = []\n",
    "    print('Generating {:.1f}k pseudo-events of tau'.format(n_tau*1.0e-3))\n",
    "    pb = ProgressBar(n_tau)\n",
    "    pb.show(0)\n",
    "    while np.sum(w_tau) < n_tau:\n",
    "        pb.show(np.sum(w_tau))\n",
    "        i = np.random.randint(0, dSet['tau']['q2'].shape[0], size=(1, ))[0]\n",
    "        w = cal_pT.f['C'](dSet['tau']['MC_B_pt'][i])\n",
    "        w *= dSet['tau']['wh_CLNCentral'][i]\n",
    "        idx_tau.append(i)\n",
    "        w_tau.append(w)\n",
    "    pb.show(n_tau-1)\n",
    "    \n",
    "    n_Hc = np.random.poisson(lam=N_exp*f_Hc)\n",
    "    w_Hc = []\n",
    "    idx_Hc = []\n",
    "    print('Generating {:.1f}k pseudo-events of Hc'.format(n_Hc*1.0e-3))\n",
    "    pb = ProgressBar(n_Hc)\n",
    "    while np.sum(w_Hc) < n_Hc:\n",
    "        pb.show(np.sum(w_Hc))\n",
    "        i = np.random.randint(0, dSet['Hc']['q2'].shape[0], size=(1, ))[0]\n",
    "        w = cal_pT.f['C'](dSet['Hc']['MC_B_pt'][i])\n",
    "        idx_Hc.append(i)\n",
    "        w_Hc.append(w)\n",
    "    pb.show(n_Hc-1)\n",
    "    \n",
    "    n_Dstst = np.random.poisson(lam=N_exp*f_Dstst)\n",
    "    print('Generating {:.1f}k pseudo-events of Dstst'.format(n_Dstst*1.0e-3))\n",
    "    idx_Dstst = np.random.randint(0, dSet['Dstst']['q2'].shape[0], size=(n_Dstst, ))\n",
    "\n",
    "    pseudo_data = {}\n",
    "    pseudo_w = np.array(w_mu + w_tau + w_Hc + [1.]*len(idx_Dstst))\n",
    "    for var in binning.keys():\n",
    "        pseudo_data[var] = np.concatenate((dSet['mu'][var][idx_mu], \n",
    "                                           dSet['tau'][var][idx_tau],\n",
    "                                           dSet['Hc'][var][idx_Hc],\n",
    "                                           dSet['Dstst'][var][idx_Dstst]\n",
    "                                          ))\n",
    "\n",
    "    for i_q2 in range(len(binning['q2'])-1):\n",
    "        q2_l = binning['q2'][i_q2]\n",
    "        q2_h = binning['q2'][i_q2 + 1]\n",
    "\n",
    "        for var in ['M2_miss', 'Est_mu']:\n",
    "            cat_name = var+'_q2bin'+str(i_q2)\n",
    "\n",
    "            sel = np.logical_and(pseudo_data['q2'] > q2_l, pseudo_data['q2'] < q2_h)\n",
    "            \n",
    "            h = create_TH1D(pseudo_data[var][sel], \n",
    "                            name='data_obs', title='data obs',\n",
    "                            binning=binning[var][i_q2],\n",
    "                            opt='underflow,overflow',\n",
    "                            weights=pseudo_w[sel]\n",
    "                           )\n",
    "            h.Sumw2(0)\n",
    "            for i in range(1, h.GetNbinsX()+1):\n",
    "                h.SetBinContent(i, round(h.GetBinContent(i)))\n",
    "            h.Sumw2()\n",
    "            histo[cat_name]['data'] = h\n",
    "\n",
    "\n",
    "    print 'r_toy = {:.2f}%'.format(100.*n_tau/n_mu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_data = 0\n",
    "N_mu = 0\n",
    "N_tau = 0\n",
    "N_Hc = 0\n",
    "N_Dstst = 0\n",
    "for k, h_dic in histo.iteritems():\n",
    "    if 'Est_mu' in k:\n",
    "        N_data += h_dic['data'].Integral()\n",
    "        N_mu += h_dic['mu'].Integral()\n",
    "        N_tau += h_dic['tau'].Integral()\n",
    "        N_Hc += h_dic['Hc'].Integral()\n",
    "        N_Dstst += h_dic['Dstst'].Integral()\n",
    "N_B2mu_exp = N_data*(1-f_bkg)/(1+rawR_exp)\n",
    "\n",
    "print 'Number of data events: {:.0f}'.format(N_data)\n",
    "print 'Number of B0 -> D*munu expected: {:.0f}'.format(N_B2mu_exp)\n",
    "print 'Total norm'\n",
    "print 'Mu: {:.3f}'.format(N_mu)\n",
    "print 'Tau: {:.3f}'.format(N_tau)\n",
    "print 'Hc: {:.3f}'.format(N_Hc)\n",
    "print 'Dstst: {:.3f}'.format(N_Dstst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histo_file_dir = '../data/_root/histos4combine/'\n",
    "if not os.path.isdir(histo_file_dir):\n",
    "    os.makedirs(histo_file_dir)\n",
    "histo_file_loc = {}\n",
    "for cat_name, h_dic in histo.iteritems():\n",
    "    histo_file_loc[cat_name] = histo_file_dir+'{}_{}.root'.format(card_name, cat_name)\n",
    "    tf = rt.TFile(histo_file_loc[cat_name], 'recreate')\n",
    "    for v in h_dic.values():\n",
    "        v.Write()\n",
    "    tf.Close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "CMS_lumi.integrated_lumi = lumi_tot\n",
    "scale_dic = {\n",
    "    'tau': N_B2mu_exp*rawR_exp, \n",
    "    'mu' : N_B2mu_exp,\n",
    "    'Hc' : N_data*f_Hc,\n",
    "    'Dstst' : N_data*f_Dstst\n",
    "            }\n",
    "\n",
    "c = plot_gridVarQ2(CMS_lumi, binning, histo, scale_dic, min_y=1, logy=True)\n",
    "\n",
    "# CMS_lumi.integrated_lumi = ''\n",
    "# histNorm = {}\n",
    "# for k, hdic in histo.iteritems():\n",
    "#     if not k in histNorm.keys():\n",
    "#         histNorm[k] = {}\n",
    "#     for kk, h in hdic.iteritems():\n",
    "#         hAux = h.Clone()\n",
    "#         hAux.Scale(1./float(N_data))\n",
    "#         histNorm[k][kk] = hAux\n",
    "\n",
    "# c = plot_gridVarQ2s(CMS_lumi, binning, histNorm, scale_dic, min_y=1, logy=False, iPad_legend=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write the card"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_processes = ['tau', 'mu']\n",
    "bkg_processes = ['Hc', 'Dstst']\n",
    "processes = sig_processes + bkg_processes\n",
    "categories = np.sort([k for k in histo.keys() if not '__' in k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-14T01:36:12.367638Z",
     "start_time": "2019-05-14T01:36:12.352769Z"
    }
   },
   "outputs": [],
   "source": [
    "card_location = 'cards/{}.txt'.format(card_name)\n",
    "fc = open(card_location, 'w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-14T01:36:12.392125Z",
     "start_time": "2019-05-14T01:36:12.371738Z"
    }
   },
   "outputs": [],
   "source": [
    "# number of different categories\n",
    "card = 'imax *\\n'\n",
    "# number of processes minus one\n",
    "card += 'jmax {}\\n'.format(len(processes)-1)\n",
    "# number of nuissance parameters\n",
    "card += 'kmax *\\n'\n",
    "card += '--------------------------------------------------------------\\n'\n",
    "\n",
    "# shape file location\n",
    "for k in categories:\n",
    "    card += 'shapes * {} {} $PROCESS $PROCESS__$SYSTEMATIC\\n'.format(k, histo_file_loc[k])\n",
    "card += '--------------------------------------------------------------\\n'\n",
    "\n",
    "# number of events observed\n",
    "card += 'bin ' + ' '.join(categories) + '\\n'\n",
    "obs = map(lambda k: '{:.0f}'.format(histo[k]['data'].Integral()), categories)\n",
    "obs = ' '.join(obs)\n",
    "card += 'observation ' + obs + '\\n'\n",
    "card += '--------------------------------------------------------------\\n'\n",
    "\n",
    "\n",
    "# MC expected events\n",
    "aux_bin = ''\n",
    "aux_proc_name = ''\n",
    "aux_proc_id = ''\n",
    "aux_proc_rate = ''\n",
    "for c, p in itertools.product(categories, processes):\n",
    "    aux_bin += ' '+c\n",
    "    aux_proc_name += ' '+p\n",
    "    aux_proc_id += ' '+str(np.argmax(np.array(processes) == p))\n",
    "    aux_proc_rate += ' {:.4f}'.format(histo[c][p].Integral())\n",
    "    \n",
    "card += 'bin' + aux_bin + '\\n'\n",
    "card += 'process' + aux_proc_name + '\\n'\n",
    "# Zero or negative for sig and positive for bkg\n",
    "card += 'process' + aux_proc_id + '\\n'\n",
    "# Expected rate\n",
    "card += 'rate' + aux_proc_rate + '\\n'\n",
    "card += '--------------------------------------------------------------\\n'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add additional rate parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "card += 'N_B2mu rateParam * tau {:.1f} [0,{:.0f}]\\n'.format(scale_dic['mu'], 1.2*N_data)\n",
    "card += 'N_B2mu rateParam * mu {:.1f} [0,{:.0f}]\\n'.format(scale_dic['mu'], 1.2*N_data)\n",
    "card += 'N_B2DstHc rateParam * Hc {:.1f} [0,{:.0f}]\\n'.format(scale_dic['Hc'], 1.2*N_data)\n",
    "card += 'N_B2Dstst rateParam * Dstst {:.1f} [0,{:.0f}]\\n'.format(scale_dic['Dstst'], 1.2*N_data)\n",
    "card += '--------------------------------------------------------------\\n'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Systematics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux_B0pT = ''\n",
    "for c, p in itertools.product(categories, processes):\n",
    "    if p in ['tau', 'mu', 'Hc']:\n",
    "        aux_B0pT += ' 1.'\n",
    "    else:\n",
    "        aux_B0pT += ' -'\n",
    "card += 'B0pT shape' + aux_B0pT + '\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n_pFF in ['R0', 'R1', 'R2', 'RhoSq']:\n",
    "    aux = ''\n",
    "    for c, p in itertools.product(categories, processes):\n",
    "        if p in ['tau', 'mu']:\n",
    "            aux += ' 1.'\n",
    "        else:\n",
    "            aux += ' -'\n",
    "    card += 'B2DstCLN{} shape'.format(n_pFF) + aux + '\\n'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MC statistic systematics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "card += '* autoMCStats 0 1 1\\n'\n",
    "card += '--------------------------------------------------------------\\n'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining groups of systematics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# autoMCStats group = defined by default when using autoMCStats\n",
    "card += 'B2DstFF group = B2DstCLN' + ' B2DstCLN'.join(['R0', 'R1', 'R2', 'RhoSq']) + '\\n'\n",
    "card += 'bkgMC_norm group = N_B2DstHc N_B2Dstst\\n'\n",
    "card += 'all_card group = N_B2mu N_B2DstHc N_B2Dstst B0pT\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-14T01:36:12.412621Z",
     "start_time": "2019-05-14T01:36:12.396482Z"
    }
   },
   "outputs": [],
   "source": [
    "print card"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-14T01:36:12.432835Z",
     "start_time": "2019-05-14T01:36:12.416805Z"
    }
   },
   "outputs": [],
   "source": [
    "fc.write(card)\n",
    "fc.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create output directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdir = 'results/' + card_name\n",
    "\n",
    "if os.path.isdir(outdir):\n",
    "    os.system('rm -rf ' + outdir)\n",
    "os.system('mkdir ' + outdir);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Combine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cmd = 'text2workspace.py ' + card_location \n",
    "cmd += ' -o ' + card_location.replace('.txt', '.root')\n",
    "cmd += ' --no-b-only'\n",
    "cmd += ' --verbose 1'\n",
    "# cmd += ' --no-wrappers'\n",
    "os.system(cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the Maximum Likelyhood fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd = 'combine'\n",
    "cmd += ' -M FitDiagnostics'\n",
    "cmd += ' --robustFit 1'\n",
    "cmd += ' --cminDefaultMinimizerStrategy 0'\n",
    "cmd += ' --skipBOnlyFit'\n",
    "cmd += ' -d ' + card_location.replace('.txt', '.root')\n",
    "cmd += ' -D ' + histo[histo.keys()[0]]['data'].GetName()\n",
    "cmd += ' --X-rtd MINIMIZER_analytic'\n",
    "cmd += ' --setParameters r={:.2f}'.format(rawR_exp)\n",
    "cmd += ' --setParameterRanges r=0.001,1'\n",
    "cmd += ' --trackParameters N_B2mu,N_B2DstHc,N_B2Dstst'\n",
    "cmd += ' -n {}'.format(card_name)\n",
    "cmd += ' --out ' + outdir\n",
    "cmd += ' --saveShapes --saveWithUncertainties'\n",
    "cmd += ' --plots'\n",
    "cmd += ' --verbose 1'\n",
    "\n",
    "print cmd\n",
    "os.system(cmd)\n",
    "os.system('mv combine_logger.out ' + outdir + '/')\n",
    "os.system('mv ./*.root ' + outdir + '/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cmd = 'python diffNuisances.py '.format(os.environ['CMSSW_BASE'])\n",
    "cmd += glob(outdir + '/fitDiagnostics{}.root'.format(card_name))[0]\n",
    "cmd += ' --skipFitB'\n",
    "cmd += ' -g {}/nuisance_pull.root'.format(outdir)\n",
    "print cmd\n",
    "os.system(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tdrstyle\n",
    "tdrstyle.setTDRStyle()\n",
    "\n",
    "def plot_gridVarQ2s(CMS_lumi, binning, histo, scale_dic, \n",
    "                    min_y=1e-4, \n",
    "                    draw_pulls=False, \n",
    "                    pulls_ylim=[0.8, 1.2], \n",
    "                    logy=False, iPad_legend=1):\n",
    "    col_dic = {'mu': rt.kAzure+1, 'tau': rt.kRed-4, 'Hc':rt.kGreen+1, 'Dstst': rt.kViolet-7}\n",
    "    \n",
    "    canvas = rt.TCanvas('c_out', 'c_out', 50, 50, 2*600, 400*len(binning['q2'])-1)\n",
    "    canvas.SetTickx(0)\n",
    "    canvas.SetTicky(0)\n",
    "    canvas.Divide(2, len(binning['q2'])-1, 0.001, 0.001)\n",
    "    \n",
    "    canvas.dnd = []\n",
    "\n",
    "    vars_to_plot = ['M2_miss', 'Est_mu']\n",
    "\n",
    "    xAx_title = {'M2_miss':'m^{2}_{miss} [GeV^{2}]', 'Est_mu':'E_{#mu}* [GeV]'}\n",
    "    label_dic = {'data' : 'Data',\n",
    "                 'mu'   : 'B#rightarrow D*#mu#nu',\n",
    "                 'tau'  : 'B#rightarrow D*#tau#nu',\n",
    "                 'Hc'   : 'B#rightarrow D*H_{c}',\n",
    "                 'Dstst': 'B#rightarrow D**#mu#nu'\n",
    "                }\n",
    "    \n",
    "    rt.TGaxis.SetMaxDigits(3)\n",
    "\n",
    "    max_entries = dict(zip(vars_to_plot, [0]*len(vars_to_plot)))\n",
    "    for k, h_dic in histo.iteritems():\n",
    "        if 'M2' in k:\n",
    "            max_entries['M2_miss'] = max(h_dic['data'].GetMaximum(), max_entries['M2_miss'])\n",
    "        elif 'Est' in k:\n",
    "            max_entries['Est_mu'] = max(h_dic['data'].GetMaximum(), max_entries['Est_mu'])\n",
    "    max_entries['M2_miss'] = 0.09*0.55\n",
    "    max_entries['Est_mu'] = 0.035*0.4\n",
    "\n",
    "    for i_q2 in range(len(binning['q2'])-1):\n",
    "        q2_l = binning['q2'][i_q2]\n",
    "        q2_h = binning['q2'][i_q2 + 1]\n",
    "        q2_txt = '{:.1f} <  q^{{2}}  < {:.1f} GeV^{{2}}'.format(q2_l, q2_h)\n",
    "\n",
    "        for i_v, vark in enumerate(vars_to_plot):            \n",
    "            cat_name = vark+'_q2bin'+str(i_q2)\n",
    "            h_dic = histo[cat_name]\n",
    "            \n",
    "            i_pad = i_q2*2 + i_v + 1\n",
    "            pad_master = canvas.cd(i_pad)\n",
    "            \n",
    "            if not draw_pulls:\n",
    "                pad = rt.TPad('pmain_'+cat_name, 'pmain_'+cat_name, 0, 0, 1, 1)\n",
    "                pad.SetBottomMargin(0.2)\n",
    "            else:\n",
    "                pad = rt.TPad('pmain_'+cat_name, 'pmain_'+cat_name, 0, 0.25, 1, 1)\n",
    "                pad.SetBottomMargin(0.)\n",
    "            pad.SetTopMargin(0.07)\n",
    "            pad.SetRightMargin(0.05)\n",
    "            pad.SetLeftMargin(0.18)\n",
    "            pad.Draw()\n",
    "            pad.cd()\n",
    "\n",
    "            h = h_dic['data'].Clone('h_aux_data_'+cat_name)\n",
    "            if 'data' in scale_dic.keys(): h.Scale(scale_dic['data'])\n",
    "            h.SetLineColor(1)\n",
    "            h.SetLineWidth(1)\n",
    "            h.SetMarkerColor(1)\n",
    "            h.SetMarkerStyle(20)\n",
    "            h.GetXaxis().SetTitle(xAx_title[vark])\n",
    "            h.GetXaxis().SetTitleSize(0.075)\n",
    "            h.GetXaxis().SetLabelSize(0.07)\n",
    "            h.GetYaxis().SetTitleOffset(1.5)\n",
    "            h.GetXaxis().SetTitleOffset(1.1)\n",
    "            h.GetYaxis().SetTitleSize(0.06)\n",
    "            h.GetYaxis().SetLabelSize(0.07)\n",
    "            iunits = xAx_title[vark].find('[') + 1\n",
    "            h.GetYaxis().SetTitle('a.u. / {:.2f} '.format(h.GetBinWidth(3)) + xAx_title[vark][iunits:-1])\n",
    "            max_y = max_entries[vark]\n",
    "            if 'data' in scale_dic.keys(): \n",
    "                max_y *= scale_dic['data']\n",
    "            h.GetYaxis().SetRangeUser(min_y, max_y)\n",
    "            \n",
    "            \n",
    "            h_Dstst = h_dic['Dstst'].Clone('h_aux_Dstst_'+cat_name)\n",
    "            if 'Dstst' in scale_dic.keys(): h_Dstst.Scale(scale_dic['Dstst'])\n",
    "            h_Dstst.SetLineWidth(0)\n",
    "            h_Dstst.SetFillColor(col_dic['Dstst'])\n",
    "            h_Dstst.SetFillStyle(1)\n",
    "            h_Dstst.Sumw2(0)\n",
    "            \n",
    "            h_Hc = h_dic['Hc'].Clone('h_aux_Hc_'+cat_name)\n",
    "            if 'Hc' in scale_dic.keys(): h_Hc.Scale(scale_dic['Hc'])\n",
    "            h_Hc.Add(h_Dstst)\n",
    "            h_Hc.SetLineWidth(0)\n",
    "            h_Hc.SetFillColor(col_dic['Hc'])\n",
    "            h_Hc.SetFillStyle(1)\n",
    "            h_Hc.Sumw2(0)\n",
    "            \n",
    "            h_tau = h_dic['tau'].Clone('h_aux_tau_'+cat_name)\n",
    "            if 'tau' in scale_dic.keys(): h_tau.Scale(scale_dic['tau'])\n",
    "            h_tau.Add(h_Hc)\n",
    "            h_tau.SetLineWidth(0)\n",
    "            h_tau.SetFillColor(col_dic['tau'])\n",
    "            h_tau.SetFillStyle(1)\n",
    "            h_tau.Sumw2(0)\n",
    "            \n",
    "            h_mu = h_dic['mu'].Clone('h_aux_mu_'+cat_name)\n",
    "            if 'mu' in scale_dic.keys(): h_mu.Scale(scale_dic['mu'])\n",
    "            h_mu.Add(h_tau)\n",
    "            h_mu.SetLineWidth(0)\n",
    "            h_mu.SetFillColor(col_dic['mu'])\n",
    "            h_mu.SetFillStyle(1)\n",
    "            h_mu.Sumw2(0)\n",
    "            \n",
    "            \n",
    "            h.Draw('E1')\n",
    "            h_mu.DrawCopy('SAME')\n",
    "            h_tau.Draw('SAME')\n",
    "            h_Hc.Draw('SAME')\n",
    "            h_Dstst.Draw('SAME')\n",
    "            h.Draw('SAMEE1') #Draw it a second time to bring it in foreground\n",
    "\n",
    "            l = rt.TLatex()\n",
    "            l.SetTextAlign(11)\n",
    "            l.SetTextSize(0.06)\n",
    "            l.SetTextFont(42)\n",
    "#             l.DrawLatexNDC(0.22, 0.85, q2_txt)\n",
    "\n",
    "            CMS_lumi.CMS_lumi(pad, -1, 33, cmsTextSize=0.75*1.2, lumiTextSize=0.6*1.2)\n",
    "            if logy:\n",
    "                pad.SetLogy()\n",
    "\n",
    "            if i_pad == iPad_legend:\n",
    "                leg = rt.TLegend(0.6, 0.3, 0.9, 0.7)\n",
    "                leg.SetTextFont(42)\n",
    "                leg.SetTextAlign(12)\n",
    "                leg.SetLineWidth(0)\n",
    "                leg.SetBorderSize(0)\n",
    "                leg.AddEntry(h, label_dic['data'], 'lep')\n",
    "                leg.AddEntry(h_mu, label_dic['mu'], 'f')\n",
    "                leg.AddEntry(h_tau, label_dic['tau'], 'f')\n",
    "                leg.AddEntry(h_Hc, label_dic['Hc'], 'f')\n",
    "                leg.AddEntry(h_Dstst, label_dic['Dstst'], 'f')\n",
    "                leg.Draw()\n",
    "                canvas.dnd.append(leg)\n",
    "                \n",
    "            canvas.dnd.append([pad, h, h_tau, h_mu, h_Hc, h_Dstst])    \n",
    "\n",
    "            if draw_pulls:\n",
    "                pad_master.cd()\n",
    "\n",
    "                pad = rt.TPad('ppull_'+cat_name, 'ppull_'+cat_name, 0, 0, 1, 0.25)\n",
    "                pad.SetBottomMargin(0.5)\n",
    "                pad.SetTopMargin(0)\n",
    "                pad.SetRightMargin(0.05)\n",
    "                pad.SetLeftMargin(0.18)\n",
    "                pad.Draw()\n",
    "                pad.cd()\n",
    "                \n",
    "                h_dr = h.Clone('h_aux_dataratio_'+cat_name)\n",
    "                h_dr.GetYaxis().SetTitle('RD/MC')\n",
    "                h_tot = h_dic['total'].Clone('h_aux_total_'+cat_name)\n",
    "                g_up = rt.TGraph()\n",
    "                g_up.SetPoint(0, h_tot.GetBinCenter(1)-0.5*h_tot.GetBinWidth(1), 1)\n",
    "                g_down = rt.TGraph()\n",
    "                g_down.SetPoint(0, h_tot.GetBinCenter(1)-0.5*h_tot.GetBinWidth(1), 1)\n",
    "                for i in range(1, h_dr.GetNbinsX()+1):\n",
    "                    c = h_dr.GetBinContent(i)\n",
    "                    e = h_dr.GetBinError(i)\n",
    "                    c_MC = h_tot.GetBinContent(i)\n",
    "                    e_MC = h_tot.GetBinError(i)\n",
    "                    h_dr.SetBinContent(i, c/c_MC)\n",
    "                    h_dr.SetBinError(i, e/c_MC)\n",
    "                    x_low = h_tot.GetBinCenter(i) - 0.5*h.GetBinWidth(i)\n",
    "                    x_up = h_tot.GetBinCenter(i) + 0.5*h.GetBinWidth(i)\n",
    "                    g_up.SetPoint(2*i-1, x_low, (c_MC+e_MC)/c_MC)\n",
    "                    g_up.SetPoint(2*i, x_up, (c_MC+e_MC)/c_MC)\n",
    "                    g_down.SetPoint(2*i-1, x_low, (c_MC-e_MC)/c_MC)\n",
    "                    g_down.SetPoint(2*i, x_up, (c_MC-e_MC)/c_MC)\n",
    "                g_up.SetPoint(2*i+1, x_up, 1)\n",
    "                g_down.SetPoint(2*i+1, x_up, 1)\n",
    "                \n",
    "                h_dr.GetYaxis().SetRangeUser(pulls_ylim[0], pulls_ylim[1])\n",
    "                h_dr.GetYaxis().SetTitleOffset(0.35)\n",
    "                h_dr.GetYaxis().SetTitleSize(0.2)\n",
    "                h_dr.GetYaxis().SetLabelSize(0.2)\n",
    "                h_dr.GetYaxis().SetNdivisions(402)\n",
    "                h_dr.GetXaxis().SetTitleOffset(0.95)\n",
    "                h_dr.GetXaxis().SetTitleSize(0.22)\n",
    "                h_dr.GetXaxis().SetLabelSize(0.22)\n",
    "                h_dr.GetXaxis().SetTickSize(0.07)\n",
    "                \n",
    "                h_dr.Draw('E1')\n",
    "                \n",
    "                g_up.SetFillColor(rt.kGray)\n",
    "                g_up.SetFillStyle(1)\n",
    "                g_up.Draw('F')\n",
    "                g_down.SetFillColor(rt.kGray)\n",
    "                g_down.SetFillStyle(1)\n",
    "                g_down.Draw('F')\n",
    "                l = rt.TLine()\n",
    "                l.SetLineColor(rt.kGray+1)\n",
    "                l.SetLineWidth(1)\n",
    "                l.SetLineStyle(9)\n",
    "                x_low = h_tot.GetBinCenter(1)-0.5*h.GetBinWidth(1)\n",
    "                x_high = h_tot.GetBinCenter(i)+0.5*h.GetBinWidth(i)\n",
    "                l.DrawLine(x_low, 1, x_high, 1)\n",
    "                h_dr.Draw('sameE') #redraw it to bring it to front\n",
    "                \n",
    "                canvas.dnd.append([pad, h_dr, h_tot, g_up, g_down])\n",
    "\n",
    "    canvas.Draw()\n",
    "    return canvas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "f = ur.open(glob(outdir + '/higgsCombine{}.FitDiagnostics.mH120.root'.format(card_name))[0])\n",
    "c, d, u, _ = f['limit']['limit'].array()\n",
    "print 'r = {:.1f} +{:.1f}/-{:.1f} %'.format(100*c, 100*(u-c), 100*(c-d))\n",
    "\n",
    "N_B2mu = f['limit']['trackedParam_N_B2mu'].array()[0]\n",
    "print 'N_B2mu = {:.0f}'.format(N_B2mu)\n",
    "N_B2DstHc = f['limit']['trackedParam_N_B2DstHc'].array()[0]\n",
    "print 'N_B2DstHc = {:.0f}'.format(N_B2DstHc)\n",
    "N_B2Dstst = f['limit']['trackedParam_N_B2Dstst'].array()[0]\n",
    "print 'N_B2Dstst = {:.0f}'.format(N_B2Dstst)\n",
    "\n",
    "# Get post-fit shapes\n",
    "f = rt.TFile(glob(outdir + '/fitDiagnostics{}.root'.format(card_name))[0], 'READ')\n",
    "fd = f.shapes_fit_s\n",
    "\n",
    "print '\\n'\n",
    "histo_postfit = {}\n",
    "for cat, h_dic in histo.iteritems():\n",
    "    histo_postfit[cat] = {}\n",
    "    for n, h in h_dic.iteritems():\n",
    "        if '__' in n:\n",
    "            continue\n",
    "        h_post = h.Clone(h.GetName() + '_postfit')\n",
    "        if 'data' in n:\n",
    "            h_fit = fd.Get(cat+'/total')\n",
    "            h_data = h.Clone(h.GetName() + '_data')\n",
    "            for i in range(1, h_post.GetNbinsX()+1):\n",
    "                h_post.SetBinContent(i, h_fit.GetBinContent(i))\n",
    "                h_post.SetBinError(i, h_fit.GetBinError(i))     \n",
    "            \n",
    "            histo_postfit[cat]['total'] = h_post\n",
    "            histo_postfit[cat][n] = h_data\n",
    "        else:\n",
    "            h_fit = fd.Get(cat+'/'+n)\n",
    "            for i in range(1, h_post.GetNbinsX()+1):\n",
    "                h_post.SetBinContent(i, h_fit.GetBinContent(i))\n",
    "                h_post.SetBinError(i, h_fit.GetBinError(i)) \n",
    "\n",
    "            histo_postfit[cat][n] = h_post\n",
    "            \n",
    "# c_out = plot_gridVarQ2(CMS_lumi, binning, histo_postfit, scale_dic={}, draw_pulls=True, pulls_ylim=[0.9, 1.1])\n",
    "\n",
    "CMS_lumi.integrated_lumi = ''\n",
    "histNorm = {}\n",
    "for k, hdic in histo_postfit.iteritems():\n",
    "    if not k in histNorm.keys():\n",
    "        histNorm[k] = {}\n",
    "    for kk, h in hdic.iteritems():\n",
    "        hAux = h.Clone()\n",
    "        hAux.Scale(1./float(N_data))\n",
    "        histNorm[k][kk] = hAux\n",
    "\n",
    "c = plot_gridVarQ2s(CMS_lumi, binning, histNorm, scale_dic={}, min_y=1, logy=False, draw_pulls=True, iPad_legend=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_out.SaveAs('gridPlot_test.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run likelyhood scan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getUncertainty(name, verbose=True):\n",
    "    f = ur.open(name)\n",
    "    r_arr = f['limit']['r'].array()\n",
    "    nll_arr = f['limit']['deltaNLL'].array()\n",
    "    c = r_arr[0]\n",
    "    r_u = r_arr[r_arr>r_arr[0]]\n",
    "    nll_u = nll_arr[r_arr>r_arr[0]]\n",
    "    f_u = interp1d(nll_u, r_u, 'quadratic')\n",
    "    u = f_u(0.5)\n",
    "    r_l = r_arr[r_arr<r_arr[0]]\n",
    "    nll_l = nll_arr[r_arr<r_arr[0]]\n",
    "    f_l = interp1d(nll_l, r_l, 'quadratic')\n",
    "    l = f_l(0.5)\n",
    "    if verbose:\n",
    "        print '----------------------------------'\n",
    "        print 'r = {:.2f} +{:.2f}/-{:.2f} %'.format(100*c, 100*(u-c), 100*(c-l))\n",
    "        print 'Sigma = {:.3f}'.format((u-l)*0.5)\n",
    "        print '----------------------------------\\n'\n",
    "    return c, c-l, u-c, (u-l)*0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd = 'combine'\n",
    "cmd += ' -M MultiDimFit'\n",
    "cmd += ' --algo grid --points=100'\n",
    "cmd += ' --robustFit 1'\n",
    "cmd += ' -d ' + card_location.replace('.txt', '.root')\n",
    "cmd += ' -D ' + histo[histo.keys()[0]]['data'].GetName()\n",
    "cmd += ' --X-rtd MINIMIZER_analytic'\n",
    "cmd += ' --rMin={:.4f} --rMax={:.4f}'.format(c - 5*(c-d), c + 5*(u-c))\n",
    "cmd += ' -n {}_nominal'.format(card_name)\n",
    "cmd += ' --verbose -1'\n",
    "print cmd\n",
    "os.system(cmd)\n",
    "cmd = 'plot1DScan.py higgsCombine{}_nominal.MultiDimFit.mH120.root'.format(card_name)\n",
    "cmd += '; mv scan.png scan_nominal.png'\n",
    "os.system(cmd)\n",
    "res_nominal = getUncertainty('higgsCombine{}_nominal.MultiDimFit.mH120.root'.format(card_name))\n",
    "display(Image(filename='scan_nominal.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uncertainy breakdown by group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd = 'combine'\n",
    "cmd += ' -M MultiDimFit'\n",
    "cmd += ' --algo none'\n",
    "cmd += ' --cminDefaultMinimizerStrategy=2'\n",
    "cmd += ' --robustFit 1'\n",
    "cmd += ' -d ' + card_location.replace('.txt', '.root')\n",
    "cmd += ' -D ' + histo[histo.keys()[0]]['data'].GetName()\n",
    "cmd += ' --X-rtd MINIMIZER_analytic'\n",
    "cmd += ' --setParameters r=0.1'\n",
    "cmd += ' --rMin=0 --rMax=1'\n",
    "cmd += ' -n {}_bestfit'.format(card_name)\n",
    "cmd += ' --saveWorkspace'\n",
    "cmd += ' --verbose -1'\n",
    "print cmd\n",
    "os.system(cmd);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical uncertainty\n",
    "cmd = 'combine'\n",
    "cmd += ' -M MultiDimFit'\n",
    "cmd += ' --algo grid --points=100'\n",
    "cmd += ' --cminDefaultMinimizerStrategy=2'\n",
    "cmd += ' --robustFit 1'\n",
    "cmd += ' -d higgsCombine{}_bestfit.MultiDimFit.mH120.root'.format(card_name)\n",
    "cmd += ' -D ' + histo[histo.keys()[0]]['data'].GetName()\n",
    "cmd += ' --X-rtd MINIMIZER_analytic'\n",
    "cmd += ' --rMin={:.4f} --rMax={:.4f}'.format(c - 5*(c-d), c + 5*(u-c))\n",
    "cmd += ' -n {}_stat'.format(card_name)\n",
    "cmd += ' --snapshotName MultiDimFit'\n",
    "cmd += ' --freezeParameters allConstrainedNuisances'\n",
    "cmd += ' --verbose -1'\n",
    "print cmd\n",
    "os.system(cmd);\n",
    "res_stat = getUncertainty('higgsCombine{}_stat.MultiDimFit.mH120.root'.format(card_name))\n",
    "cmd = 'plot1DScan.py higgsCombine{}_nominal.MultiDimFit.mH120.root'.format(card_name)\n",
    "cmd += ' --others \"higgsCombine{}_stat.MultiDimFit.mH120.root:Freeze all:2\"'.format(card_name)\n",
    "cmd += ' --breakdown syst,stat'\n",
    "cmd += '; mv scan.png scan_stat.png'\n",
    "print cmd\n",
    "os.system(cmd)\n",
    "display(Image(filename='scan_stat.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MC Statistics\n",
    "cmd = 'combine'\n",
    "cmd += ' -M MultiDimFit'\n",
    "cmd += ' --algo grid --points=100'\n",
    "cmd += ' --cminDefaultMinimizerStrategy=2'\n",
    "cmd += ' --robustFit 1'\n",
    "cmd += ' -d higgsCombine{}_bestfit.MultiDimFit.mH120.root'.format(card_name)\n",
    "cmd += ' -D ' + histo[histo.keys()[0]]['data'].GetName()\n",
    "cmd += ' --X-rtd MINIMIZER_analytic'\n",
    "cmd += ' --rMin={:.4f} --rMax={:.4f}'.format(c - 5*(c-d), c + 5*(u-c))\n",
    "cmd += ' -n {}_MCstat'.format(card_name)\n",
    "cmd += ' --snapshotName MultiDimFit'\n",
    "cmd += ' --freezeNuisanceGroups=autoMCStats'\n",
    "cmd += ' --verbose -1'\n",
    "print cmd\n",
    "os.system(cmd);\n",
    "res_MCstat = getUncertainty('higgsCombine{}_MCstat.MultiDimFit.mH120.root'.format(card_name))\n",
    "cmd = 'plot1DScan.py higgsCombine{}_nominal.MultiDimFit.mH120.root'.format(card_name)\n",
    "cmd += ' --others'\n",
    "cmd += ' \"higgsCombine{}_MCstat.MultiDimFit.mH120.root:Freeze MC stat:4\"'.format(card_name)\n",
    "cmd += ' \"higgsCombine{}_stat.MultiDimFit.mH120.root:Freeze all:2\"'.format(card_name)\n",
    "cmd += ' --breakdown MCstat,syst,stat'\n",
    "cmd += '; mv scan.png scan_MCstat.png'\n",
    "print cmd\n",
    "os.system(cmd)\n",
    "display(Image(filename='scan_MCstat.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.system('mv higgsCombine*.root ' + outdir + '/')\n",
    "os.system('mv scan* ' + outdir + '/')\n",
    "os.system('mv combine_logger.out ' + outdir + '/');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the pull/impact plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit first the POI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cmd = 'combineTool.py -M Impacts --doInitialFit -m 120'\n",
    "cmd += ' --robustFit 1'\n",
    "cmd += ' -d ' + card_location.replace('.txt', '.root')\n",
    "cmd += ' -D ' + histo[histo.keys()[0]]['data'].GetName()\n",
    "cmd += ' --X-rtd MINIMIZER_analytic'\n",
    "cmd += ' --setParameters r={:.2f}'.format(rawR_exp)\n",
    "cmd += ' --setParameterRanges r=0.001,1'\n",
    "cmd += ' -n {}'.format(card_name)\n",
    "cmd += ' --out ' + outdir\n",
    "cmd += ' --verbose 0'\n",
    "os.system(cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Perform a similar scan for each nuisance parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd = 'combineTool.py -M Impacts --doFits -m 120'\n",
    "cmd += ' --robustFit 1'\n",
    "cmd += ' --parallel 8'\n",
    "cmd += ' -d ' + card_location.replace('.txt', '.root')\n",
    "cmd += ' -D ' + histo[histo.keys()[0]]['data'].GetName()\n",
    "cmd += ' --X-rtd MINIMIZER_analytic'\n",
    "# cmd += ' --setParameters r={:.2f}'.format(rawR_exp)\n",
    "# cmd += ' --setParameterRanges r=0.001,1'\n",
    "cmd += ' -n {}'.format(card_name)\n",
    "cmd += ' --out ' + outdir\n",
    "cmd += ' --verbose 0'\n",
    "print cmd\n",
    "os.system(cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collect the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd = 'combineTool.py -M Impacts -o impacts.json -m 120'\n",
    "cmd += ' -d ' + card_location.replace('.txt', '.root')\n",
    "cmd += ' -n {}'.format(card_name)\n",
    "print cmd\n",
    "os.system(cmd);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rename = {\n",
    "'B0pT': 'B_{0} p_{T} spectrum',\n",
    "'N_B2mu':'N_{B#rightarrow D*#mu#nu}',\n",
    "'N_B2DstHc':'N_{B#rightarrow D*H_{c}}',\n",
    "'N_B2Dstst':'N_{B#rightarrow D**#mu#nu}',\n",
    "'B2DstCLNR0':'R_{0} (CLN B#rightarrow D*)',\n",
    "'B2DstCLNR1':'R_{1} (CLN B#rightarrow D*)',\n",
    "'B2DstCLNR2':'R_{2} (CLN B#rightarrow D*)',\n",
    "'B2DstCLNRhoSq':'#rho^{2} (CLN B#rightarrow D*)'\n",
    "}\n",
    "json.dump(rename, open('rename.json', 'w'))\n",
    "\n",
    "cmd = 'plotImpacts.py -i impacts.json -o impacts -t rename.json'\n",
    "os.system(cmd)\n",
    "IFrame(\"impacts.pdf\", width=900, height=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.system('mv *.root {}/'.format(outdir))\n",
    "os.system('mv impacts.* {}/'.format(outdir))\n",
    "os.system('mv rename.json {}/'.format(outdir))\n",
    "os.system('mv combine_logger.out {}/'.format(outdir));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the Goodness of fit test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the observed test stat value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd = 'combine'\n",
    "cmd += ' -M GoodnessOfFit'\n",
    "cmd += ' -d ' + card_location\n",
    "cmd += ' -D ' + histo[histo.keys()[0]]['data'].GetName()\n",
    "cmd += ' -n Obs'                                    # Just the output name\n",
    "cmd += ' -t 0'                                      # Don't run toys\n",
    "cmd += ' -s -1'                                     # Random seed\n",
    "cmd += ' --toysNoSystematics --algo=saturated'\n",
    "# cmd += ' --toysFrequentist'\n",
    "cmd += ' --X-rtd MINIMIZER_analytic'\n",
    "cmd += ' --setParameters r=0.1'\n",
    "cmd += ' --setParameterRanges r=0.001,1'\n",
    "cmd += ' --trackParameters N_B2mu'\n",
    "cmd += ' --plots'\n",
    "cmd += ' --verbose 9'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print cmd\n",
    "os.system(cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the test stat toy distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd = 'combine'\n",
    "cmd += ' -M GoodnessOfFit'\n",
    "cmd += ' -d ' + card_location\n",
    "cmd += ' -D ' + histo[histo.keys()[0]]['data'].GetName()\n",
    "cmd += ' -n Toys'                                   # Just the output name\n",
    "cmd += ' -t 300'                                    # Number of toys to run\n",
    "cmd += ' -s -1'                                     # Random seed\n",
    "cmd += ' --toysNoSystematics --algo=saturated'\n",
    "# cmd += ' --toysFrequentist'\n",
    "# cmd += '--expectSignal=0'                           # Depending on the hypothesis to test. If none, r is fluctruated\n",
    "cmd += ' --X-rtd MINIMIZER_analytic'\n",
    "cmd += ' --setParameters r=0.1'\n",
    "cmd += ' --setParameterRanges r=0.001,1'\n",
    "cmd += ' --trackParameters N_B2mu'\n",
    "cmd += ' --plots'\n",
    "cmd += ' --verbose 1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print cmd\n",
    "os.system(cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine them to get the p-value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_obs = glob('higgsCombineObs.GoodnessOfFit.*.root')[0]\n",
    "# name_obs = glob(outdir+'/higgsCombineObs.GoodnessOfFit.*.root')[0]\n",
    "name_toys = glob('higgsCombineToys.GoodnessOfFit.*.root')[0]\n",
    "# name_toys = glob(outdir+'/higgsCombineToys.GoodnessOfFit.*.root')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = ur.open(name_obs)\n",
    "s_obs = f['limit']['limit'].array()[0]\n",
    "\n",
    "f = ur.open(name_toys)\n",
    "s_toys = f['limit']['limit'].array()\n",
    "\n",
    "content, center, _ = plt.hist(s_toys, label='Toys')\n",
    "plt.plot([s_obs, s_obs], [0, np.max(content)], 'm--', label='Observed')\n",
    "plt.legend(loc='best')\n",
    "\n",
    "p_val = np.sum(s_toys > s_obs)/float(s_toys.shape[0])\n",
    "print 'p-value: {:.1f}%'.format(100*p_val)\n",
    "if p_val < 0.01: print p_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cmd = 'combineTool.py'\n",
    "# cmd += ' -M CollectGoodnessOfFit'\n",
    "# cmd += ' --mass 120'\n",
    "# cmd += ' -o gof.json'\n",
    "# cmd += ' --input {} {}'.format(name_obs, name_toys)\n",
    "# print cmd\n",
    "# os.system(cmd)\n",
    "# os.system('plotGof.py gof.json -o gof --mass 120.0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.system('mv *.root {}/'.format(outdir))\n",
    "os.system('mv *.dot {}/'.format(outdir))\n",
    "os.system('mv *.out {}/'.format(outdir))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
