{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New:\n",
    " - Hc divided into 3 subsamples\n",
    " - PU/PV additional tracks ratio corrected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T02:25:34.778289Z",
     "start_time": "2020-05-16T02:25:34.767437Z"
    }
   },
   "outputs": [],
   "source": [
    "card_name = 'v8'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T02:25:34.839518Z",
     "start_time": "2020-05-16T02:25:34.783766Z"
    }
   },
   "outputs": [],
   "source": [
    "fit_real_data = True\n",
    "category = 'low'\n",
    "SM_RDst = 0.26\n",
    "fastRun = False\n",
    "card_name += '_'+category"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hide_input": true
   },
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T02:25:35.184096Z",
     "start_time": "2020-05-16T02:25:34.845127Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import sys, os, pickle, time\n",
    "from glob import glob\n",
    "sys.path.append('../lib')\n",
    "sys.path.append('../analysis')\n",
    "from categoriesDef import categories\n",
    "import itertools\n",
    "import commands\n",
    "from prettytable import PrettyTable\n",
    "import json, yaml\n",
    "from IPython.display import IFrame, Image, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T02:25:42.499529Z",
     "start_time": "2020-05-16T02:25:35.189078Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from array import array\n",
    "\n",
    "import uproot as ur\n",
    "import ROOT as rt\n",
    "rt.gErrorIgnoreLevel = rt.kError\n",
    "rt.RooMsgService.instance().setGlobalKillBelow(rt.RooFit.ERROR)\n",
    "import root_numpy as rtnp\n",
    "\n",
    "from analysis_utilities import drawOnCMSCanvas, getEff, DSetLoader\n",
    "from pT_calibration_reader import pTCalReader\n",
    "from histo_utilities import create_TH1D, create_TH2D, std_color_list\n",
    "from gridVarQ2Plot import plot_gridVarQ2, plot_SingleCategory\n",
    "from progressBar import ProgressBar\n",
    "from lumi_utilities import getLumiByTrigger\n",
    "from combine_utilities import getUncertaintyFromLimitTree, dumpDiffNuisances, stringJubCustomizationCaltechT2\n",
    "\n",
    "import CMS_lumi, tdrstyle\n",
    "tdrstyle.setTDRStyle()\n",
    "CMS_lumi.writeExtraText = 1\n",
    "\n",
    "if fit_real_data:\n",
    "    CMS_lumi.extraText = \"     Preliminary\"\n",
    "else:\n",
    "    CMS_lumi.extraText = \"     Simulation Preliminary\"\n",
    "\n",
    "donotdelete = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T02:25:42.520716Z",
     "start_time": "2020-05-16T02:25:42.504657Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cat = categories[category]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Load the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T02:25:57.539223Z",
     "start_time": "2020-05-16T02:25:42.525482Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#They all have to be produced with the same pileup\n",
    "MCsample = {\n",
    "'mu' : DSetLoader('B0_MuNuDmst_PUc0'),\n",
    "'tau' : DSetLoader('B0_TauNuDmst_PUc0'),\n",
    "'DstmD0' : DSetLoader('B0_DstmD0_PUc0'),\n",
    "'DstmDp' : DSetLoader('B0_DstmDp_PUc0'),\n",
    "'DstmDsp' : DSetLoader('B0_DstmDsp_PUc0'),\n",
    "'DstPip' : DSetLoader('Bp_MuNuDstst_Pip_PUc0'),\n",
    "'DstPi0' : DSetLoader('B0_MuNuDstst_Pi0_PUc0'),\n",
    "'DstPipPi0' : DSetLoader('Bp_MuNuDstst_PipPi0_PUc0'),\n",
    "'DstPipPim' : DSetLoader('B0_MuNuDstst_PipPim_PUc0'),\n",
    "'DstPi0Pi0' : DSetLoader('B0_MuNuDstst_Pi0Pi0_PUc0'),\n",
    "}\n",
    "dSet = {}\n",
    "dSetTkSide = {}\n",
    "for n, s in MCsample.iteritems():\n",
    "    dSet[n] = rtnp.root2array(s.skimmed_dir + '/{}_corr.root'.format(cat.name))\n",
    "    dSetTkSide[n] = rtnp.root2array(s.skimmed_dir + '/{}_trkCtrl_corr.root'.format(cat.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T02:25:58.917186Z",
     "start_time": "2020-05-16T02:25:57.544822Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "if fit_real_data:\n",
    "    creation_date = '200416'\n",
    "    locRD = '../data/cmsRD/skimmed/B2DstMu_{}_{}'.format(creation_date, cat.name)\n",
    "    dSet['data'] = rtnp.root2array(locRD + '_corr.root')\n",
    "    dSetTkSide['data'] = rtnp.root2array(locRD + '_trkCtrl_corr.root')\n",
    "    dataDir = '../data/cmsRD'\n",
    "    datasets_loc = glob(dataDir + '/ParkingBPH*/*RDntuplizer_B2DstMu_{}_CAND.root'.format(creation_date))\n",
    "    lumi_tot = getLumiByTrigger(datasets_loc, cat.trg, verbose=True)\n",
    "    CMS_lumi.integrated_lumi = lumi_tot\n",
    "else:\n",
    "    expectedLumi = {'low':6., 'mid':20., 'high':26., 'single':6.} #fb^-1\n",
    "    lumi_tot = expectedLumi[category]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Load all the calibrations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Pileup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T02:25:59.043335Z",
     "start_time": "2020-05-16T02:25:58.922463Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "loc = '../data/cmsRD/ParkingBPH{}/Run2018D-05May2019promptD-v1_RDntuplizer_PrescaleVertices_200421_CAND.root'\n",
    "fAuxPileupRD = []\n",
    "\n",
    "hPileupTarget = None\n",
    "\n",
    "for i in range(2, 6):\n",
    "    fAuxPileupRD.append(rt.TFile.Open(loc.format(i), 'READ'))\n",
    "    if hPileupTarget is None:\n",
    "        hPileupTarget = fAuxPileupRD[-1].Get('nVtx/hNvtxPassed'+cat.trg).Clone()\n",
    "    else:\n",
    "        hPileupTarget.Add(fAuxPileupRD[-1].Get('nVtx/hNvtxPassed'+cat.trg))\n",
    "\n",
    "hPileupTarget.Scale(1./hPileupTarget.Integral())\n",
    "\n",
    "fAuxPileupMC = rt.TFile.Open(MCsample['mu'].skimmed_dir + '/{}_corr.root'.format(cat.name), 'READ')\n",
    "hPileupGen = fAuxPileupMC.Get('hAllNvtx')\n",
    "hPileupGen.Scale(1./hPileupGen.Integral())\n",
    "\n",
    "weights = np.ones(hPileupGen.GetNbinsX())\n",
    "s = 0\n",
    "for i in range(weights.shape[0]):\n",
    "    if hPileupGen.GetBinContent(i+1) == 0:\n",
    "        continue\n",
    "    weights[i] = hPileupTarget.GetBinContent(i+1)/hPileupGen.GetBinContent(i+1)\n",
    "    s += hPileupGen.GetBinContent(i+1) * weights[i]\n",
    "\n",
    "weightsPileupMC = weights/s\n",
    "\n",
    "for f in fAuxPileupRD + [fAuxPileupMC]:\n",
    "    f.Close()\n",
    "\n",
    "def getPileupWeights(ds, selection=None):\n",
    "    x = ds['N_vtx']\n",
    "    if not selection is None:\n",
    "        x = x[selection]\n",
    "    return weightsPileupMC[x.astype(np.int)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Total norm pre-scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T02:25:59.083968Z",
     "start_time": "2020-05-16T02:25:59.048624Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "r = np.zeros((3,2))\n",
    "for i, fn in enumerate(glob('../data/calibration/totalRate/ratioB02JPsiKst_*.txt')):\n",
    "    with open(fn, 'r') as faux:\n",
    "        aux = faux.readlines()[0][:-1].split(' ')\n",
    "        r[i] = [float(aux[0]), float(aux[1])]\n",
    "s2 = np.square(r[:,1])\n",
    "num = np.sum(r[:,0]/s2)\n",
    "den = np.sum(1./s2)\n",
    "RDoMC_normRatio = [num/den, np.sqrt(1/den)]\n",
    "print 'Expected ratio between RD and MC norm: {:.3f} +/- {:.3f}'.format(RDoMC_normRatio[0], RDoMC_normRatio[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Branching fraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T02:25:59.124795Z",
     "start_time": "2020-05-16T02:25:59.089236Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "decayBR = pickle.load(open('../data/forcedDecayChannelsFactors.pickle', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Trigger scale factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T02:25:59.170270Z",
     "start_time": "2020-05-16T02:25:59.129840Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "loc = '../data/calibration/triggerScaleFactors/'\n",
    "fTriggerSF = rt.TFile.Open(loc + 'HLT_' + cat.trg + '_SF.root', 'READ')\n",
    "hTriggerSF = fTriggerSF.Get('hSF_HLT_' + cat.trg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T02:25:59.219304Z",
     "start_time": "2020-05-16T02:25:59.175321Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def computeTrgSF(ds, selection=None):\n",
    "    trgSF = np.ones_like(ds['q2'])\n",
    "    trgSFUnc = np.zeros_like(ds['q2'])\n",
    "    if not fastRun:\n",
    "        ptmax = hTriggerSF.GetXaxis().GetXmax() - 0.01\n",
    "        ipmax = hTriggerSF.GetYaxis().GetXmax() - 0.01\n",
    "        etamax = hTriggerSF.GetZaxis().GetXmax() - 0.01\n",
    "        x = np.column_stack((ds['mu_pt'], ds['mu_eta'], ds['mu_sigdxy']))\n",
    "        if not selection is None:\n",
    "            x = x[selection]\n",
    "        for i, (pt, eta, ip) in enumerate(x):\n",
    "            ix = hTriggerSF.GetXaxis().FindBin(min(ptmax, pt))\n",
    "            iy = hTriggerSF.GetYaxis().FindBin(min(ipmax, ip))\n",
    "            iz = hTriggerSF.GetZaxis().FindBin(min(etamax, np.abs(eta)))\n",
    "            trgSF[i] = hTriggerSF.GetBinContent(ix, iy, iz)\n",
    "            ib = hTriggerSF.GetBin(ix, iy, iz)\n",
    "            trgSFUnc[i] = hTriggerSF.GetBinError(ib)\n",
    "            if trgSF[i] == 0:\n",
    "                print pt, ip, np.abs(eta)\n",
    "                raise\n",
    "    # Divide them for the weight so later you can simply multiply back to get the value\n",
    "    up = 1 + trgSFUnc/trgSF\n",
    "    down = 1 - trgSFUnc/trgSF\n",
    "    return trgSF, up, down"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Muon ID scale factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T02:25:59.270513Z",
     "start_time": "2020-05-16T02:25:59.223994Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fMuonIDSF = rt.TFile.Open('../data/calibration/muonIDscaleFactors/Run2018ABCD_SF_MuonID_Jpsi.root', 'READ')\n",
    "hMuonIDSF = fMuonIDSF.Get('NUM_SoftID_DEN_genTracks_pt_abseta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T02:25:59.311921Z",
     "start_time": "2020-05-16T02:25:59.275120Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def computeMuonIDSF(ds, selection=None):\n",
    "    muonSF = np.ones_like(ds['q2'])\n",
    "    muonSFUnc = np.zeros_like(ds['q2'])\n",
    "    if not fastRun:\n",
    "        ptmax = hMuonIDSF.GetXaxis().GetXmax() - 0.01\n",
    "        etamax = hMuonIDSF.GetYaxis().GetXmax() - 0.01\n",
    "        x = np.column_stack((ds['MC_mu_pt'], ds['MC_mu_eta']))\n",
    "        if not selection is None:\n",
    "            x = x[selection]\n",
    "        for i, (pt, eta) in enumerate(x):\n",
    "            ix = hMuonIDSF.GetXaxis().FindBin(min(pt, ptmax))\n",
    "            if ix == 0: ix = 1 #Remove underflows (Meaning that the MC matching failed)\n",
    "            iy = hMuonIDSF.GetYaxis().FindBin(min(np.abs(eta), etamax))\n",
    "            muonSF[i] = hMuonIDSF.GetBinContent(ix, iy)\n",
    "            muonSFUnc[i] = hMuonIDSF.GetBinError(hMuonIDSF.GetBin(ix, iy))\n",
    "            if muonSF[i] == 0:\n",
    "                print pt, eta\n",
    "                print ix, iy\n",
    "                raise\n",
    "    up = 1 + muonSFUnc/muonSF\n",
    "    down = 1 - muonSFUnc/muonSF\n",
    "    return muonSF, up, down"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "B transverse momentum calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T02:25:59.353441Z",
     "start_time": "2020-05-16T02:25:59.316989Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "aux = 'Low' if category == 'single' else cat.name\n",
    "cal_pT = pTCalReader(calibration_file='../data/calibration/B0pTspectrum/pwWeights_{}.txt'.format(aux))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T02:25:59.384495Z",
     "start_time": "2020-05-16T02:25:59.358734Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def computeB0pTweights(ds):\n",
    "    # The denominator (sum of weights) for this weights is not known but it cancel out in the ratio\n",
    "    w = cal_pT.f['C'](ds['MC_B_pt'])\n",
    "    if np.sum(w==0):\n",
    "        print np.sum(w==0)\n",
    "        raise\n",
    "    up = cal_pT.f['Up'](ds['MC_B_pt'])/w\n",
    "    down = cal_pT.f['Down'](ds['MC_B_pt'])/w\n",
    "    return w, up, down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T02:25:59.407970Z",
     "start_time": "2020-05-16T02:25:59.391291Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def computeBrVarWeights(ds, selItems={}, relScale=0.2, keepNorm=False):\n",
    "    sel = np.ones_like(ds['mu_pt']).astype(np.bool)\n",
    "    for var, val in selItems.iteritems():\n",
    "        sel = np.logical_and(ds[var].astype(np.int) == val, sel)\n",
    "    w = np.ones_like(sel)\n",
    "    up = np.where(sel, 1.+relScale, 1.)\n",
    "    down = np.where(sel, max(0, 1.-relScale), 1.)\n",
    "    if keepNorm:\n",
    "        up = float(up.shape[0])/np.sum(up)\n",
    "        down = float(down.shape[0])/np.sum(down)\n",
    "    return w, up, down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T02:25:59.447934Z",
     "start_time": "2020-05-16T02:25:59.413148Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def computeTksPVweights(ds, relScale=0.1, centralVal=0.430/0.117):\n",
    "    selPdgID0 = np.logical_or(np.abs(ds['MC_tkMotherPdgId_0']) < 6, ds['MC_tkMotherPdgId_0']==2212)\n",
    "    selPdgID0 = np.logical_and( selPdgID0, ds['MC_tkFlag_0'] == 1)\n",
    "    selPdgID1 = np.logical_or(np.abs(ds['MC_tkMotherPdgId_1']) < 6, ds['MC_tkMotherPdgId_1']==2212)\n",
    "    selPdgID1 = np.logical_and( selPdgID1, ds['MC_tkFlag_1'] == 1)\n",
    "    exponent = selPdgID0.astype(np.int) + selPdgID1.astype(np.int)\n",
    "    w = np.power(centralVal, exponent)\n",
    "    up = np.power(centralVal*(1+relScale), exponent)/w\n",
    "    down = np.power(centralVal*(1-relScale), exponent)/w\n",
    "    return w, up, down"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create MC histograms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Signal region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T02:25:59.477318Z",
     "start_time": "2020-05-16T02:25:59.452611Z"
    },
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "binning = {\n",
    "    'M2_miss' : [\n",
    "        array('d', [-2.5] + list(np.arange(-1.8, 1.0, 0.4)) + [8] ),\n",
    "        array('d', [-2.5] + list(np.arange(-1.8, 3.0, 0.4)) + [8] ),\n",
    "        array('d', [-2.5] + list(np.arange(-1.8, 5.6, 0.4)) + [8] ),\n",
    "        array('d', [-2.5] + list(np.arange(-1.8, 7.6, 0.4)) + [8] ),\n",
    "    ],\n",
    "    'Est_mu'  : [\n",
    "        array('d', [0.3] + list(np.arange(0.7, 2.3, 0.1)) + [2.5] ),\n",
    "        array('d', [0.3] + list(np.arange(0.7, 2.5, 0.1)) + [2.5] ),\n",
    "        array('d', [0.3] + list(np.arange(0.5, 2.5, 0.1)) + [2.5] ),\n",
    "        [22, 0.3, 2.500],\n",
    "    ],\n",
    "}\n",
    "if fit_real_data:\n",
    "#     binning['q2'] = array('d', [-2, 2.5, 6, 9.4, 12])\n",
    "    binning['q2'] = array('d', [-2, 2.5, 6])\n",
    "else:\n",
    "    binning['q2'] = array('d', [-2, 2.5, 6, 9.4, 12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T02:27:01.110793Z",
     "start_time": "2020-05-16T02:25:59.481971Z"
    },
    "code_folding": [],
    "hide_input": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "histo = {}\n",
    "for n, ds in dSet.iteritems():\n",
    "    if n == 'data': continue\n",
    "    print '\\n----------->', n, '<-------------'\n",
    "    sMC = MCsample[n]\n",
    "    \n",
    "    nTotSelected = ds['q2'].shape[0]\n",
    "    print 'N tot selected: {:.1f}k'.format(1e-3*nTotSelected)\n",
    "    nGenExp = sMC.effMCgen['xsec'][0] * lumi_tot * RDoMC_normRatio[0]\n",
    "    eff = [1, 0]\n",
    "    for f, df in [sMC.effMCgen['effGEN'], decayBR[n], sMC.effCand['effCAND'], sMC.getSkimEff(cat.name+'_corr')]:\n",
    "        eff[0] *= f\n",
    "        eff[1] += np.square(df/f)\n",
    "    eff[1] = eff[0] * np.sqrt(eff[1])\n",
    "    nTotExp = nGenExp*eff[0]\n",
    "    print 'N tot expected (before weights): {:.2f}k'.format(1e-3*nTotExp)\n",
    "    \n",
    "    wVar = {}\n",
    "    weights = {}\n",
    "    \n",
    "    print 'Including pileup reweighting'\n",
    "    weights['pileup'] = getPileupWeights(ds)\n",
    "    print 'Including trigger corrections'\n",
    "    weights['trgSF'], wVar['trgSFUp'], wVar['trgSFDown'] = computeTrgSF(ds)\n",
    "    print 'Including muon ID corrections'\n",
    "    weights['muonIdSF'], wVar['muonIdSFUp'], wVar['muonIdSFDown'] = computeMuonIDSF(ds)\n",
    "    if n in ['mu', 'tau', 'DstmD0', 'DstmDp', 'DstmDsp','DstPi0', 'DstPipPim', 'DstPi0Pi0']: #B0 dominated final states (probably we should do something about B+ too)\n",
    "        print 'Including B0 pT corrections'\n",
    "        weights['B0pT'], wVar['B0pTUp'], wVar['B0pTDown'] = computeB0pTweights(ds)\n",
    "    # Hammer corrections to the FF\n",
    "    if n in ['mu', 'tau']:\n",
    "        print 'Including FF corrections (Hammer)'\n",
    "        weights['B2DstCLN'] = ds['wh_CLNCentral']*sMC.effCand['rate_den']/sMC.effCand['rate_Central']\n",
    "        for nPar in ['R0', 'R1', 'R2', 'RhoSq']:\n",
    "            for var in ['Up', 'Down']:\n",
    "                tag = 'CLN' + nPar + var\n",
    "                wVar['B2Dst'+tag] = ds['wh_'+tag]/sMC.effCand['rate_' + nPar + var]\n",
    "                wVar['B2Dst'+tag] *= sMC.effCand['rate_Central']/ds['wh_CLNCentral']\n",
    "    #Hc mix variations\n",
    "    if n == 'DstmD0':\n",
    "        _, wVar['BrB02DstD0KpUp'], wVar['BrB02DstD0KpDown'] = computeBrVarWeights(ds, {'MC_DstSisterPdgId_heavy': 421, 'MC_DstSisterPdgId_light': 321}, 0.21/2.47) #Gamma 169 pdg 2020\n",
    "        _, wVar['BrB02DstD0KstpUp'], wVar['BrB02DstD0KstpDown'] = computeBrVarWeights(ds, {'MC_DstSisterPdgId_heavy': 421, 'MC_DstSisterPdgId_light': 323}, 0.5) # Guess\n",
    "        _, wVar['BrB02DstDst0KpUp'], wVar['BrB02DstDst0KpDown'] = computeBrVarWeights(ds, {'MC_DstSisterPdgId_heavy': 423, 'MC_DstSisterPdgId_light': 321}, 0.09/1.06) #Gamma 170 pdg 2020\n",
    "        _, wVar['BrB02DstDst0KstpUp'], wVar['BrB02DstDst0KstpDown'] = computeBrVarWeights(ds, {'MC_DstSisterPdgId_heavy': 423, 'MC_DstSisterPdgId_light': 323}, 0.5) # Guess\n",
    "        _, wVar['BrB02DstDstpK0Up'], wVar['BrB02DstDstpK0Down'] = computeBrVarWeights(ds, {'MC_DstSisterPdgId_heavy': 413, 'MC_DstSisterPdgId_light': 311}, 0.5/5.3) #Gamma 173 pdg 2020\n",
    "        _, wVar['BrB02DstDstpKst0Up'], wVar['BrB02DstDstpKst0Down'] = computeBrVarWeights(ds, {'MC_DstSisterPdgId_heavy': 413, 'MC_DstSisterPdgId_light': 313}, 0.5) # Guess\n",
    "    if n == 'DstmDp':\n",
    "        _, wVar['BrB02DstDpK0Up'], wVar['BrB02DstDpK0Down'] = computeBrVarWeights(ds, {'MC_DstSisterPdgId_heavy': 411, 'MC_DstSisterPdgId_light': 311}, 0.5/3.2) #Gamma 172 pdg 2020\n",
    "        _, wVar['BrB02DstDpKst0Up'], wVar['BrB02DstDpKst0Down'] = computeBrVarWeights(ds, {'MC_DstSisterPdgId_heavy': 411, 'MC_DstSisterPdgId_light': 313}, 0.5) # Guess\n",
    "        _, wVar['BrB02DstDstpK0Up'], wVar['BrB02DstDstpK0Down'] = computeBrVarWeights(ds, {'MC_DstSisterPdgId_heavy': 413, 'MC_DstSisterPdgId_light': 311}, 0.2/2.7) #Gamma 173 pdg 2020\n",
    "        _, wVar['BrB02DstDstpKst0Up'], wVar['BrB02DstDstpKst0Down'] = computeBrVarWeights(ds, {'MC_DstSisterPdgId_heavy': 413, 'MC_DstSisterPdgId_light': 313}, 0.5) # Guess\n",
    "    if n == 'DstmDsp':\n",
    "        _, wVar['BrB02DstDsUp'], wVar['BrB02DstDsDown'] = computeBrVarWeights(ds, {'MC_DstSisterPdgId_heavy': 431}, 1.1/8.0) #Gamma 83 pdg 2020\n",
    "        _, wVar['BrB02DstDsstUp'], wVar['BrB02DstDsstDown'] = computeBrVarWeights(ds, {'MC_DstSisterPdgId_heavy': 433}, .14/1.77) #Gamma 85 pdg 2020\n",
    "        _, wVar['BrB02DstDs0stUp'], wVar['BrB02DstDs0stDown'] = computeBrVarWeights(ds, {'MC_DstSisterPdgId_heavy': 10431}, .6/1.5) #Gamma 95 pdg 2020\n",
    "    \n",
    "    print 'Computing total weights'\n",
    "    weightsCentral = np.ones_like(ds['q2'])\n",
    "    for w in weights.values(): weightsCentral *= w\n",
    "    print 'N tot expected (after weights): {:.2f}k'.format(1e-3*nTotExp*np.sum(weightsCentral)/nTotSelected)\n",
    "    wVar[''] = np.ones_like(weightsCentral)\n",
    "    \n",
    "    for i_q2 in range(len(binning['q2'])-1):\n",
    "        q2_l = binning['q2'][i_q2]\n",
    "        q2_h = binning['q2'][i_q2 + 1]\n",
    "        sel_q2 = np.logical_and(ds['q2'] > q2_l, ds['q2'] < q2_h)\n",
    "        for var in ['M2_miss', 'Est_mu']:\n",
    "            cat_name = var+'_q2bin'+str(i_q2)\n",
    "            \n",
    "            if not cat_name in histo.keys():\n",
    "                histo[cat_name] = {}\n",
    "            \n",
    "            for name_wVar, v_wVar in wVar.iteritems():\n",
    "                h_name = n\n",
    "                if not name_wVar == '':\n",
    "                    h_name += '__' + name_wVar\n",
    "                w = weightsCentral*v_wVar\n",
    "                scale = nTotExp/nTotSelected\n",
    "                histo[cat_name][h_name] = create_TH1D(\n",
    "                                                      ds[var][sel_q2], \n",
    "                                                      name=h_name, title=h_name, \n",
    "                                                      binning=binning[var][i_q2], \n",
    "                                                      opt='underflow,overflow',\n",
    "                                                      weights=w[sel_q2], scale_histo=scale,\n",
    "                                                      )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single track side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T02:27:01.204294Z",
     "start_time": "2020-05-16T02:27:01.116366Z"
    }
   },
   "outputs": [],
   "source": [
    "sideSelecton = {}\n",
    "sideVar = {}\n",
    "sideXtitle = {}\n",
    "sideAddtext = {}\n",
    "\n",
    "def selfun__TkPlus(ds):\n",
    "    sel = np.logical_and(ds['N_goodAddTks'] == 1, ds['tkCharge_0'] > 0)\n",
    "    return sel\n",
    "#     return np.logical_and(np.abs(ds['tkMassHad_0'] - 2.43) < 0.3, sel)\n",
    "sideSelecton['AddTk_p_mHad'] = selfun__TkPlus\n",
    "sideVar['AddTk_p_mHad'] = 'tkMassHad_0'\n",
    "binning['AddTk_p_mHad'] = [35, 2.13, 2.83]\n",
    "sideXtitle['AddTk_p_mHad'] = 'Total hadrons mass'\n",
    "sideAddtext['AddTk_p_mHad'] = 'N_{tk} = 1 & Q_{tk} = +1'\n",
    "\n",
    "def selfun__TkMinus(ds):\n",
    "    sel = np.logical_and(ds['N_goodAddTks'] == 1, ds['tkCharge_0'] < 0)\n",
    "    return sel\n",
    "sideSelecton['AddTk_m_mHad'] = selfun__TkMinus\n",
    "sideVar['AddTk_m_mHad'] = 'tkMassHad_0'\n",
    "binning['AddTk_m_mHad'] = [30, 2.1, 3.3]\n",
    "sideXtitle['AddTk_m_mHad'] = 'Total hadrons mass'\n",
    "sideAddtext['AddTk_m_mHad'] = 'N_{tk} = 1 & Q_{tk} = -1'\n",
    "\n",
    "# sideSelecton['AddTk_m_tkPt'] = selfun__TkMinus\n",
    "# sideVar['AddTk_m_tkPt'] = 'tkPt_0'\n",
    "# binning['AddTk_m_tkPt'] = np.logspace(np.log10(0.5), np.log10(5.0), 30)\n",
    "# sideXtitle['AddTk_m_tkPt'] = 'Additional track p_{T}'\n",
    "# sideAddtext['AddTk_m_tkPt'] = 'N_{tk} = 1 & Q_{tk} = -1'\n",
    "\n",
    "\n",
    "def selfun__TkPlusMinus(ds):\n",
    "    sel = np.logical_and(ds['tkCharge_0']+ds['tkCharge_1'] == 0, ds['N_goodAddTks'] == 2)\n",
    "    sel = np.logical_and(ds['tkMassVis12'] < 5.3, sel)\n",
    "    return sel\n",
    "sideSelecton['AddTk_pm_mVis'] = selfun__TkPlusMinus\n",
    "sideVar['AddTk_pm_mVis'] = 'tkMassVis12'\n",
    "binning['AddTk_pm_mVis'] = array('d', [2.8] + list(np.arange(3., 5.3, 0.1)) + [5.3] )\n",
    "sideXtitle['AddTk_pm_mVis'] = 'Total visible mass'\n",
    "sideAddtext['AddTk_pm_mVis'] = 'N_{tk} = 2 & #sumQ_{tk} = 0'\n",
    "\n",
    "\n",
    "sideSelecton['AddTk_pm_mHad'] = selfun__TkPlusMinus\n",
    "sideVar['AddTk_pm_mHad'] = 'tkMassHad12'\n",
    "binning['AddTk_pm_mHad'] = [30, 2.25, 3.75]\n",
    "sideXtitle['AddTk_pm_mHad'] = 'Total hadrons mass'\n",
    "sideAddtext['AddTk_pm_mHad'] = 'N_{tk} = 2 & #sumQ_{tk} = 0'\n",
    "\n",
    "def selfun__TkMinusMinus(ds):\n",
    "    sel = np.logical_and(ds['tkCharge_0']+ds['tkCharge_1'] == -2, ds['N_goodAddTks'] == 2)\n",
    "    sel = np.logical_and(ds['tkMassVis12'] < 5.3, sel)\n",
    "    return sel\n",
    "sideSelecton['AddTk_mm_mHad'] = selfun__TkMinusMinus\n",
    "sideVar['AddTk_mm_mHad'] = 'tkMassHad12'\n",
    "binning['AddTk_mm_mHad'] = [15, 2.25, 3.6]\n",
    "sideXtitle['AddTk_mm_mHad'] = 'Total hadrons mass'\n",
    "sideAddtext['AddTk_mm_mHad'] = 'N_{tk} = 2 & #sumQ_{tk} = -2'\n",
    "\n",
    "def selfun__TkPlusPlus(ds):\n",
    "    sel = np.logical_and(ds['tkCharge_0']+ds['tkCharge_1'] == +2, ds['N_goodAddTks'] == 2)\n",
    "    sel = np.logical_and(ds['tkMassVis12'] < 5.3, sel)\n",
    "    return sel\n",
    "sideSelecton['AddTk_pp_mHad'] = selfun__TkPlusPlus\n",
    "sideVar['AddTk_pp_mHad'] = 'tkMassHad12'\n",
    "binning['AddTk_pp_mHad'] = [15, 2.25, 3.75]\n",
    "sideXtitle['AddTk_pp_mHad'] = 'Total hadrons mass'\n",
    "sideAddtext['AddTk_pp_mHad'] = 'N_{tk} = 2 & #sumQ_{tk} = +2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T02:27:19.501832Z",
     "start_time": "2020-05-16T02:27:01.208971Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for k in sideSelecton.keys():\n",
    "    histo[k] = {}\n",
    "\n",
    "for n, ds in dSetTkSide.iteritems():\n",
    "    if n == 'data': continue\n",
    "    print '\\n----------->', n, '<-------------'\n",
    "    sMC = MCsample[n]    \n",
    "    wVar = {}\n",
    "    weights = {}\n",
    "    \n",
    "    print 'Including pileup reweighting'\n",
    "    weights['pileup'] = getPileupWeights(ds)\n",
    "    print 'Including trigger corrections'\n",
    "    weights['trgSF'], wVar['trgSFUp'], wVar['trgSFDown'] = computeTrgSF(ds)\n",
    "    print 'Including muon ID corrections'\n",
    "    weights['muonIdSF'], wVar['muonIdSFUp'], wVar['muonIdSFDown'] = computeMuonIDSF(ds)\n",
    "    if n in ['mu', 'tau', 'DstmD0', 'DstmDp', 'DstmDsp','DstPi0', 'DstPipPim', 'DstPi0Pi0']: #B0 dominated final states (probably we should do something about B+ too)\n",
    "        print 'Including B0 pT corrections'\n",
    "        weights['B0pT'], wVar['B0pTUp'], wVar['B0pTDown'] = computeB0pTweights(ds)\n",
    "    # Hammer corrections to the FF\n",
    "    if n in ['mu', 'tau']:\n",
    "        print 'Including FF corrections (Hammer)'\n",
    "        weights['B2DstCLN'] = ds['wh_CLNCentral']*sMC.effCand['rate_den']/sMC.effCand['rate_Central']\n",
    "        for nPar in ['R0', 'R1', 'R2', 'RhoSq']:\n",
    "            for var in ['Up', 'Down']:\n",
    "                tag = 'CLN' + nPar + var\n",
    "                wVar['B2Dst'+tag] = ds['wh_'+tag]/sMC.effCand['rate_' + nPar + var]\n",
    "                wVar['B2Dst'+tag] *= sMC.effCand['rate_Central']/ds['wh_CLNCentral']\n",
    "    #Hc mix variations\n",
    "    if n == 'DstmD0':\n",
    "        _, wVar['BrB02DstD0KpUp'], wVar['BrB02DstD0KpDown'] = computeBrVarWeights(ds, {'MC_DstSisterPdgId_heavy': 421, 'MC_DstSisterPdgId_light': 321}, 0.21/2.47) #Gamma 169 pdg 2020\n",
    "        _, wVar['BrB02DstD0KstpUp'], wVar['BrB02DstD0KstpDown'] = computeBrVarWeights(ds, {'MC_DstSisterPdgId_heavy': 421, 'MC_DstSisterPdgId_light': 323}, 0.5) # Guess\n",
    "        _, wVar['BrB02DstDst0KpUp'], wVar['BrB02DstDst0KpDown'] = computeBrVarWeights(ds, {'MC_DstSisterPdgId_heavy': 423, 'MC_DstSisterPdgId_light': 321}, 0.09/1.06) #Gamma 170 pdg 2020\n",
    "        _, wVar['BrB02DstDst0KstpUp'], wVar['BrB02DstDst0KstpDown'] = computeBrVarWeights(ds, {'MC_DstSisterPdgId_heavy': 423, 'MC_DstSisterPdgId_light': 323}, 0.5) # Guess\n",
    "        _, wVar['BrB02DstDstpK0Up'], wVar['BrB02DstDstpK0Down'] = computeBrVarWeights(ds, {'MC_DstSisterPdgId_heavy': 413, 'MC_DstSisterPdgId_light': 311}, 0.5/5.3) #Gamma 173 pdg 2020\n",
    "        _, wVar['BrB02DstDstpKst0Up'], wVar['BrB02DstDstpKst0Down'] = computeBrVarWeights(ds, {'MC_DstSisterPdgId_heavy': 413, 'MC_DstSisterPdgId_light': 313}, 0.5) # Guess\n",
    "    if n == 'DstmDp':\n",
    "        _, wVar['BrB02DstDpK0Up'], wVar['BrB02DstDpK0Down'] = computeBrVarWeights(ds, {'MC_DstSisterPdgId_heavy': 411, 'MC_DstSisterPdgId_light': 311}, 0.5/3.2) #Gamma 172 pdg 2020\n",
    "        _, wVar['BrB02DstDpKst0Up'], wVar['BrB02DstDpKst0Down'] = computeBrVarWeights(ds, {'MC_DstSisterPdgId_heavy': 411, 'MC_DstSisterPdgId_light': 313}, 0.5) # Guess\n",
    "        _, wVar['BrB02DstDstpK0Up'], wVar['BrB02DstDstpK0Down'] = computeBrVarWeights(ds, {'MC_DstSisterPdgId_heavy': 413, 'MC_DstSisterPdgId_light': 311}, 0.2/2.7) #Gamma 173 pdg 2020\n",
    "        _, wVar['BrB02DstDstpKst0Up'], wVar['BrB02DstDstpKst0Down'] = computeBrVarWeights(ds, {'MC_DstSisterPdgId_heavy': 413, 'MC_DstSisterPdgId_light': 313}, 0.5) # Guess\n",
    "    if n == 'DstmDsp':\n",
    "        _, wVar['BrB02DstDsUp'], wVar['BrB02DstDsDown'] = computeBrVarWeights(ds, {'MC_DstSisterPdgId_heavy': 431}, 1.1/8.0) #Gamma 83 pdg 2020\n",
    "        _, wVar['BrB02DstDsstUp'], wVar['BrB02DstDsstDown'] = computeBrVarWeights(ds, {'MC_DstSisterPdgId_heavy': 433}, .14/1.77) #Gamma 85 pdg 2020\n",
    "        _, wVar['BrB02DstDs0stUp'], wVar['BrB02DstDs0stDown'] = computeBrVarWeights(ds, {'MC_DstSisterPdgId_heavy': 10431}, .6/1.5) #Gamma 95 pdg 2020\n",
    "        \n",
    "    # Correct the amount of random tracks from PV\n",
    "    weights['tkPVfrac'], wVar['tkPVfracUp'], wVar['tkPVfracDown'] = computeTksPVweights(ds)\n",
    "    \n",
    "    print 'Computing total weights'\n",
    "    weightsCentral = np.ones_like(ds['q2'])\n",
    "    for w in weights.values(): \n",
    "        weightsCentral *= w\n",
    "    wVar[''] = np.ones_like(weightsCentral)\n",
    "    \n",
    "    nGenExp = sMC.effMCgen['xsec'][0] * lumi_tot * RDoMC_normRatio[0]\n",
    "    eff = [1, 0]\n",
    "    for f, df in [sMC.effMCgen['effGEN'], \n",
    "                  decayBR[n], \n",
    "                  sMC.effCand['effCAND'], \n",
    "                  sMC.getSkimEff(cat.name+'_trkCtrl_corr'),\n",
    "                 ]:\n",
    "        eff[0] *= f\n",
    "        eff[1] += np.square(df/f)\n",
    "    eff[1] = eff[0] * np.sqrt(eff[1])\n",
    "    nTotExp = nGenExp*eff[0]\n",
    "    \n",
    "    sel = {}\n",
    "    scale = {}\n",
    "    \n",
    "    for k, selFun in sideSelecton.iteritems():\n",
    "        sel[k] = selFun(ds)\n",
    "        nTotSel = float(np.sum(sel[k]))\n",
    "        print 'N tot selected {}: {:.0f}'.format(k, nTotSel)\n",
    "        nExp = nTotExp * nTotSel / sel[k].shape[0]\n",
    "        print 'N tot expected {} (before weights): {:.0f}'.format(k, nExp)\n",
    "        nAux = nTotExp * np.sum(weightsCentral[sel[k]]) / sel[k].shape[0]\n",
    "        print 'N tot expected {} (after weights): {:.0f}'.format(k, nAux)\n",
    "        scale[k] = nExp/nTotSel\n",
    "    \n",
    "            \n",
    "    for name_wVar, v_wVar in wVar.iteritems():\n",
    "        h_name = n\n",
    "        if not name_wVar == '':\n",
    "            h_name += '__' + name_wVar\n",
    "        w = weightsCentral*v_wVar\n",
    "        \n",
    "        for k in sideVar.keys():\n",
    "            histo[k][h_name] = create_TH1D(\n",
    "                                           ds[sideVar[k]][sel[k]], \n",
    "                                           name=h_name, title=h_name, \n",
    "                                           binning=binning[k],\n",
    "                                           opt='underflow',\n",
    "                                           weights=w[sel[k]], scale_histo=scale[k]\n",
    "                                          )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Create (pseudo-)data histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T02:27:19.709284Z",
     "start_time": "2020-05-16T02:27:19.506059Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "if fit_real_data:\n",
    "    ds = dSet['data']\n",
    "    print 'N observed data: {:.1f}k'.format(1e-3*ds['q2'].shape[0])\n",
    "    for i_q2 in range(len(binning['q2'])-1):\n",
    "        q2_l = binning['q2'][i_q2]\n",
    "        q2_h = binning['q2'][i_q2 + 1]\n",
    "        sel_q2 = np.logical_and(ds['q2'] > q2_l, ds['q2'] < q2_h)\n",
    "        for var in ['M2_miss', 'Est_mu']:\n",
    "            cat_name = var+'_q2bin'+str(i_q2)     \n",
    "            histo[cat_name]['data'] = create_TH1D(\n",
    "                                                  ds[var][sel_q2], \n",
    "                                                  name='data_obs', title='Data Obs',\n",
    "                                                  binning=binning[var][i_q2],\n",
    "                                                  opt='underflow,overflow'\n",
    "                                                 )\n",
    "    ds = dSetTkSide['data']\n",
    "    for k in sideVar.keys():\n",
    "        histo[k]['data'] = create_TH1D(\n",
    "                                       ds[sideVar[k]][sideSelecton[k](ds)], \n",
    "                                       name='data_obs', title='Data Obs', \n",
    "                                       binning=binning[k],\n",
    "                                       opt='underflow',\n",
    "                                      )\n",
    "        \n",
    "else:\n",
    "    for i_q2 in range(len(binning['q2'])-1):\n",
    "        for var in ['M2_miss', 'Est_mu']:\n",
    "            cat_name = var+'_q2bin'+str(i_q2)\n",
    "            \n",
    "            h = create_TH1D(np.array([0, 0]), name='data_obs', title='Data Obs', binning=binning[var][i_q2])\n",
    "            h.Reset()\n",
    "            for n, hMC in histo[cat_name].iteritems():\n",
    "                if not '__' in n and not n == 'data':\n",
    "                    scale = SM_RDst if 'tau' in n else 1.\n",
    "                    h.Add(hMC, scale)\n",
    "            h.Sumw2(0)\n",
    "            for i in range(1, h.GetNbinsX()+1):\n",
    "                h.SetBinContent(i, np.around(h.GetBinContent(i)))\n",
    "            h.Sumw2()\n",
    "            histo[cat_name]['data'] = h\n",
    "            \n",
    "    for k in sideVar.keys():\n",
    "        h = create_TH1D(np.array([0, 0]), name='data_obs', title='Data Obs', \n",
    "                        binning=binning[k])\n",
    "        h.Reset()\n",
    "        for n, hMC in histo[k].iteritems():\n",
    "            if not '__' in n and not n == 'data':\n",
    "                scale = SM_RDst if 'tau' in n else 1.\n",
    "                h.Add(hMC, scale)\n",
    "        h.Sumw2(0)\n",
    "        for i in range(1, h.GetNbinsX()+1):\n",
    "            h.SetBinContent(i, np.around(h.GetBinContent(i)))\n",
    "        h.Sumw2()\n",
    "        histo[k]['data'] = h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T02:27:20.374476Z",
     "start_time": "2020-05-16T02:27:19.713775Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "CMS_lumi.integrated_lumi = lumi_tot\n",
    "scale_dic = {'tau': SM_RDst\n",
    "            }\n",
    "\n",
    "cSigPre = plot_gridVarQ2(CMS_lumi, binning, histo, scale_dic=scale_dic, min_y=1, logy=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T02:27:20.691753Z",
     "start_time": "2020-05-16T02:27:20.380032Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cSidePre = {}\n",
    "for k in np.sort(sideVar.keys()):\n",
    "    legLoc = [0.65, 0.4, 0.9, 0.7]\n",
    "    if 'MassVis' in sideVar[k]:\n",
    "        legLoc = [0.15, 0.45, 0.35, 0.75]\n",
    "    cSidePre[k] = plot_SingleCategory(CMS_lumi, histo[k], scale_dic=scale_dic,\n",
    "                                      xtitle=sideXtitle[k], addText=sideAddtext[k], \n",
    "                                      tag=k, legLoc=legLoc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T02:27:21.344046Z",
     "start_time": "2020-05-16T02:27:20.696311Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "histo_file_dir = '../data/_root/histos4combine/'\n",
    "if not os.path.isdir(histo_file_dir):\n",
    "    os.makedirs(histo_file_dir)\n",
    "histo_file_loc = {}\n",
    "for cat_name, h_dic in histo.iteritems():\n",
    "    histo_file_loc[cat_name] = histo_file_dir+'{}_{}.root'.format(card_name, cat_name)\n",
    "    tf = rt.TFile(histo_file_loc[cat_name], 'recreate')\n",
    "    for v in h_dic.values():\n",
    "        v.Write()\n",
    "    tf.Close()\n",
    "    \n",
    "del dSet, dSetTkSide"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Write the card"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T02:27:21.463701Z",
     "start_time": "2020-05-16T02:27:21.349056Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sig_processes = ['tau', 'mu']\n",
    "bkg_processes = ['DstmD0', 'DstmDp', 'DstmDsp', 'DstPip', 'DstPipPi0', 'DstPi0', 'DstPipPim', 'DstPi0Pi0']\n",
    "processes = sig_processes + bkg_processes\n",
    "nProc = len(processes)\n",
    "categories = np.sort([k for k in histo.keys()])\n",
    "nCat = len(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T02:27:21.535597Z",
     "start_time": "2020-05-16T02:27:21.468377Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# number of different categories\n",
    "card = 'imax *\\n'\n",
    "# number of processes minus one\n",
    "card += 'jmax {}\\n'.format(len(processes)-1)\n",
    "# number of nuissance parameters\n",
    "card += 'kmax *\\n'\n",
    "card += '--------------------------------------------------------------\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T02:27:21.566081Z",
     "start_time": "2020-05-16T02:27:21.540031Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# shape file location\n",
    "for k in categories:\n",
    "    card += 'shapes * {} {} $PROCESS $PROCESS__$SYSTEMATIC\\n'.format(k, histo_file_loc[k])\n",
    "card += '--------------------------------------------------------------\\n'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Number of events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T02:27:21.626476Z",
     "start_time": "2020-05-16T02:27:21.570538Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# number of events observed\n",
    "card += 'bin ' + ' '.join(categories) + '\\n'\n",
    "obs = map(lambda k: '{:.0f}'.format(histo[k]['data'].Integral()), categories)\n",
    "obs = ' '.join(obs)\n",
    "card += 'observation ' + obs + '\\n'\n",
    "card += '--------------------------------------------------------------\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T02:27:21.669738Z",
     "start_time": "2020-05-16T02:27:21.632137Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# MC expected events\n",
    "aux_bin = ''\n",
    "aux_proc_name = ''\n",
    "aux_proc_id = ''\n",
    "aux_proc_rate = ''\n",
    "for c, p in itertools.product(categories, processes):\n",
    "    aux_bin += ' '+c\n",
    "    aux_proc_name += ' '+p\n",
    "    aux_proc_id += ' '+str(np.argmax(np.array(processes) == p))\n",
    "    aux_proc_rate += ' {:.2f}'.format(histo[c][p].Integral())\n",
    "    \n",
    "card += 'bin' + aux_bin + '\\n'\n",
    "card += 'process' + aux_proc_name + '\\n'\n",
    "# Zero or negative for sig and positive for bkg\n",
    "card += 'process' + aux_proc_id + '\\n'\n",
    "# Expected rate\n",
    "card += 'rate' + aux_proc_rate + '\\n'\n",
    "card += '--------------------------------------------------------------\\n'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Systematic uncertainties"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Scale systematics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T02:27:21.699726Z",
     "start_time": "2020-05-16T02:27:21.674134Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#pp -> bb cros-section * luminosity\n",
    "card += 'xsecpp2bbXlumi lnN' + ' 1.9'*nProc*nCat + '\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T02:27:21.730847Z",
     "start_time": "2020-05-16T02:27:21.704038Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Hadronization fraction of B0\n",
    "aux = ''\n",
    "for n in processes:\n",
    "    if n in ['tau', 'mu', 'DstmD0', 'DstmDp', 'DstmDsp', 'DstPi0', 'DstPipPim', 'DstPi0Pi0']: aux += ' 3'\n",
    "    else: aux += ' -'\n",
    "card += 'b2B0Had lnN' + aux*nCat + '\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T02:27:21.760117Z",
     "start_time": "2020-05-16T02:27:21.735504Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Hadronization fraction of B+\n",
    "aux = ''\n",
    "for n in processes:\n",
    "    if n in ['DstPip', 'DstPipPi0']: aux += ' 3'\n",
    "    else: aux += ' -'\n",
    "card += 'b2BpHad lnN' + aux*nCat + '\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T02:27:21.813268Z",
     "start_time": "2020-05-16T02:27:21.764821Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Selection efficiencies\n",
    "for n in processes:\n",
    "    if n == 'tau': continue\n",
    "    val = ' {:.2f}'.format(1+decayBR[n][1]/decayBR[n][0])\n",
    "    aux = ''\n",
    "    for nn in processes:\n",
    "        if nn == n: aux += val\n",
    "        else: aux += ' -'\n",
    "    card += n + 'Br lnN' + aux*nCat + '\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T02:27:21.852957Z",
     "start_time": "2020-05-16T02:27:21.817683Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "card += '--------------------------------------------------------------\\n'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Rate parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T02:27:21.891120Z",
     "start_time": "2020-05-16T02:27:21.857266Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "card += 'pAddTk param 1.0 0.15\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T02:27:21.967328Z",
     "start_time": "2020-05-16T02:27:21.895407Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "linear = []\n",
    "quadratic = []\n",
    "\n",
    "for procAux in ['tau', 'mu', 'DstPi0', 'DstPi0Pi0']: \n",
    "    linear.append(['AddTk_p_mHad', procAux])\n",
    "    \n",
    "for procAux in ['tau', 'mu', 'DstPi0', 'DstPi0Pi0', 'DstPip', 'DstPipPi0']: \n",
    "    linear.append(['AddTk_m_mHad', procAux])\n",
    "    \n",
    "for procAux in ['DstPip', 'DstPipPi0', 'DstPipPim', 'DstmD0', 'DstmDp', 'DstmDsp']:\n",
    "    linear.append(['AddTk_pp_mHad', procAux])\n",
    "for procAux in ['tau', 'mu', 'DstPi0', 'DstPi0Pi0']:\n",
    "    quadratic.append(['AddTk_pp_mHad', procAux])\n",
    "    \n",
    "\n",
    "for procAux in ['DstPip', 'DstPipPi0']:\n",
    "    linear.append(['AddTk_pm_mHad', procAux])\n",
    "    linear.append(['AddTk_pm_mVis', procAux])\n",
    "for procAux in ['tau', 'mu', 'DstPi0', 'DstPi0Pi0']:\n",
    "    quadratic.append(['AddTk_pm_mHad', procAux])\n",
    "    quadratic.append(['AddTk_pm_mVis', procAux])\n",
    "    \n",
    "for procAux in ['DstPipPim', 'DstmD0', 'DstmDp', 'DstmDsp']:\n",
    "    linear.append(['AddTk_mm_mHad', procAux])\n",
    "for procAux in ['tau', 'mu', 'DstPi0', 'DstPi0Pi0', 'DstPip', 'DstPipPi0']:\n",
    "    quadratic.append(['AddTk_mm_mHad', procAux])\n",
    "    \n",
    "for binAux, procAux in linear:\n",
    "    card += 'pAddTk rateParam {} {} 1\\n'.format(binAux, procAux)\n",
    "for binAux, procAux in quadratic:\n",
    "    card += 'pAddTk2 rateParam {} {} @0*@0 pAddTk\\n'.format(binAux, procAux)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T02:27:21.996144Z",
     "start_time": "2020-05-16T02:27:21.971766Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "card += '--------------------------------------------------------------\\n'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Shape Systematics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T02:27:22.023895Z",
     "start_time": "2020-05-16T02:27:21.999463Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "card += 'trgSF shape' + ' 1.'*nProc*nCat + '\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T02:27:22.082842Z",
     "start_time": "2020-05-16T02:27:22.027289Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "card += 'muonIdSF shape' + ' 1.'*nProc*nCat + '\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T02:27:22.121533Z",
     "start_time": "2020-05-16T02:27:22.087126Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "aux = ''\n",
    "for cat in categories:\n",
    "    if cat.startswith('AddTk_'):\n",
    "        aux += ' 1.'*nProc\n",
    "    else: aux += ' -'*nProc\n",
    "card += 'tkPVfrac shape' + aux + '\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T02:27:22.172730Z",
     "start_time": "2020-05-16T02:27:22.124945Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# B0 pT spectrum\n",
    "aux = ''\n",
    "for p in processes:\n",
    "    if p in ['tau', 'mu', 'DstmD0', 'DstmDp', 'DstmDsp', 'DstPi0', 'DstPipPim', 'DstPi0Pi0']:\n",
    "        aux += ' 1.'\n",
    "    else:\n",
    "        aux += ' -'\n",
    "card += 'B0pT shape' + aux*nCat + '\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T02:27:22.242495Z",
     "start_time": "2020-05-16T02:27:22.177029Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Form Factors from Hammer\n",
    "for n_pFF in ['R0', 'R1', 'R2', 'RhoSq']:\n",
    "    aux = ''\n",
    "    for p in processes:\n",
    "        if p in ['tau', 'mu']:\n",
    "            aux += ' 1.'\n",
    "        else:\n",
    "            aux += ' -'\n",
    "    card += 'B2DstCLN{} shape'.format(n_pFF) + aux*nCat + '\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T02:27:22.272561Z",
     "start_time": "2020-05-16T02:27:22.247195Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Hc mix composition\n",
    "aux = ''\n",
    "for p in processes:\n",
    "    if p == 'DstmD0': aux += ' 1.'\n",
    "    else: aux += ' -'\n",
    "card += 'BrB02DstD0Kp shape' + aux*nCat + '\\n'\n",
    "card += 'BrB02DstD0Kstp shape' + aux*nCat + '\\n'\n",
    "card += 'BrB02DstDst0Kp shape' + aux*nCat + '\\n'\n",
    "card += 'BrB02DstDst0Kstp shape' + aux*nCat + '\\n'\n",
    "\n",
    "aux = ''\n",
    "for p in processes:\n",
    "    if p == 'DstmDp': aux += ' 1.'\n",
    "    else: aux += ' -'\n",
    "card += 'BrB02DstDpK0 shape' + aux*nCat + '\\n'\n",
    "card += 'BrB02DstDpKst0 shape' + aux*nCat + '\\n'\n",
    "\n",
    "aux = ''\n",
    "for p in processes:\n",
    "    if p == 'DstmDp' or p == 'DstmD0': aux += ' 1.'\n",
    "    else: aux += ' -'\n",
    "card += 'BrB02DstDstpK0 shape' + aux*nCat + '\\n'\n",
    "card += 'BrB02DstDstpKst0 shape' + aux*nCat + '\\n'\n",
    "\n",
    "aux = ''\n",
    "for p in processes:\n",
    "    if p == 'DstmDsp': aux += ' 1.'\n",
    "    else: aux += ' -'\n",
    "card += 'BrB02DstDs shape' + aux*nCat + '\\n'\n",
    "card += 'BrB02DstDsst shape' + aux*nCat + '\\n'\n",
    "card += 'BrB02DstDs0st shape' + aux*nCat + '\\n'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### MC statistic systematics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T02:27:22.343026Z",
     "start_time": "2020-05-16T02:27:22.276771Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# card += '* autoMCStats 0 1 1\\n'\n",
    "card += '* autoMCStats 20 1 1\\n'\n",
    "card += '--------------------------------------------------------------\\n'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Defining groups of systematics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T02:27:22.384464Z",
     "start_time": "2020-05-16T02:27:22.346326Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# autoMCStats group = defined by default when using autoMCStats\n",
    "aux_FF = ' '.join(['B2DstCLN'+n for n in ['R0', 'R1', 'R2', 'RhoSq']])\n",
    "card += 'B2DstFF group = ' + aux_FF + '\\n'\n",
    "\n",
    "card += 'normMC group = xsecpp2bbXlumi b2B0Had b2BpHad\\n'\n",
    "\n",
    "card += 'knownBr group = ' + ' '.join([n+'Br' for n in processes if not n == 'tau']) + '\\n'\n",
    "\n",
    "card += 'allShape group = trgSF muonIdSF B0pT ' + aux_FF + '\\n'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Create output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T02:27:22.455960Z",
     "start_time": "2020-05-16T02:27:22.389172Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print card"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T02:27:22.495274Z",
     "start_time": "2020-05-16T02:27:22.460401Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "card_location = 'cards/{}.txt'.format(card_name)\n",
    "fc = open(card_location, 'w')\n",
    "fc.write(card)\n",
    "fc.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T02:27:22.631897Z",
     "start_time": "2020-05-16T02:27:22.498530Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "outdir = 'results/' + card_name\n",
    "if os.path.isdir(outdir):\n",
    "    os.system('rm -rf ' + outdir)\n",
    "os.system('mkdir -p ' + outdir + '/fig');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Combine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T02:27:35.139940Z",
     "start_time": "2020-05-16T02:27:22.638134Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cmd = 'text2workspace.py ' + card_location \n",
    "cmd += ' -o ' + card_location.replace('.txt', '.root')\n",
    "cmd += ' --no-b-only'\n",
    "cmd += ' --verbose 1'\n",
    "# cmd += ' --no-wrappers'\n",
    "os.system(cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the Maximum Likelyhood fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T02:27:35.151765Z",
     "start_time": "2020-05-16T02:27:35.145343Z"
    }
   },
   "outputs": [],
   "source": [
    "seedMLf = '6741'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T02:36:47.243873Z",
     "start_time": "2020-05-16T02:27:35.156214Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cmd = 'combine -M FitDiagnostics'\n",
    "cmd += ' --robustFit 1 --robustHesse 1 --cminDefaultMinimizerStrategy 0 --X-rtd MINIMIZER_analytic'\n",
    "cmd += ' --skipBOnlyFit'\n",
    "cmd += ' --seed ' + seedMLf\n",
    "cmd += ' -d ' + card_location.replace('.txt', '.root')\n",
    "cmd += ' -D ' + histo[histo.keys()[0]]['data'].GetName()\n",
    "cmd += ' --setParameters r={:.2f}'.format(SM_RDst)\n",
    "cmd += ' --setParameterRanges r=0.01,5'\n",
    "cmd += ' -n {}'.format(card_name)\n",
    "cmd += ' --out ' + outdir\n",
    "cmd += ' --saveShapes --saveWithUncertainties --saveNormalizations'\n",
    "cmd += ' --plots'\n",
    "cmd += ' --verbose 1'\n",
    "\n",
    "print cmd\n",
    "status, output = commands.getstatusoutput(cmd)\n",
    "for line in output.split('\\n'):\n",
    "        if 'ERROR' in line: print line.replace('ERROR', '\\033[1m\\x1b[31mError\\x1b[0m')\n",
    "os.system('mv combine_logger.out ' + outdir + '/combine_logger_FitDiagnostics.out')\n",
    "os.system('mv ./higgsCombine{}.FitDiagnostics.mH120.{}.root '.format(card_name, seedMLf) + outdir + '/');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T02:36:47.308795Z",
     "start_time": "2020-05-16T02:36:47.249846Z"
    }
   },
   "outputs": [],
   "source": [
    "f = ur.open(glob(outdir + '/higgsCombine{}.FitDiagnostics.mH120.{}.root'.format(card_name, seedMLf))[0])\n",
    "c, d, u, _ = f['limit']['limit'].array()\n",
    "print 'R(D*) = {:.3f} +{:.3f}/-{:.3f} [{:.1f} %]'.format(c, u-c, c-d, 100*(u-d)*0.5/c)\n",
    "rDst_postFitRegion = [max(0.01,c - 5*(c-d)), min(c + 5*(u-c), 0.9)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T02:36:47.451341Z",
     "start_time": "2020-05-16T02:36:47.312584Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Get post-fit shapes\n",
    "fFitDiagnostics = rt.TFile.Open(outdir + '/fitDiagnostics{}.root'.format(card_name), 'READ')\n",
    "fd = fFitDiagnostics.shapes_fit_s\n",
    "\n",
    "histo_postfit = {}\n",
    "for cat, h_dic in histo.iteritems():\n",
    "    histo_postfit[cat] = {}\n",
    "    for n, h in h_dic.iteritems():\n",
    "        if '__' in n:\n",
    "            continue\n",
    "        h_post = h.Clone(h.GetName() + '_postfit')\n",
    "        if 'data' in n:\n",
    "            h_fit = fd.Get(cat+'/total')\n",
    "            h_data = h.Clone(h.GetName() + '_data')\n",
    "            for i in range(1, h_post.GetNbinsX()+1):\n",
    "                h_post.SetBinContent(i, h_fit.GetBinContent(i))\n",
    "                h_post.SetBinError(i, h_fit.GetBinError(i))     \n",
    "            \n",
    "            histo_postfit[cat]['total'] = h_post\n",
    "            histo_postfit[cat][n] = h_data\n",
    "        else:\n",
    "            h_fit = fd.Get(cat+'/'+n)\n",
    "            for i in range(1, h_post.GetNbinsX()+1):\n",
    "                h_post.SetBinContent(i, h_fit.GetBinContent(i))\n",
    "                h_post.SetBinError(i, h_fit.GetBinError(i)) \n",
    "\n",
    "            histo_postfit[cat][n] = h_post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T02:36:47.696984Z",
     "start_time": "2020-05-16T02:36:47.456278Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "h2 = fFitDiagnostics.Get('covariance_fit_s')\n",
    "rt.gStyle.SetPaintTextFormat('.1f')\n",
    "\n",
    "N = h2.GetNbinsX()\n",
    "n=20\n",
    "\n",
    "h2.GetXaxis().SetRange(1, n)\n",
    "h2.GetYaxis().SetRangeUser(N-n, N)\n",
    "h2.SetMarkerSize(1.3)\n",
    "CC = drawOnCMSCanvas(CMS_lumi, [h2, h2], ['colz', 'text same'], tag='tl', mL=0.22, mR=0.15, mB=0.18)\n",
    "CC.SaveAs(outdir+'/fig/covariance_zoom.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T02:36:48.529746Z",
     "start_time": "2020-05-16T02:36:47.701952Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cSigPost = plot_gridVarQ2(CMS_lumi, binning, histo_postfit, draw_pulls=True, pulls_ylim=[-5, 5])\n",
    "cSigPost.SaveAs(outdir+'/fig/signalRegion_postfit.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T02:36:49.218557Z",
     "start_time": "2020-05-16T02:36:48.535025Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cSidePost = {}\n",
    "for k in np.sort(sideVar.keys()):\n",
    "    legLoc = [0.67, 0.3, 0.93, 0.72]\n",
    "    if 'MassVis' in sideVar[k]:\n",
    "        legLoc = [0.18, 0.4, 0.4, 0.75]\n",
    "    cSidePost[k] = plot_SingleCategory(CMS_lumi, histo_postfit[k], \n",
    "                                       xtitle=sideXtitle[k], addText=sideAddtext[k], \n",
    "                                       tag=k, legLoc=legLoc,\n",
    "                                       draw_pulls=True\n",
    "                                      )\n",
    "    cSidePost[k].SaveAs(outdir+'/fig/'+k+'_postfit.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T02:36:52.342630Z",
     "start_time": "2020-05-16T02:36:49.223605Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cmd = 'python diffNuisances.py '.format(os.environ['CMSSW_BASE'])\n",
    "cmd += outdir + '/fitDiagnostics{}.root'.format(card_name)\n",
    "cmd += ' --skipFitB'\n",
    "# cmd += ' --all'\n",
    "cmd += ' --abs'\n",
    "cmd += ' -g {}/nuisance_difference.root'.format(outdir)\n",
    "print cmd\n",
    "status, output = commands.getstatusoutput(cmd)\n",
    "dumpDiffNuisances(output, outdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T02:36:52.362103Z",
     "start_time": "2020-05-16T02:36:52.347679Z"
    }
   },
   "outputs": [],
   "source": [
    "if fastRun:\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run likelyhood scan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T02:40:09.731168Z",
     "start_time": "2020-05-16T02:36:52.366638Z"
    }
   },
   "outputs": [],
   "source": [
    "cmd = 'combine'\n",
    "cmd += ' -M MultiDimFit'\n",
    "cmd += ' --algo grid --points=100'\n",
    "cmd += ' --robustFit 1'\n",
    "cmd += ' -d ' + card_location.replace('.txt', '.root')\n",
    "cmd += ' -D ' + histo[histo.keys()[0]]['data'].GetName()\n",
    "cmd += ' --X-rtd MINIMIZER_analytic'\n",
    "cmd += ' --rMin={:.4f} --rMax={:.4f}'.format(*rDst_postFitRegion)\n",
    "cmd += ' -n {}_nominal'.format(card_name)\n",
    "cmd += ' --verbose -1'\n",
    "print cmd\n",
    "os.system(cmd)\n",
    "cmd = 'plot1DScan.py higgsCombine{}_nominal.MultiDimFit.mH120.root'.format(card_name)\n",
    "cmd += '; mv scan.png scan_nominal.png'\n",
    "os.system(cmd)\n",
    "res_nominal = getUncertaintyFromLimitTree('higgsCombine{}_nominal.MultiDimFit.mH120.root'.format(card_name))\n",
    "display(Image(filename='scan_nominal.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uncertainy breakdown by group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T02:40:18.714668Z",
     "start_time": "2020-05-16T02:40:09.735553Z"
    }
   },
   "outputs": [],
   "source": [
    "cmd = 'combine -M MultiDimFit --algo none'\n",
    "cmd += ' --cminDefaultMinimizerStrategy=2 --robustFit 1 --X-rtd MINIMIZER_analytic'\n",
    "cmd += ' -d ' + card_location.replace('.txt', '.root')\n",
    "cmd += ' -D ' + histo[histo.keys()[0]]['data'].GetName()\n",
    "cmd += ' --setParameters r={:.2f}'.format(SM_RDst)\n",
    "cmd += ' --setParameterRanges r=0.001,1'\n",
    "cmd += ' -n {}_bestfit'.format(card_name)\n",
    "cmd += ' --saveWorkspace --verbose -1'\n",
    "print cmd\n",
    "os.system(cmd);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T02:40:40.424803Z",
     "start_time": "2020-05-16T02:40:18.718790Z"
    }
   },
   "outputs": [],
   "source": [
    "# Statistical uncertainty\n",
    "cmd = 'combine -M MultiDimFit --algo grid --points=100'\n",
    "cmd += ' --cminDefaultMinimizerStrategy=2 --robustFit 1 --X-rtd MINIMIZER_analytic'\n",
    "cmd += ' -d higgsCombine{}_bestfit.MultiDimFit.mH120.root'.format(card_name)\n",
    "cmd += ' -D ' + histo[histo.keys()[0]]['data'].GetName()\n",
    "cmd += ' --rMin={:.4f} --rMax={:.4f}'.format(*rDst_postFitRegion)\n",
    "cmd += ' -n {}_stat'.format(card_name)\n",
    "cmd += ' --snapshotName MultiDimFit'\n",
    "cmd += ' --freezeNuisanceGroups=autoMCStats,allShape'\n",
    "cmd += ' --verbose -1'\n",
    "print cmd\n",
    "os.system(cmd);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T02:41:13.638110Z",
     "start_time": "2020-05-16T02:40:40.432004Z"
    }
   },
   "outputs": [],
   "source": [
    "# MC Statistics\n",
    "cmd = 'combine -M MultiDimFit --algo grid --points=100'\n",
    "cmd += ' --cminDefaultMinimizerStrategy=2 --robustFit 1 --X-rtd MINIMIZER_analytic'\n",
    "cmd += ' -d higgsCombine{}_bestfit.MultiDimFit.mH120.root'.format(card_name)\n",
    "cmd += ' -D ' + histo[histo.keys()[0]]['data'].GetName()\n",
    "cmd += ' --rMin={:.4f} --rMax={:.4f}'.format(*rDst_postFitRegion)\n",
    "cmd += ' -n {}_MCstat'.format(card_name)\n",
    "cmd += ' --snapshotName MultiDimFit'\n",
    "cmd += ' --freezeNuisanceGroups=autoMCStats'\n",
    "cmd += ' --verbose -1'\n",
    "print cmd\n",
    "os.system(cmd);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T02:41:17.492190Z",
     "start_time": "2020-05-16T02:41:13.643839Z"
    }
   },
   "outputs": [],
   "source": [
    "cmd = 'plot1DScan.py higgsCombine{}_nominal.MultiDimFit.mH120.root'.format(card_name)\n",
    "cmd += ' --others'\n",
    "cmd += ' \"higgsCombine{}_MCstat.MultiDimFit.mH120.root:Freeze MC stat:4\"'.format(card_name)\n",
    "cmd += ' \"higgsCombine{}_stat.MultiDimFit.mH120.root:Freeze all:2\"'.format(card_name)\n",
    "cmd += ' --breakdown MCstat,syst,stat'\n",
    "cmd += '; mv scan.png scan_MCstat.png'\n",
    "print cmd\n",
    "os.system(cmd)\n",
    "display(Image(filename='scan_MCstat.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T02:41:17.656089Z",
     "start_time": "2020-05-16T02:41:17.496839Z"
    }
   },
   "outputs": [],
   "source": [
    "os.system('mv higgsCombine*.root ' + outdir + '/')\n",
    "os.system('mv scan* ' + outdir + '/')\n",
    "os.system('mv combine_logger.out ' + outdir + '/');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the impact plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit first the POI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T02:41:17.680017Z",
     "start_time": "2020-05-16T02:41:17.664210Z"
    }
   },
   "outputs": [],
   "source": [
    "os.mkdir(outdir+'/impactPlots')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T02:42:03.450109Z",
     "start_time": "2020-05-16T02:41:17.686062Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cmd = 'cd {}/impactPlots;'.format(outdir)\n",
    "cmd += ' combineTool.py -M Impacts --doInitialFit -m 120'\n",
    "cmd += ' --robustFit 1 --X-rtd MINIMIZER_analytic'\n",
    "cmd += ' -d ../../../' + card_location.replace('.txt', '.root')\n",
    "cmd += ' -D ' + histo[histo.keys()[0]]['data'].GetName()\n",
    "cmd += ' --setParameters r={:.2f}'.format(SM_RDst)\n",
    "cmd += ' --setParameterRanges r=0.01,1'\n",
    "cmd += ' -n {}'.format(card_name)\n",
    "cmd += ' --verbose -1'\n",
    "os.system(cmd);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Perform a similar scan for each nuisance parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If running on Tier2 condor remmeber to add this line to CombineToolBase.py ln 11\n",
    "``source /cvmfs/cms.cern.ch/cmsset_default.sh``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T02:42:08.391537Z",
     "start_time": "2020-05-16T02:42:03.455153Z"
    }
   },
   "outputs": [],
   "source": [
    "cmd = 'cd {}/impactPlots;'.format(outdir)\n",
    "cmd += ' combineTool.py -M Impacts --doFits -m 120'\n",
    "cmd += ' --robustFit 1 --X-rtd MINIMIZER_analytic'\n",
    "# cmd += ' --parallel 20'\n",
    "cmd += ' --parallel 100 --job-mode condor --task-name combineImpacts'\n",
    "cmd += ' --sub-opts \"{}\"'.format(stringJubCustomizationCaltechT2.replace('\"', '\\\\\\\"').replace('$', '\\$'))\n",
    "cmd += ' -d ../../../' + card_location.replace('.txt', '.root')\n",
    "cmd += ' -D ' + histo[histo.keys()[0]]['data'].GetName()\n",
    "cmd += ' -n {}'.format(card_name)\n",
    "cmd += ' --verbose -1'\n",
    "print cmd\n",
    "os.system(cmd);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collect the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T02:43:43.872451Z",
     "start_time": "2020-05-16T02:42:08.396784Z"
    }
   },
   "outputs": [],
   "source": [
    "status, output = commands.getstatusoutput('condor_q')\n",
    "while 'combineImpacts' in output:\n",
    "    time.sleep(10)\n",
    "    status, output = commands.getstatusoutput(cmd)\n",
    "cmd = 'cd {}/impactPlots;'.format(outdir)\n",
    "cmd += ' combineTool.py -M Impacts -o impacts.json -m 120'\n",
    "cmd += ' -d ../../../' + card_location.replace('.txt', '.root')\n",
    "cmd += ' -n {}'.format(card_name)\n",
    "print cmd\n",
    "os.system(cmd);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T02:43:43.874268Z",
     "start_time": "2020-05-16T02:25:34.259Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rename = {\n",
    "'r': 'R(D*)',\n",
    "'B0pT': 'B_{0} p_{T} spectrum',\n",
    "'B2DstCLNR0':'R_{0} (CLN B#rightarrow D*#ell#nu)',\n",
    "'B2DstCLNR1':'R_{1} (CLN B#rightarrow D*)',\n",
    "'B2DstCLNR2':'R_{2} (CLN B#rightarrow D*)',\n",
    "'B2DstCLNRhoSq':'#rho^{2} (CLN B#rightarrow D*)',\n",
    "'trgSF': 'Trigger scale factor',\n",
    "'xsecpp2bbXlumi': 'Luminosity*#sigma_{pp#rightarrowbb}',\n",
    "    \n",
    "}\n",
    "\n",
    "procName_dic = {\n",
    "'mu'        : 'B_{0}#rightarrow D*#mu#nu',\n",
    "'tau'       : 'B_{0}#rightarrow D*#tau#nu',\n",
    "'DstmD0'    : 'B^{+}#rightarrow D*D_{0}',\n",
    "'DstmDp'    : 'B^{+}#rightarrow D*D^{+}',\n",
    "'DstmDsp'   : 'B^{+}#rightarrow D*D_{s}^{+}',\n",
    "'DstPip'    : 'B^{+}#rightarrow D*#pi^{+}#mu#nu',\n",
    "'DstPipPi0' : 'B^{+}#rightarrow D*#pi^{+}#pi^{0}#mu#nu',\n",
    "'DstPi0'    : 'B_{0}#rightarrow D*#pi^{0}#mu#nu',\n",
    "'DstPipPim' : 'B_{0}#rightarrow D*#pi^{+}#pi^{-}#mu#nu',\n",
    "'DstPi0Pi0' : 'B_{0}#rightarrow D*#pi^{0}#pi^{0}#mu#nu'\n",
    "}\n",
    "\n",
    "for n in processes:\n",
    "    rename[n+'Br'] = 'Branching fraction ' + procName_dic[n]\n",
    "\n",
    "d = json.load(open(outdir+'/impactPlots/impacts.json', 'r'))\n",
    "for par in d['params']:\n",
    "    name = str(par['name'])\n",
    "    if not name.startswith('prop_bin'): continue\n",
    "    label = name.replace('prop_bin', 'MC stat. ')\n",
    "    label = label.replace('M2_miss_', 'M^{2}_{miss} ')\n",
    "    label = label.replace('Est_mu_', 'E*_{#mu} ')\n",
    "    label = label.replace('q2bin', '[b_{q^{2}}=')\n",
    "    label = label.replace('_bin', '] ')\n",
    "    rename[name] = label + 10*' '\n",
    "    \n",
    "json.dump(rename, open(outdir+'/impactPlots/rename.json', 'w'))\n",
    "\n",
    "cmd = 'cd {};'.format(outdir)\n",
    "cmd += 'plotImpacts.py -i impactPlots/impacts.json -o impacts -t impactPlots/rename.json'\n",
    "os.system(cmd)\n",
    "IFrame(outdir+'/impacts.pdf', width=900, height=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the Goodness of fit test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the observed test stat value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T02:43:43.877107Z",
     "start_time": "2020-05-16T02:25:34.263Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cmd = 'combine -M GoodnessOfFit --toysFrequentist --algo=saturated'\n",
    "cmd += ' --robustFit 1 --X-rtd MINIMIZER_analytic --cminDefaultMinimizerStrategy 0'\n",
    "cmd += ' -d results/{cn}/higgsCombine{cn}_bestfit.MultiDimFit.mH120.root'.format(cn=card_name)\n",
    "cmd += ' --snapshotName MultiDimFit --bypassFrequentistFit'\n",
    "cmd += ' -D ' + histo[histo.keys()[0]]['data'].GetName()\n",
    "cmd += ' -n Obs'                                    # Just the output name\n",
    "cmd += ' -t 0'                                      # Don't run toys\n",
    "cmd += ' -s 1'                                      # Random seed\n",
    "cmd += ' --setParameters r={:.2f}'.format(SM_RDst)\n",
    "cmd += ' --setParameterRanges r=0.001,1'\n",
    "cmd += ' --plots --verbose -1'\n",
    "print cmd\n",
    "os.system(cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the test stat toy distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T02:43:43.879624Z",
     "start_time": "2020-05-16T02:25:34.268Z"
    }
   },
   "outputs": [],
   "source": [
    "cmd = 'combine -M GoodnessOfFit --toysFrequentist --algo=saturated'\n",
    "cmd += ' --robustFit 1 --X-rtd MINIMIZER_analytic --cminDefaultMinimizerStrategy 0'\n",
    "cmd += ' -d results/{cn}/higgsCombine{cn}_bestfit.MultiDimFit.mH120.root'.format(cn=card_name)\n",
    "cmd += ' --snapshotName MultiDimFit --bypassFrequentistFit'\n",
    "cmd += ' -D ' + histo[histo.keys()[0]]['data'].GetName()\n",
    "cmd += ' -n Toys'                                   # Just the output name\n",
    "cmd += ' -t 20'                                     # Number of toys to run\n",
    "cmd += ' -s -1'                                     # Random seed\n",
    "cmd += ' --setParameters r={:.2f}'.format(SM_RDst)\n",
    "cmd += ' --setParameterRanges r=0.001,1'\n",
    "cmd += ' --plots --verbose -1'\n",
    "cmdToys = cmd\n",
    "print cmdToys\n",
    "# os.system(cmdToys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T02:43:43.881800Z",
     "start_time": "2020-05-16T02:25:34.271Z"
    }
   },
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "\n",
    "def runCommand(cmd):\n",
    "    os.system(cmd)\n",
    "\n",
    "Nrep = 15\n",
    "p = Pool(min(20,Nrep))\n",
    "outputs = p.map(runCommand, Nrep*[cmdToys])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine them to get the p-value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T02:43:43.884269Z",
     "start_time": "2020-05-16T02:25:34.275Z"
    }
   },
   "outputs": [],
   "source": [
    "f = ur.open('higgsCombineObs.GoodnessOfFit.mH120.1.root')\n",
    "s_obs = f['limit']['limit'].array()[0]\n",
    "\n",
    "s_toys = []\n",
    "for name_toys in glob('higgsCombineToys.GoodnessOfFit.*.root'):\n",
    "    f = ur.open(name_toys)\n",
    "    s_toys += list(f['limit']['limit'].array())\n",
    "\n",
    "content, center, _ = plt.hist(s_toys, label='Toys')\n",
    "plt.plot([s_obs, s_obs], [0, np.max(content)], 'm--', label='Observed')\n",
    "plt.legend(loc='best')\n",
    "\n",
    "p_val = np.sum(s_toys > s_obs)/float(len(s_toys))\n",
    "print 'p-value: {:.1f}%'.format(100*p_val)\n",
    "if p_val < 0.01: print p_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T02:43:43.886487Z",
     "start_time": "2020-05-16T02:25:34.278Z"
    }
   },
   "outputs": [],
   "source": [
    "os.system('mv *.root {}/'.format(outdir))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14+"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "308px",
    "left": "1550px",
    "right": "20px",
    "top": "120px",
    "width": "338px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
