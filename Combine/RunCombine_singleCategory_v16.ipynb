{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New from v13 (AN_v2):\n",
    " - Save B pT nad eta as well\n",
    " - D** lineshape (DstPi and DstPiPi)\n",
    " - New backgrouns samples: D** Tau\n",
    " \n",
    "New from v14:\n",
    " - pT uncertainty for B+ as well\n",
    " - Poly B pT uncertainty\n",
    " - Possibility of running with BLPR FF\n",
    " - DstPiPi wider (200 MeV MC)\n",
    " \n",
    "To do:\n",
    " - New backgrouns samples: 3 pi (not going to do it, they are compatible with 0)\n",
    " - Tracking SF (to do)\n",
    " - Add combinatorial and fake from data template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-23T00:02:02.924730Z",
     "start_time": "2020-11-23T00:02:02.914985Z"
    }
   },
   "outputs": [],
   "source": [
    "use_real_data = True\n",
    "blinded_fit = True\n",
    "\n",
    "category = ['low', 'mid', 'high', 'single'][1]\n",
    "useMVA = [False, 'v0', 'v1'][0]\n",
    "schemeFF = ['CLN', 'BLPR', 'NoFF'][0]\n",
    "card_name = 'v16'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-23T00:02:02.988245Z",
     "start_time": "2020-11-23T00:02:02.929367Z"
    }
   },
   "outputs": [],
   "source": [
    "useMCstats = True\n",
    "runCombine = True\n",
    "runScanOnly = False\n",
    "runBias = False\n",
    "runFitDiagnostics = True\n",
    "runImpacts = False\n",
    "runGoF = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": true
   },
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-23T00:02:03.229174Z",
     "start_time": "2020-11-23T00:02:02.992893Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys, os, pickle, time\n",
    "from glob import glob\n",
    "sys.path.append('../lib')\n",
    "sys.path.append('../analysis')\n",
    "from categoriesDef import categories as categoriesDef\n",
    "import itertools\n",
    "import commands\n",
    "from prettytable import PrettyTable\n",
    "import json, yaml\n",
    "from IPython.display import IFrame, Image, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-23T00:02:09.486216Z",
     "start_time": "2020-11-23T00:02:03.233871Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to JupyROOT 6.12/07\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from array import array\n",
    "\n",
    "import uproot as ur\n",
    "import ROOT as rt\n",
    "rt.gErrorIgnoreLevel = rt.kError\n",
    "rt.RooMsgService.instance().setGlobalKillBelow(rt.RooFit.ERROR)\n",
    "import root_numpy as rtnp\n",
    "\n",
    "from analysis_utilities import drawOnCMSCanvas, getEff, DSetLoader\n",
    "from pT_calibration_reader import pTCalReader\n",
    "from histo_utilities import create_TH1D, create_TH2D, std_color_list\n",
    "from gridVarQ2Plot import plot_gridVarQ2, plot_SingleCategory, getControlXtitle, getControlSideText\n",
    "from progressBar import ProgressBar\n",
    "from lumi_utilities import getLumiByTrigger\n",
    "from combine_utilities import getUncertaintyFromLimitTree, dumpDiffNuisances, stringJubCustomizationCaltechT2, loadHisto4CombineFromRoot\n",
    "\n",
    "import CMS_lumi, tdrstyle\n",
    "tdrstyle.setTDRStyle()\n",
    "CMS_lumi.writeExtraText = 1\n",
    "\n",
    "if use_real_data:\n",
    "    CMS_lumi.extraText = \"     Preliminary\"\n",
    "else:\n",
    "    CMS_lumi.extraText = \"     Simulation Preliminary\"\n",
    "\n",
    "donotdelete = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-23T00:02:09.511822Z",
     "start_time": "2020-11-23T00:02:09.491424Z"
    }
   },
   "outputs": [],
   "source": [
    "card_name += category + '_' + schemeFF\n",
    "if useMVA:\n",
    "    card_name += '_MVA'+useMVA\n",
    "if not use_real_data: \n",
    "    card_name += '_Asimov'\n",
    "if blinded_fit: \n",
    "    card_name += '_blinded'\n",
    "if not useMCstats: \n",
    "    card_name += '_NoMCstats'\n",
    "outdir = 'results/' + card_name\n",
    "if not os.path.isdir(outdir):\n",
    "    os.system('mkdir -p ' + outdir + '/fig')\n",
    "card_location = 'cards/{}.txt'.format(card_name)\n",
    "histo_file_dir = '/storage/user/ocerri/BPhysics/data/_root/histos4combine/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-23T00:02:09.572823Z",
     "start_time": "2020-11-23T00:02:09.516549Z"
    }
   },
   "outputs": [],
   "source": [
    "cat = categoriesDef[category]\n",
    "binning = {'q2': array('d', [-2, 2.5, 6, 9.4, 12])}\n",
    "SM_RDst = 0.295\n",
    "expectedLumi = {'low':6.4, 'mid':20.7, 'high':26.4, 'single':6.} #fb^-1\n",
    "lumi_tot = expectedLumi[category]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-23T00:02:09.682908Z",
     "start_time": "2020-11-23T00:02:09.577367Z"
    }
   },
   "outputs": [],
   "source": [
    "FreeParFF = {\n",
    "   'CLN': ['R0', 'eig1', 'eig2', 'eig3'],\n",
    "   'BLPR': ['eig1', 'eig2', 'eig3', 'eig4', 'eig5', 'eig6'],\n",
    "   'NoFF': []\n",
    "}[schemeFF]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create histograms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-23T00:02:40.766752Z",
     "start_time": "2020-11-23T00:02:09.687196Z"
    }
   },
   "outputs": [],
   "source": [
    "#They all have to be produced with the same pileup\n",
    "MCsample = {\n",
    "'tau' : DSetLoader('B0_TauNuDmst_PUc0'),\n",
    "'mu' : DSetLoader('B0_MuNuDmst_PUc0'),\n",
    "'DstmD0' : DSetLoader('B0_DstmD0_PUc0'),\n",
    "'DstmDp' : DSetLoader('B0_DstmDp_PUc0'),\n",
    "'DstmDsp' : DSetLoader('B0_DstmDsp_PUc0'),\n",
    "'BpDstmHc' : DSetLoader('Bp_DstmHc_PUc0'),\n",
    "'BmDstmHc' : DSetLoader('Bm_DstmHc_PUc0'),\n",
    "'antiB0DstmHc' : DSetLoader('antiB0_DstmHc_PUc0'),\n",
    "'DstPip' : DSetLoader('Bp_MuNuDstst_Pip_PUc0'),\n",
    "'DstPi0' : DSetLoader('B0_MuNuDstst_Pi0_PUc0'),\n",
    "'DstPipPi0' : DSetLoader('Bp_MuNuDstst_PipPi0_PUc0'),\n",
    "'DstPipPim' : DSetLoader('B0_MuNuDstst_PipPim_PUc0'),\n",
    "# 'DstPipPi0' : DSetLoader('Bp_MuNuDstPipPi0_PUc0'),\n",
    "# 'DstPipPim' : DSetLoader('B0_MuNuDstPipPim_PUc0'),\n",
    "'DstPi0Pi0' : DSetLoader('B0_MuNuDstst_Pi0Pi0_PUc0'),\n",
    "'TauDstPi0' : DSetLoader('B0_TauNuDstst_Pi0_PUc0'),\n",
    "'TauDstPip' : DSetLoader('Bp_TauNuDstst_Pip_PUc0')\n",
    "}\n",
    "processOrder = ['tau', 'mu', \n",
    "                'DstPip','DstPi0',\n",
    "                'DstPipPi0','DstPipPim','DstPi0Pi0',\n",
    "                'TauDstPi0', 'TauDstPip',\n",
    "                'DstmDsp','DstmD0','DstmDp',\n",
    "                'BpDstmHc','BmDstmHc','antiB0DstmHc']\n",
    "dSet = {}\n",
    "dSetTkSide = {}\n",
    "for n, s in MCsample.iteritems():\n",
    "    if not n in processOrder: raise\n",
    "    dSet[n] = pd.DataFrame(rtnp.root2array(s.skimmed_dir + '/{}_corr.root'.format(cat.name)))\n",
    "    dSetTkSide[n] = rtnp.root2array(s.skimmed_dir + '/{}_trkCtrl_corr.root'.format(cat.name))\n",
    "#     dSet[n] = pd.DataFrame(rtnp.root2array(s.skimmed_dir + '/{}_bare.root'.format(cat.name)))\n",
    "#     dSetTkSide[n] = rtnp.root2array(s.skimmed_dir + '/{}_trkCtrl_bare.root'.format(cat.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-23T00:02:40.781450Z",
     "start_time": "2020-11-23T00:02:40.772292Z"
    },
    "code_folding": [
     0,
     8
    ]
   },
   "outputs": [],
   "source": [
    "SamplesB0 = ['mu', 'tau', \n",
    "             'DstmD0', 'DstmDp', 'DstmDsp', \n",
    "             'antiB0DstmHc', \n",
    "             'DstPi0', \n",
    "             'DstPipPim', 'DstPi0Pi0', \n",
    "             'TauDstPi0'\n",
    "            ]\n",
    "\n",
    "SamplesBp = ['Bp_DstmHc_PUc0', 'Bm_DstmHc_PUc0', \n",
    "             'Bp_MuNuDstst_Pip_PUc0', \n",
    "             'Bp_MuNuDstst_PipPi0_PUc0', \n",
    "             'Bp_TauNuDstst_Pip_PUc0'\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-23T00:02:46.312952Z",
     "start_time": "2020-11-23T00:02:40.785848Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run2018D-05May2019promptD-v1_RDntuplizer_B2DstMu_201101\n",
      "HLT_Mu9_IP6_part2_v3 4.14\n",
      "Run2018D-05May2019promptD-v1_RDntuplizer_B2DstMu_201101\n",
      "HLT_Mu9_IP6_part1_v3 4.15\n",
      "Run2018D-05May2019promptD-v1_RDntuplizer_B2DstMu_201101\n",
      "HLT_Mu9_IP6_part4_v3 4.15\n",
      "Run2018D-05May2019promptD-v1_RDntuplizer_B2DstMu_201101\n",
      "HLT_Mu9_IP6_part3_v3 4.14\n",
      "Run2018D-05May2019promptD-v1_RDntuplizer_B2DstMu_201101\n",
      "HLT_Mu9_IP6_part0_v3 4.12\n",
      "Total lumi: 20.70 fb^-1\n"
     ]
    }
   ],
   "source": [
    "if use_real_data:\n",
    "    creation_date = '201101'\n",
    "    locRD = '../data/cmsRD/skimmed/B2DstMu_B0_{}_{}'.format(creation_date, cat.name)\n",
    "    dSet['data'] = rtnp.root2array(locRD + '_corr.root')\n",
    "    dSetTkSide['data'] = rtnp.root2array(locRD + '_trkCtrl_corr.root')\n",
    "    dataDir = '../data/cmsRD'\n",
    "    datasets_loc = glob(dataDir + '/ParkingBPH*/*RDntuplizer_B2DstMu_{}_CAND.root'.format(creation_date))\n",
    "    lumi_tot = getLumiByTrigger(datasets_loc, cat.trg, verbose=True)\n",
    "    CMS_lumi.integrated_lumi = lumi_tot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load calibrations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pileup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-23T00:02:46.401386Z",
     "start_time": "2020-11-23T00:02:46.316438Z"
    }
   },
   "outputs": [],
   "source": [
    "from pileup_utilities import pileupReweighter\n",
    "puReweighter = pileupReweighter(MCsample['mu'].skimmed_dir + '/{}_corr.root'.format(cat.name), cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Branching fraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-23T00:02:46.441441Z",
     "start_time": "2020-11-23T00:02:46.405830Z"
    }
   },
   "outputs": [],
   "source": [
    "decayBR = pickle.load(open('../data/forcedDecayChannelsFactors.pickle', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trigger scale factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-23T00:02:46.529731Z",
     "start_time": "2020-11-23T00:02:46.445781Z"
    }
   },
   "outputs": [],
   "source": [
    "loc = '../data/calibration/triggerScaleFactors/'\n",
    "fTriggerSF = rt.TFile.Open(loc + 'HLT_' + cat.trg + '_SF_v3.root', 'READ')\n",
    "hTriggerSF = fTriggerSF.Get('hSF_HLT_' + cat.trg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-23T00:02:46.614819Z",
     "start_time": "2020-11-23T00:02:46.533610Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def computeTrgSF(ds, selection=None):\n",
    "    trgSF = np.ones_like(ds['q2'])\n",
    "    trgSFUnc = np.zeros_like(ds['q2'])\n",
    "    ptmax = hTriggerSF.GetXaxis().GetXmax() - 0.01\n",
    "    ipmax = hTriggerSF.GetYaxis().GetXmax() - 0.01\n",
    "    etamax = hTriggerSF.GetZaxis().GetXmax() - 0.01\n",
    "    x = np.column_stack((ds['mu_pt'], ds['mu_eta'], ds['mu_sigdxy']))\n",
    "    if not selection is None:\n",
    "        x = x[selection]\n",
    "    for i, (pt, eta, ip) in enumerate(x):\n",
    "        ix = hTriggerSF.GetXaxis().FindBin(min(ptmax, pt))\n",
    "        iy = hTriggerSF.GetYaxis().FindBin(min(ipmax, ip))\n",
    "        iz = hTriggerSF.GetZaxis().FindBin(min(etamax, np.abs(eta)))\n",
    "        trgSF[i] = hTriggerSF.GetBinContent(ix, iy, iz)\n",
    "        ib = hTriggerSF.GetBin(ix, iy, iz)\n",
    "        trgSFUnc[i] = hTriggerSF.GetBinError(ib)\n",
    "        if trgSF[i] == 0:\n",
    "            print pt, ip, np.abs(eta)\n",
    "            raise\n",
    "    # Divide them for the weight so later you can simply multiply back to get the value\n",
    "    up = 1 + trgSFUnc/trgSF\n",
    "    down = 1 - trgSFUnc/trgSF\n",
    "    return trgSF, up, down"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Muon ID scale factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-23T00:02:46.717422Z",
     "start_time": "2020-11-23T00:02:46.620835Z"
    }
   },
   "outputs": [],
   "source": [
    "fMuonIDSF = rt.TFile.Open('../data/calibration/muonIDscaleFactors/Run2018ABCD_SF_MuonID_Jpsi.root', 'READ')\n",
    "hMuonIDSF = fMuonIDSF.Get('NUM_SoftID_DEN_genTracks_pt_abseta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-23T00:02:46.802478Z",
     "start_time": "2020-11-23T00:02:46.723503Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def computeMuonIDSF(ds, selection=None):\n",
    "    muonSF = np.ones_like(ds['q2'])\n",
    "    muonSFUnc = np.zeros_like(ds['q2'])\n",
    "    ptmax = hMuonIDSF.GetXaxis().GetXmax() - 0.01\n",
    "    etamax = hMuonIDSF.GetYaxis().GetXmax() - 0.01\n",
    "    x = np.column_stack((ds['MC_mu_pt'], ds['MC_mu_eta']))\n",
    "    if not selection is None:\n",
    "        x = x[selection]\n",
    "    for i, (pt, eta) in enumerate(x):\n",
    "        ix = hMuonIDSF.GetXaxis().FindBin(min(pt, ptmax))\n",
    "        if ix == 0: ix = 1 #Remove underflows (Meaning that the MC matching failed)\n",
    "        iy = hMuonIDSF.GetYaxis().FindBin(min(np.abs(eta), etamax))\n",
    "        muonSF[i] = hMuonIDSF.GetBinContent(ix, iy)\n",
    "        muonSFUnc[i] = hMuonIDSF.GetBinError(hMuonIDSF.GetBin(ix, iy))\n",
    "        if muonSF[i] == 0:\n",
    "            print pt, eta\n",
    "            print ix, iy\n",
    "            raise\n",
    "    up = 1 + muonSFUnc/muonSF\n",
    "    down = 1 - muonSFUnc/muonSF\n",
    "#     print np.column_stack((muonSF, up, down, muonSF*up, muonSF*down))\n",
    "#     raise\n",
    "    return muonSF, up, down"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "B transverse momentum calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-23T00:02:46.863349Z",
     "start_time": "2020-11-23T00:02:46.807769Z"
    }
   },
   "outputs": [],
   "source": [
    "aux = 'Low' if category == 'single' else cat.name\n",
    "cal_pT_B0 = pTCalReader(calibration_file='../data/calibration/B0pTspectrum/polyCoeffWeights_{}.pkl'.format(aux))\n",
    "cal_pT_Bp = pTCalReader(calibration_file='../data/calibration/Bcharged_pTspectrum/pwWeights_{}.txt'.format(aux))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-23T00:02:46.894707Z",
     "start_time": "2020-11-23T00:02:46.868379Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def computePtWeights(ds, tag, cal_pT):\n",
    "    if cal_pT.kind == 'poly':\n",
    "        # The denominator (sum of weights) for this weights is not known but it cancel out in the ratio\n",
    "        w = cal_pT.getWeights(ds['MC_B_pt'], shape=0)\n",
    "        if np.sum(w==0):\n",
    "            print np.sum(w==0)\n",
    "            raise\n",
    "\n",
    "        varDic = {}\n",
    "        for iShape in range(1, cal_pT.nVar+1):\n",
    "            varDic[tag+'_lam{}Down'.format(iShape)] = cal_pT.getWeights(ds['MC_B_pt'], shape=-iShape)/w\n",
    "            varDic[tag+'_lam{}Up'.format(iShape)] = cal_pT.getWeights(ds['MC_B_pt'], shape=+iShape)/w\n",
    "        return w, varDic\n",
    "    elif cal_pT.kind == 'ratio':\n",
    "        w = cal_pT.f['C'](ds['MC_B_pt'])\n",
    "        if np.sum(w==0):\n",
    "            print np.sum(w==0)\n",
    "            raise\n",
    "        up = cal_pT.f['Up'](ds['MC_B_pt'])/w\n",
    "        down = cal_pT.f['Down'](ds['MC_B_pt'])/w\n",
    "        return w, up, down\n",
    "    else:\n",
    "        print 'Unknown calibration'\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-23T00:02:46.953794Z",
     "start_time": "2020-11-23T00:02:46.898587Z"
    }
   },
   "outputs": [],
   "source": [
    "pWeightsEta = pickle.load(open('../data/calibration/B0pTspectrum/etaWeights_poly_{}.p'.format(cat.name), 'rb'))\n",
    "def computeB0etaWeights(ds):\n",
    "    w = np.polyval(p=pWeightsEta, x=ds['B_eta'])\n",
    "    return np.clip(w, a_min=0.5, a_max=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-23T00:02:46.980917Z",
     "start_time": "2020-11-23T00:02:46.958329Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def computeBrVarWeights(ds, selItems={}, relScale=0.2, keepNorm=False):\n",
    "    sel = np.ones_like(ds['mu_pt']).astype(np.bool)\n",
    "    for var, val in selItems.iteritems():\n",
    "        sel = np.logical_and(ds[var].astype(np.int) == val, sel)\n",
    "    w = np.ones_like(sel)\n",
    "    up = np.where(sel, 1.+relScale, 1.)\n",
    "    down = np.where(sel, max(0, 1.-relScale), 1.)\n",
    "    if keepNorm:\n",
    "        up = float(up.shape[0])/np.sum(up)\n",
    "        down = float(down.shape[0])/np.sum(down)\n",
    "    return w, up, down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-23T00:02:47.071273Z",
     "start_time": "2020-11-23T00:02:46.985169Z"
    }
   },
   "outputs": [],
   "source": [
    "def computeWidthVarWeights(ds, selItems=[], #pdgId, mass, Gamma\n",
    "                           relScale=0.1): #Gamma modification factor\n",
    "    up = np.ones_like(ds['mu_pt'])\n",
    "    down = np.ones_like(ds['mu_pt'])\n",
    "    for pdgId, mass, gamma in selItems:\n",
    "        print pdgId, mass, gamma\n",
    "        gUp = gamma*(1+relScale)\n",
    "        gDown = gamma*(1-relScale)\n",
    "\n",
    "        dx2 = np.clip(np.square(ds['MC_MassCharmedBDaughter'] - mass), 0, 9*(gamma**2))\n",
    "        wUp = ((dx2 + gamma**2)*gUp)/(gamma*(dx2 + gUp**2))\n",
    "        wDown = ((dx2 + gamma**2)*gDown)/(gamma*(dx2 + gDown**2))\n",
    "        \n",
    "        sel = np.abs(ds['MC_DstMotherPdgId'].astype(np.int)) == np.abs(pdgId)\n",
    "        up = np.where(sel, wUp, up)\n",
    "        down = np.where(sel, wDown, down)\n",
    "        \n",
    "    w = np.ones_like(sel)    \n",
    "    return w, up, down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-23T00:02:47.110204Z",
     "start_time": "2020-11-23T00:02:47.075344Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def computeTksPVweights(ds, relScale=0.05, centralVal=0.39/0.10):\n",
    "    selPdgID0 = np.logical_and(np.abs(ds['MC_tkMotherPdgId_0']) < 6, ds['MC_tkMotherPdgId_0'] != 0)\n",
    "    selPdgID0 = np.logical_or(selPdgID0, ds['MC_tkMotherPdgId_0']==2212)\n",
    "    selPdgID0 = np.logical_and(selPdgID0, ds['MC_tkFlag_0'] == 1)\n",
    "    selPdgID1 = np.logical_and(np.abs(ds['MC_tkMotherPdgId_1']) < 6, ds['MC_tkMotherPdgId_1'] != 0)\n",
    "    selPdgID1 = np.logical_or(selPdgID1, ds['MC_tkMotherPdgId_1']==2212)\n",
    "    selPdgID1 = np.logical_and( selPdgID1, ds['MC_tkFlag_1'] == 1)\n",
    "    exponent = selPdgID0.astype(np.int) + selPdgID1.astype(np.int)\n",
    "    w = np.power(centralVal, exponent)\n",
    "    up = np.power(centralVal*(1+relScale), exponent)/w\n",
    "    down = np.power(centralVal*(1-relScale), exponent)/w\n",
    "    return w, up, down"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-23T00:02:47.186653Z",
     "start_time": "2020-11-23T00:02:47.114608Z"
    }
   },
   "outputs": [],
   "source": [
    "if useMVA:\n",
    "    fname = '../plot_scripts/kinObsMVA/clfGBC_tauVall_{}{}.p'.format(useMVA, cat.name)\n",
    "    clfGBC = pickle.load(open(fname, 'rb'))\n",
    "    \n",
    "    def computeVarMVA(ds):\n",
    "        if useMVA == 'v0':\n",
    "            aux = np.column_stack((ds['q2'], ds['Est_mu'], ds['M2_miss']))\n",
    "        elif useMVA == 'v1':\n",
    "            ds['pt_vis'] = ds['B_pt']*ds['mass_D0pismu']/5.27963\n",
    "            aux = np.column_stack((ds['q2'], ds['Est_mu'], ds['M2_miss'], \n",
    "                                   ds['pt_vis'], ds['mass_D0pismu'],\n",
    "                                   ds['B_eta']\n",
    "                                         ))\n",
    "        else: raise\n",
    "        p = clfGBC.predict_proba(aux)\n",
    "        return p[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create MC histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-23T00:02:47.268258Z",
     "start_time": "2020-11-23T00:02:47.192932Z"
    }
   },
   "outputs": [],
   "source": [
    "histo = {}\n",
    "eventCountingStr = {}\n",
    "RDoMC_normRatio = 6 # Difference in Pythia prediction between Hard and Soft QCD production"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Signal region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-23T00:02:47.338595Z",
     "start_time": "2020-11-23T00:02:47.271860Z"
    },
    "code_folding": [],
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "binning = {\n",
    "    'M2_miss' : [\n",
    "        array('d', [-2.5] + list(np.arange(-1.8, -0.2, 0.4)) + [-0.2, 0., 0.2, 0.6, 8] ),\n",
    "        array('d', [-2.5] + list(np.arange(-1.8, -0.1, 0.4)) + [-0.1, 0.0, 0.1, 0.2, 0.3] + list(np.arange(0.4, 3.0, 0.4)) + [8] ),\n",
    "        array('d', [-2.5] + list(np.arange(-1.8, 5.6, 0.4)) + [8] ),\n",
    "        array('d', [-2.5] + list(np.arange(-1.8, 7.6, 0.4)) + [8] ),\n",
    "    ],\n",
    "    'Est_mu'  : [\n",
    "        array('d', [0.3] + list(np.arange(0.5, 2.4, 0.05)) + [2.5] ),\n",
    "        array('d', [0.3] + list(np.arange(0.5, 2.5, 0.05)) + [2.5] ),\n",
    "        array('d', [0.3] + list(np.arange(0.5, 2.5, 0.1)) + [2.5] ),\n",
    "        [22, 0.3, 2.500],\n",
    "    ],\n",
    "}\n",
    "\n",
    "binning_2D = [\n",
    "    [\n",
    "        array('d', [-2.5] + list(np.arange(-1.8, -0.2, 0.4)) + [-0.2, 0., 0.2, 0.6, 8] ),\n",
    "#         array('d', [0.3] + list(np.arange(0.7, 2.3, 0.5)) + [2.5] )\n",
    "        array('d', [0.3] + list(np.arange(0.7, 2.3, 0.3)) + [2.5] )\n",
    "    ],\n",
    "    [\n",
    "        array('d', [-2.5] + list(np.arange(-1.8, 3.0, 0.4)) + [8] ),\n",
    "#         array('d', [0.3] + list(np.arange(0.7, 2.5, 0.5)) + [2.5] )\n",
    "        array('d', [0.3] + list(np.arange(0.7, 2.5, 0.3)) + [2.5] )\n",
    "    ],\n",
    "    [\n",
    "        array('d', [-2.5] + list(np.arange(-1.8, 5.6, 0.4)) + [8] ),\n",
    "        array('d', [0.3] + list(np.arange(0.5, 2.5, 0.3)) + [2.5] )\n",
    "    ],\n",
    "    [\n",
    "        array('d', [-2.5] + list(np.arange(-1.8, 7.6, 0.4)) + [8] ),\n",
    "        array('d', list(np.linspace(0.3, 2.5, 11)) )\n",
    "    ]\n",
    "    \n",
    "]\n",
    "\n",
    "binning['q2'] = array('d', [-2, 2.5, 6, 9.4, 12])\n",
    "binning['B_pt'] = array('d', list(np.arange(10, 75, 2)) )\n",
    "binning['B_eta'] = array('d', list(np.arange(-1.9, 1.91, 0.05)) )\n",
    "\n",
    "if use_real_data:\n",
    "    binning['MVA'] = array('d', list(np.arange(0., 0.51, 0.03)))\n",
    "else:\n",
    "    binning['MVA'] = array('d', list(np.arange(0., 0.83, 0.02)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-23T00:02:02.997Z"
    },
    "code_folding": [
     49,
     60,
     64,
     71,
     76,
     83,
     92,
     106,
     141
    ],
    "hide_input": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----------> tau <-------------\n",
      "N tot selected: 39.8k\n",
      "N tot expected (before weights): 29.29k\n",
      "Including pileup reweighting\n",
      "Including trigger corrections\n",
      "Including muon ID corrections\n",
      "Including B0 pT corrections\n",
      "Including FF corrections (Hammer)\n",
      "Computing total weights\n",
      "N tot expected (after weights): 31.927k\n",
      "\n",
      "-----------> mu <-------------\n",
      "N tot selected: 768.4k\n",
      "N tot expected (before weights): 360.26k\n",
      "Including pileup reweighting\n",
      "Including trigger corrections\n",
      "Including muon ID corrections\n"
     ]
    }
   ],
   "source": [
    "totalCounting = [0,0]\n",
    "for n in processOrder: \n",
    "    ds = dSet[n]\n",
    "    if n == 'data': continue\n",
    "    print '\\n----------->', n, '<-------------'\n",
    "    sMC = MCsample[n]\n",
    "    \n",
    "    nTotSelected = ds['q2'].shape[0]\n",
    "    print 'N tot selected: {:.1f}k'.format(1e-3*nTotSelected)\n",
    "    totalCounting[1] += 1e-3*nTotSelected\n",
    "    nGenExp = sMC.effMCgen['xsec'][0] * lumi_tot * RDoMC_normRatio\n",
    "    eff = [1, 0]\n",
    "    for f, df in [sMC.effMCgen['effGEN'], decayBR[n], sMC.effCand['effCAND'], sMC.getSkimEff(cat.name+'_corr')]:\n",
    "        eff[0] *= f\n",
    "        eff[1] += np.square(df/f)\n",
    "    eff[1] = eff[0] * np.sqrt(eff[1])\n",
    "    nTotExp = nGenExp*eff[0]\n",
    "    print 'N tot expected (before weights): {:.2f}k'.format(1e-3*nTotExp)\n",
    "    \n",
    "    wVar = {}\n",
    "    weights = {}\n",
    "    \n",
    "    print 'Including pileup reweighting'\n",
    "    weights['pileup'] = puReweighter.weightsPileupMC[ds['N_vtx'].astype(np.int)]\n",
    "    print 'Including trigger corrections'\n",
    "    weights['trg{}SF'.format(cat.trg)], wVar['trg{}SFUp'.format(cat.trg)], wVar['trg{}SFDown'.format(cat.trg)] = computeTrgSF(ds)\n",
    "#     weights['trg{}SF'.format(cat.trg)], _, _ = computeTrgSF(ds)\n",
    "    print 'Including muon ID corrections'\n",
    "#     weights['muonIdSF'], wVar['muonIdSFUp'], wVar['muonIdSFDown'] = computeMuonIDSF(ds)\n",
    "    weights['muonIdSF'], _, _ = computeMuonIDSF(ds)\n",
    "    weights['etaB'] = computeB0etaWeights(ds)\n",
    "    if n in SamplesB0:\n",
    "        print 'Including B0 pT corrections'\n",
    "        weights['B0pT'], auxVarDic = computePtWeights(ds, 'B0pT', cal_pT_B0)\n",
    "        wVar.update(auxVarDic)\n",
    "    if n in SamplesBp:\n",
    "        print 'Including B +/- pT corrections'\n",
    "        weights['BpPt'], wVar['BpPtUp'], wVar['BpPtDown'] = computePtWeights(ds, None, cal_pT_Bp)\n",
    "    # Hammer corrections to the FF\n",
    "    if n in ['mu', 'tau'] and schemeFF != 'NoFF':\n",
    "        print 'Including FF corrections (Hammer)'\n",
    "        weights['B2DstFF'] = ds['wh_'+schemeFF+'Central']*sMC.effCand['rate_den']/sMC.effCand['rate_'+schemeFF+'Central']\n",
    "        for nPar in FreeParFF:\n",
    "            for var in ['Up', 'Down']:\n",
    "                tag = schemeFF + nPar + var\n",
    "                wVar['B2Dst'+tag] = ds['wh_'+tag]/ds['wh_'+schemeFF+'Central']\n",
    "                wVar['B2Dst'+tag] *= sMC.effCand['rate_'+schemeFF+'Central']/sMC.effCand['rate_' + tag]\n",
    "    #Dstst resonance mix\n",
    "    if n == 'DstPip' or n =='TauDstPip':\n",
    "        _, wVar['fDststWideUp'], wVar['fDststWideDown'] = computeBrVarWeights(ds, {'MC_munuSisterPdgId': -20423}, 0.6/2.7, keepNorm=True) #Gamma 14 pdg 2020\n",
    "        widthMods = [\n",
    "            [10423, 2.422, 0.020],\n",
    "            [20423, 2.445, 0.250],\n",
    "            [425, 2.461, 0.043],\n",
    "        ]\n",
    "#         _, wVar['DstPipWidthUp'], wVar['DstPipWidthDown'] = computeWidthVarWeights(ds, selItems=widthMods, relScale=0.15)\n",
    "        _, wVar['D2420_10WidthUp'], wVar['D2420_10WidthDown'] = computeWidthVarWeights(ds, selItems=[[10423, 2.422, 0.020]], relScale=0.15)\n",
    "        _, wVar['D2430_10WidthUp'], wVar['D2430_10WidthDown'] = computeWidthVarWeights(ds, selItems=[[20423, 2.445, 0.250]], relScale=0.1)\n",
    "        _, wVar['D2460_1StWidthUp'], wVar['D2460_1StWidthDown'] = computeWidthVarWeights(ds, selItems=[[425, 2.461, 0.043]], relScale=0.15)\n",
    "    if n == 'DstPipPim' or n == 'DstPi0Pi0':\n",
    "        widthMods = [[100413, 2.640, 0.200]]\n",
    "        _, wVar['DstPiPiWidthUp'], wVar['DstPiPiWidthDown'] = computeWidthVarWeights(ds, selItems=widthMods, relScale=0.1)\n",
    "    #Hc mix variations\n",
    "    if n == 'DstmD0':\n",
    "        _, wVar['BrB02DstD0KpUp'], wVar['BrB02DstD0KpDown'] = computeBrVarWeights(ds, {'MC_DstSisterPdgId_heavy': 421, 'MC_DstSisterPdgId_light': 321}, 0.21/2.47) #Gamma 169 pdg 2020\n",
    "        _, wVar['BrB02DstD0KstpUp'], wVar['BrB02DstD0KstpDown'] = computeBrVarWeights(ds, {'MC_DstSisterPdgId_heavy': 421, 'MC_DstSisterPdgId_light': 323}, 0.5) # Guess\n",
    "        _, wVar['BrB02DstDst0KpUp'], wVar['BrB02DstDst0KpDown'] = computeBrVarWeights(ds, {'MC_DstSisterPdgId_heavy': 423, 'MC_DstSisterPdgId_light': 321}, 0.09/1.06) #Gamma 170 pdg 2020\n",
    "        _, wVar['BrB02DstDst0KstpUp'], wVar['BrB02DstDst0KstpDown'] = computeBrVarWeights(ds, {'MC_DstSisterPdgId_heavy': 423, 'MC_DstSisterPdgId_light': 323}, 0.5) # Guess\n",
    "        _, wVar['BrB02DstDstpK0Up'], wVar['BrB02DstDstpK0Down'] = computeBrVarWeights(ds, {'MC_DstSisterPdgId_heavy': 413, 'MC_DstSisterPdgId_light': 311}, 0.5/5.3) #Gamma 173 pdg 2020\n",
    "        _, wVar['BrB02DstDstpKst0Up'], wVar['BrB02DstDstpKst0Down'] = computeBrVarWeights(ds, {'MC_DstSisterPdgId_heavy': 413, 'MC_DstSisterPdgId_light': 313}, 0.5) # Guess\n",
    "    if n == 'DstmDp':\n",
    "        _, wVar['BrB02DstDpK0Up'], wVar['BrB02DstDpK0Down'] = computeBrVarWeights(ds, {'MC_DstSisterPdgId_heavy': 411, 'MC_DstSisterPdgId_light': 311}, 0.5/3.2) #Gamma 172 pdg 2020\n",
    "        _, wVar['BrB02DstDpKst0Up'], wVar['BrB02DstDpKst0Down'] = computeBrVarWeights(ds, {'MC_DstSisterPdgId_heavy': 411, 'MC_DstSisterPdgId_light': 313}, 0.5) # Guess\n",
    "        _, wVar['BrB02DstDstpK0Up'], wVar['BrB02DstDstpK0Down'] = computeBrVarWeights(ds, {'MC_DstSisterPdgId_heavy': 413, 'MC_DstSisterPdgId_light': 311}, 0.2/2.7) #Gamma 173 pdg 2020\n",
    "        _, wVar['BrB02DstDstpKst0Up'], wVar['BrB02DstDstpKst0Down'] = computeBrVarWeights(ds, {'MC_DstSisterPdgId_heavy': 413, 'MC_DstSisterPdgId_light': 313}, 0.5) # Guess\n",
    "    if n == 'DstmDsp':\n",
    "        _, wVar['BrB02DstDsUp'], wVar['BrB02DstDsDown'] = computeBrVarWeights(ds, {'MC_DstSisterPdgId_heavy': 431}, 1.1/8.0) #Gamma 83 pdg 2020\n",
    "        _, wVar['BrB02DstDsstUp'], wVar['BrB02DstDsstDown'] = computeBrVarWeights(ds, {'MC_DstSisterPdgId_heavy': 433}, .14/1.77) #Gamma 85 pdg 2020\n",
    "        _, wVar['BrB02DstDs0stUp'], wVar['BrB02DstDs0stDown'] = computeBrVarWeights(ds, {'MC_DstSisterPdgId_heavy': 10431}, .6/1.5) #Gamma 95 pdg 2020\n",
    "    \n",
    "    print 'Computing total weights'\n",
    "    weightsCentral = np.ones_like(ds['q2'])\n",
    "    for w in weights.values(): \n",
    "        weightsCentral *= w\n",
    "    print 'N tot expected (after weights): {:.3f}k'.format(1e-3*nTotExp*np.sum(weightsCentral)/nTotSelected)\n",
    "    totalCounting[0] += 1e-3*nTotExp*np.sum(weightsCentral)/nTotSelected\n",
    "    evCountStr = '{:.2f} ({:.2f})'.format(1e-3*nTotExp*np.sum(weightsCentral)/nTotSelected, 1e-3*nTotSelected)\n",
    "    eventCountingStr[n] = evCountStr\n",
    "    wVar[''] = np.ones_like(weightsCentral)\n",
    "    \n",
    "    \n",
    "    if useMVA:\n",
    "        print 'Evaluating MVA'\n",
    "        if not 'MVA' in histo.keys():\n",
    "            histo['MVA'] = {}\n",
    "        sMVA = computeVarMVA(ds)\n",
    "        for name_wVar, v_wVar in wVar.iteritems():\n",
    "                h_name = n\n",
    "                if not name_wVar == '':\n",
    "                    h_name += '__' + name_wVar\n",
    "                w = weightsCentral*v_wVar\n",
    "                scale = nTotExp/nTotSelected\n",
    "                histo['MVA'][h_name] = create_TH1D(sMVA, name=h_name, weights=w, scale_histo=scale,\n",
    "                                                   binning=binning['MVA'], opt='underflow,overflow')\n",
    "    \n",
    "    for i_q2 in range(len(binning['q2'])-1):\n",
    "        q2_l = binning['q2'][i_q2]\n",
    "        q2_h = binning['q2'][i_q2 + 1]\n",
    "        sel_q2 = np.logical_and(ds['q2'] > q2_l, ds['q2'] <= q2_h)\n",
    "        name2D = 'h2D_q2bin'+str(i_q2)\n",
    "        if not name2D in histo.keys():\n",
    "                histo[name2D] = {}\n",
    "        for var in ['M2_miss', 'Est_mu']:\n",
    "            cat_name = var+'_q2bin'+str(i_q2)\n",
    "            \n",
    "            if not cat_name in histo.keys():\n",
    "                histo[cat_name] = {}\n",
    "            \n",
    "            for name_wVar, v_wVar in wVar.iteritems():\n",
    "                h_name = n\n",
    "                if not name_wVar == '':\n",
    "                    h_name += '__' + name_wVar\n",
    "                w = weightsCentral*v_wVar\n",
    "                scale = nTotExp/nTotSelected\n",
    "                histo[cat_name][h_name] = create_TH1D(\n",
    "                                                      ds[var][sel_q2], \n",
    "                                                      name=h_name, title=h_name, \n",
    "                                                      binning=binning[var][i_q2], \n",
    "                                                      opt='underflow,overflow',\n",
    "                                                      weights=w[sel_q2], scale_histo=scale,\n",
    "                                                      )\n",
    "                if not var == 'M2_miss': \n",
    "                    continue\n",
    "                auxS = np.column_stack((ds['M2_miss'][sel_q2], ds['Est_mu'][sel_q2]))\n",
    "                histo[name2D][h_name] = create_TH2D(\n",
    "                                                      auxS, \n",
    "                                                      name=h_name, title=h_name, \n",
    "                                                      binning=binning_2D[i_q2],\n",
    "                                                      weights=w[sel_q2], scale_histo=scale,\n",
    "                                                      )\n",
    "    for var in ['B_pt', 'B_eta']:\n",
    "        if not var in histo.keys():\n",
    "            histo[var] = {}          \n",
    "        for name_wVar, v_wVar in wVar.iteritems():\n",
    "            h_name = n\n",
    "            if not name_wVar == '':\n",
    "                h_name += '__' + name_wVar\n",
    "            w = weightsCentral*v_wVar\n",
    "            scale = nTotExp/nTotSelected\n",
    "            histo[var][h_name] = create_TH1D(ds[var], name=h_name, weights=w, scale_histo=scale,\n",
    "                                                binning=binning[var], opt='underflow,overflow')\n",
    "                \n",
    "                \n",
    "evCountStr = '{:.1f} ({:.1f})'.format(*totalCounting)\n",
    "eventCountingStr['tot'] = evCountStr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-23T00:02:03.001Z"
    },
    "hide_input": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "c2D = []\n",
    "nonEmptyIdxs = []\n",
    "unrollingCutOff = 3\n",
    "for i_q2 in range(len(binning['q2'])-1):\n",
    "    c2D.append(None)\n",
    "    nonEmptyIdxs.append([])\n",
    "    name2D = 'h2D_q2bin'+str(i_q2)\n",
    "    hSum = None\n",
    "    nDroppedBins = 0\n",
    "    nExpectedDroppedEvents = 0\n",
    "    for key, hN in histo[name2D].iteritems():\n",
    "        if '__' in key:\n",
    "            continue\n",
    "        if hSum is None:\n",
    "            hSum = hN.Clone('hSum_'+str(i_q2))\n",
    "        else:\n",
    "            scale = SM_RDst if 'tau' in n else 1.\n",
    "            hSum.Add(hN, scale)\n",
    "    hSum.GetXaxis().SetTitle('m^{2}_{miss} [GeV^{2}]')\n",
    "    hSum.GetYaxis().SetTitle('E_{#mu}* [GeV]')\n",
    "    hSum.GetZaxis().SetTitle('Events')\n",
    "    for ix in range(1, hSum.GetNbinsX()+1):\n",
    "        for iy in range(1, hSum.GetNbinsY()+1):\n",
    "            if hSum.GetBinContent(ix, iy) > unrollingCutOff:\n",
    "                nonEmptyIdxs[i_q2].append([ix, iy])\n",
    "            else:\n",
    "                nDroppedBins += 1\n",
    "                nExpectedDroppedEvents += hSum.GetBinContent(ix, iy)\n",
    "    c2D[i_q2] = drawOnCMSCanvas(CMS_lumi, [hSum], ['colz'], tag=str(i_q2), mR=0.17)\n",
    "    c2D[i_q2].SaveAs(outdir+'/fig/TotMC_M2Miss_vs_EstMu_q2bin{}.png'.format(i_q2))\n",
    "    c2D[i_q2].SetLogz()\n",
    "    print 'Dropped bins:', nDroppedBins\n",
    "    print 'Expected dropped candidates:', nExpectedDroppedEvents\n",
    "print 'Considered bins:', [len(l) for l in nonEmptyIdxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-23T00:02:03.004Z"
    }
   },
   "outputs": [],
   "source": [
    "for i_q2 in range(len(binning['q2'])-1):\n",
    "    name2D = 'h2D_q2bin'+str(i_q2)\n",
    "    nameU = 'Unrolled_q2bin'+str(i_q2)\n",
    "    histo[nameU] = {}\n",
    "    validBins = nonEmptyIdxs[i_q2]\n",
    "    for n, h in histo[name2D].iteritems():\n",
    "        hUnrolled = rt.TH1D(h.GetName(), h.GetTitle(), len(validBins), 0.5, len(validBins)+0.5)\n",
    "        for i, (ix, iy) in enumerate(validBins):\n",
    "            hUnrolled.SetBinContent(i+1, h.GetBinContent(ix, iy))\n",
    "            hUnrolled.SetBinError(i+1, h.GetBinError(ix, iy))\n",
    "        histo[nameU][n] = hUnrolled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single track side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-23T00:02:03.008Z"
    }
   },
   "outputs": [],
   "source": [
    "sideSelecton = {}\n",
    "sideVar = {}\n",
    "\n",
    "def selfun__TkPlus(ds):\n",
    "    sel = np.logical_and(ds['N_goodAddTks'] == 1, ds['tkCharge_0'] > 0)\n",
    "    return sel\n",
    "#     return np.logical_and(np.abs(ds['tkMassHad_0'] - 2.43) < 0.3, sel)\n",
    "sideSelecton['AddTk_p_mHad'] = selfun__TkPlus\n",
    "sideVar['AddTk_p_mHad'] = 'massHadTks'\n",
    "# sideVar['AddTk_p_mHad'] = 'massHadTks_DstMassConstraint'\n",
    "binning['AddTk_p_mHad'] = [35, 2.13, 2.83]\n",
    "\n",
    "def selfun__TkMinus(ds):\n",
    "    sel = np.logical_and(ds['N_goodAddTks'] == 1, ds['tkCharge_0'] < 0)\n",
    "    return sel\n",
    "sideSelecton['AddTk_m_mHad'] = selfun__TkMinus\n",
    "sideVar['AddTk_m_mHad'] = 'massHadTks'\n",
    "binning['AddTk_m_mHad'] = [30, 2.1, 3.3]\n",
    "\n",
    "\n",
    "def selfun__TkPlusMinus(ds):\n",
    "    sel = np.logical_and(ds['tkCharge_0']+ds['tkCharge_1'] == 0, ds['N_goodAddTks'] == 2)\n",
    "    sel = np.logical_and(ds['massVisTks'] < 5.3, sel)\n",
    "    return sel\n",
    "sideSelecton['AddTk_pm_mVis'] = selfun__TkPlusMinus\n",
    "sideVar['AddTk_pm_mVis'] = 'massVisTks'\n",
    "binning['AddTk_pm_mVis'] = array('d', [2.8] + list(np.arange(3., 5.3, 0.1)) + [5.3] )\n",
    "# binning['AddTk_pm_mVis'] = array('d', list(np.arange(3., 5.3, 0.1)) + [5.3] )\n",
    "\n",
    "\n",
    "sideSelecton['AddTk_pm_mHad'] = selfun__TkPlusMinus\n",
    "sideVar['AddTk_pm_mHad'] = 'massHadTks'\n",
    "binning['AddTk_pm_mHad'] = [30, 2.3, 3.75]\n",
    "\n",
    "def selfun__TkMinusMinus(ds):\n",
    "    sel = np.logical_and(ds['tkCharge_0']+ds['tkCharge_1'] == -2, ds['N_goodAddTks'] == 2)\n",
    "    sel = np.logical_and(ds['massVisTks'] < 5.3, sel)\n",
    "    return sel\n",
    "sideSelecton['AddTk_mm_mHad'] = selfun__TkMinusMinus\n",
    "sideVar['AddTk_mm_mHad'] = 'massHadTks'\n",
    "binning['AddTk_mm_mHad'] = [15, 2.25, 3.6]\n",
    "\n",
    "def selfun__TkPlusPlus(ds):\n",
    "    sel = np.logical_and(ds['tkCharge_0']+ds['tkCharge_1'] == +2, ds['N_goodAddTks'] == 2)\n",
    "    sel = np.logical_and(ds['massVisTks'] < 5.3, sel)\n",
    "    return sel\n",
    "sideSelecton['AddTk_pp_mHad'] = selfun__TkPlusPlus\n",
    "sideVar['AddTk_pp_mHad'] = 'massHadTks'\n",
    "binning['AddTk_pp_mHad'] = [15, 2.25, 3.75]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-23T00:02:03.012Z"
    },
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for k in sideSelecton.keys():\n",
    "    histo[k] = {}\n",
    "\n",
    "totalCounting = {}\n",
    "for n in processOrder:\n",
    "    ds = dSetTkSide[n]\n",
    "    if n == 'data': continue\n",
    "    print '\\n----------->', n, '<-------------'\n",
    "    sMC = MCsample[n]    \n",
    "    wVar = {}\n",
    "    weights = {}\n",
    "    \n",
    "    print 'Including pileup reweighting'\n",
    "    weights['pileup'] = puReweighter.weightsPileupMC[ds['N_vtx'].astype(np.int)]\n",
    "#     weights['pileup'] = getPileupWeights(ds)\n",
    "    print 'Including trigger corrections'\n",
    "    weights['trg{}SF'.format(cat.trg)], wVar['trg{}SFUp'.format(cat.trg)], wVar['trg{}SFDown'.format(cat.trg)] = computeTrgSF(ds)\n",
    "    print 'Including muon ID corrections'\n",
    "    weights['muonIdSF'], wVar['muonIdSFUp'], wVar['muonIdSFDown'] = computeMuonIDSF(ds)\n",
    "    if n in SamplesB0:\n",
    "        print 'Including B0 pT corrections'\n",
    "        weights['B0pT'], auxVarDic = computePtWeights(ds, 'B0pT', cal_pT_B0)\n",
    "        wVar.update(auxVarDic)\n",
    "    if n in SamplesBp:\n",
    "        print 'Including B +/- pT corrections'\n",
    "        weights['BpPt'], wVar['BpPtUp'], wVar['BpPtDown'] = computePtWeights(ds, None, cal_pT_Bp)\n",
    "    if n in ['mu', 'tau'] and schemeFF != 'NoFF':\n",
    "        print 'Including FF corrections (Hammer)'\n",
    "        weights['B2DstFF'] = ds['wh_'+schemeFF+'Central']*sMC.effCand['rate_den']/sMC.effCand['rate_'+schemeFF+'Central']\n",
    "        for nPar in FreeParFF:\n",
    "            for var in ['Up', 'Down']:\n",
    "                tag = schemeFF + nPar + var\n",
    "                wVar['B2Dst'+tag] = ds['wh_'+tag]/ds['wh_'+schemeFF+'Central']\n",
    "                wVar['B2Dst'+tag] *= sMC.effCand['rate_'+schemeFF+'Central']/sMC.effCand['rate_' + tag]\n",
    "    #Dstst resonance mix\n",
    "    if n == 'DstPip' or n == 'TauDstPip':\n",
    "        _, wVar['fDststWideUp'], wVar['fDststWideDown'] = computeBrVarWeights(ds, {'MC_munuSisterPdgId': -20423}, 0.6/2.7, keepNorm=True) #Gamma 14 pdg 2020\n",
    "        widthMods = [\n",
    "            [10423, 2.422, 0.020],\n",
    "            [20423, 2.445, 0.250],\n",
    "            [425, 2.461, 0.043],\n",
    "        ]\n",
    "#         _, wVar['DstPipWidthUp'], wVar['DstPipWidthDown'] = computeWidthVarWeights(ds, selItems=widthMods, relScale=0.15)\n",
    "        _, wVar['D2420_10WidthUp'], wVar['D2420_10WidthDown'] = computeWidthVarWeights(ds, selItems=[[10423, 2.422, 0.020]], relScale=0.15)\n",
    "        _, wVar['D2430_10WidthUp'], wVar['D2430_10WidthDown'] = computeWidthVarWeights(ds, selItems=[[20423, 2.445, 0.250]], relScale=0.1)\n",
    "        _, wVar['D2460_1StWidthUp'], wVar['D2460_1StWidthDown'] = computeWidthVarWeights(ds, selItems=[[425, 2.461, 0.043]], relScale=0.15)\n",
    "    if n == 'DstPipPim' or n == 'DstPi0Pi0':\n",
    "        widthMods = [[100413, 2.640, 0.200]]\n",
    "        _, wVar['DstPiPiWidthUp'], wVar['DstPiPiWidthDown'] = computeWidthVarWeights(ds, selItems=widthMods, relScale=0.1)\n",
    "    #Hc mix variations\n",
    "    if n == 'DstmD0':\n",
    "        _, wVar['BrB02DstD0KpUp'], wVar['BrB02DstD0KpDown'] = computeBrVarWeights(ds, {'MC_DstSisterPdgId_heavy': 421, 'MC_DstSisterPdgId_light': 321}, 0.21/2.47) #Gamma 169 pdg 2020\n",
    "        _, wVar['BrB02DstD0KstpUp'], wVar['BrB02DstD0KstpDown'] = computeBrVarWeights(ds, {'MC_DstSisterPdgId_heavy': 421, 'MC_DstSisterPdgId_light': 323}, 0.5) # Guess\n",
    "        _, wVar['BrB02DstDst0KpUp'], wVar['BrB02DstDst0KpDown'] = computeBrVarWeights(ds, {'MC_DstSisterPdgId_heavy': 423, 'MC_DstSisterPdgId_light': 321}, 0.09/1.06) #Gamma 170 pdg 2020\n",
    "        _, wVar['BrB02DstDst0KstpUp'], wVar['BrB02DstDst0KstpDown'] = computeBrVarWeights(ds, {'MC_DstSisterPdgId_heavy': 423, 'MC_DstSisterPdgId_light': 323}, 0.5) # Guess\n",
    "        _, wVar['BrB02DstDstpK0Up'], wVar['BrB02DstDstpK0Down'] = computeBrVarWeights(ds, {'MC_DstSisterPdgId_heavy': 413, 'MC_DstSisterPdgId_light': 311}, 0.5/5.3) #Gamma 173 pdg 2020\n",
    "        _, wVar['BrB02DstDstpKst0Up'], wVar['BrB02DstDstpKst0Down'] = computeBrVarWeights(ds, {'MC_DstSisterPdgId_heavy': 413, 'MC_DstSisterPdgId_light': 313}, 0.5) # Guess\n",
    "    if n == 'DstmDp':\n",
    "        _, wVar['BrB02DstDpK0Up'], wVar['BrB02DstDpK0Down'] = computeBrVarWeights(ds, {'MC_DstSisterPdgId_heavy': 411, 'MC_DstSisterPdgId_light': 311}, 0.5/3.2) #Gamma 172 pdg 2020\n",
    "        _, wVar['BrB02DstDpKst0Up'], wVar['BrB02DstDpKst0Down'] = computeBrVarWeights(ds, {'MC_DstSisterPdgId_heavy': 411, 'MC_DstSisterPdgId_light': 313}, 0.5) # Guess\n",
    "        _, wVar['BrB02DstDstpK0Up'], wVar['BrB02DstDstpK0Down'] = computeBrVarWeights(ds, {'MC_DstSisterPdgId_heavy': 413, 'MC_DstSisterPdgId_light': 311}, 0.2/2.7) #Gamma 173 pdg 2020\n",
    "        _, wVar['BrB02DstDstpKst0Up'], wVar['BrB02DstDstpKst0Down'] = computeBrVarWeights(ds, {'MC_DstSisterPdgId_heavy': 413, 'MC_DstSisterPdgId_light': 313}, 0.5) # Guess\n",
    "    if n == 'DstmDsp':\n",
    "        _, wVar['BrB02DstDsUp'], wVar['BrB02DstDsDown'] = computeBrVarWeights(ds, {'MC_DstSisterPdgId_heavy': 431}, 1.1/8.0) #Gamma 83 pdg 2020\n",
    "        _, wVar['BrB02DstDsstUp'], wVar['BrB02DstDsstDown'] = computeBrVarWeights(ds, {'MC_DstSisterPdgId_heavy': 433}, .14/1.77) #Gamma 85 pdg 2020\n",
    "        _, wVar['BrB02DstDs0stUp'], wVar['BrB02DstDs0stDown'] = computeBrVarWeights(ds, {'MC_DstSisterPdgId_heavy': 10431}, .6/1.5) #Gamma 95 pdg 2020\n",
    "        \n",
    "    # Correct the amount of random tracks from PV\n",
    "    weights['tkPVfrac'], wVar['tkPVfracUp'], wVar['tkPVfracDown'] = computeTksPVweights(ds, relScale=0.1)\n",
    "    \n",
    "    print 'Computing total weights'\n",
    "    weightsCentral = np.ones_like(ds['q2'])\n",
    "    for w in weights.values(): \n",
    "        weightsCentral *= w\n",
    "    wVar[''] = np.ones_like(weightsCentral)\n",
    "    \n",
    "    nGenExp = sMC.effMCgen['xsec'][0] * lumi_tot * RDoMC_normRatio\n",
    "    eff = [1, 0]\n",
    "    for f, df in [sMC.effMCgen['effGEN'], \n",
    "                  decayBR[n], \n",
    "                  sMC.effCand['effCAND'], \n",
    "                  sMC.getSkimEff(cat.name+'_trkCtrl_corr'),\n",
    "                 ]:\n",
    "        eff[0] *= f\n",
    "        eff[1] += np.square(df/f)\n",
    "    eff[1] = eff[0] * np.sqrt(eff[1])\n",
    "    nTotExp = nGenExp*eff[0]\n",
    "    \n",
    "    sel = {}\n",
    "    scale = {}\n",
    "    \n",
    "    latexTableString = {}\n",
    "    for k, selFun in sideSelecton.iteritems():\n",
    "        sel[k] = selFun(ds)\n",
    "        nTotSel = float(np.sum(sel[k]))\n",
    "        print 'N tot selected {}: {:.0f}'.format(k, nTotSel)\n",
    "        nExp = nTotExp * nTotSel / sel[k].shape[0]\n",
    "        print 'N tot expected {} (before weights): {:.0f}'.format(k, nExp)\n",
    "        nAux = nTotExp * np.sum(weightsCentral[sel[k]]) / sel[k].shape[0]\n",
    "        print 'N tot expected {} (after weights): {:.0f}'.format(k, nAux)\n",
    "        latexTableString[k] = '{:.0f} ({:.0f})'.format(nAux, nTotSel)\n",
    "        if not k in totalCounting.keys():\n",
    "            totalCounting[k] = [0, 0]\n",
    "        totalCounting[k][0] += nAux\n",
    "        totalCounting[k][1] += nTotSel\n",
    "        if nTotSel ==0: \n",
    "            nTotSel+=1\n",
    "        scale[k] = nExp/nTotSel\n",
    "    s = ' & '.join([latexTableString['AddTk_'+s+'_mHad'] for s in ['p', 'm', 'pp', 'pm', 'mm']])\n",
    "    print s\n",
    "    eventCountingStr[n] += ' & ' + s + '\\\\\\\\'\n",
    "    \n",
    "            \n",
    "    for name_wVar, v_wVar in wVar.iteritems():\n",
    "        h_name = n\n",
    "        if not name_wVar == '':\n",
    "            h_name += '__' + name_wVar\n",
    "        w = weightsCentral*v_wVar\n",
    "        \n",
    "        for k in sideVar.keys():\n",
    "            histo[k][h_name] = create_TH1D(\n",
    "                                           ds[sideVar[k]][sel[k]], \n",
    "                                           name=h_name, title=h_name, \n",
    "                                           binning=binning[k],\n",
    "                                           opt='underflow',\n",
    "                                           weights=w[sel[k]], scale_histo=scale[k]\n",
    "                                          )\n",
    "            \n",
    "s = ' & '.join(['{:.0f} ({:.0f})'.format(*totalCounting['AddTk_'+s+'_mHad']) for s in ['p', 'm', 'pp', 'pm', 'mm']]) + ' \\\\\\\\'\n",
    "eventCountingStr['tot'] += ' & ' + s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Create (pseudo-)data histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-23T00:02:03.017Z"
    },
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "if use_real_data:\n",
    "    ds = dSet['data']\n",
    "    print 'N observed data signal region: {:.1f}k'.format(1e-3*ds['q2'].shape[0])\n",
    "    if useMVA:\n",
    "        print 'Evaluating MVA'\n",
    "        sMVA = computeVarMVA(ds)\n",
    "        histo['MVA']['data'] = create_TH1D(sMVA, name='data_obs', binning=binning['MVA'], opt='underflow,overflow')\n",
    "                \n",
    "    for i_q2 in range(len(binning['q2'])-1):\n",
    "        q2_l = binning['q2'][i_q2]\n",
    "        q2_h = binning['q2'][i_q2 + 1]\n",
    "        sel_q2 = np.logical_and(ds['q2'] > q2_l, ds['q2'] < q2_h)\n",
    "        for var in ['M2_miss', 'Est_mu']:\n",
    "            cat_name = var+'_q2bin'+str(i_q2)     \n",
    "            histo[cat_name]['data'] = create_TH1D(\n",
    "                                                  ds[var][sel_q2], \n",
    "                                                  name='data_obs', title='Data Obs',\n",
    "                                                  binning=binning[var][i_q2],\n",
    "                                                  opt='underflow,overflow'\n",
    "                                                 )\n",
    "            if not var == 'M2_miss': \n",
    "                    continue\n",
    "            auxS = np.column_stack((ds['M2_miss'][sel_q2], ds['Est_mu'][sel_q2]))\n",
    "            cat2D = 'h2D_q2bin'+str(i_q2)\n",
    "            histo[cat2D]['data'] = create_TH2D(auxS, name='data_obs', title='Data Obs', \n",
    "                                               binning=binning_2D[i_q2])\n",
    "            catU = 'Unrolled_q2bin'+str(i_q2)\n",
    "            validBins = nonEmptyIdxs[i_q2]\n",
    "            hUnrolled = rt.TH1D('data_obs', 'Data Obs', len(validBins), 0.5, len(validBins)+0.5)\n",
    "            for i, (ix, iy) in enumerate(validBins):\n",
    "                hUnrolled.SetBinContent(i+1, histo[cat2D]['data'].GetBinContent(ix, iy))\n",
    "                hUnrolled.SetBinError(i+1, histo[cat2D]['data'].GetBinError(ix, iy))\n",
    "            histo[catU]['data'] = hUnrolled\n",
    "            \n",
    "    for var in ['B_pt', 'B_eta']:\n",
    "        histo[var]['data'] = create_TH1D(ds[var], name='data_obs', binning=binning[var], opt='underflow,overflow')\n",
    "        \n",
    "    ds = dSetTkSide['data']\n",
    "    for k in sideVar.keys():\n",
    "        histo[k]['data'] = create_TH1D(\n",
    "                                       ds[sideVar[k]][sideSelecton[k](ds)], \n",
    "                                       name='data_obs', title='Data Obs', \n",
    "                                       binning=binning[k],\n",
    "                                       opt='underflow',\n",
    "                                      )\n",
    "    print 'N observed data control regions: ' + ' & '.join(['{:.0f}'.format(histo['AddTk_'+s+'_mHad']['data'].Integral()) for s in ['p', 'm', 'pp', 'pm', 'mm']]) + ' \\\\\\\\'\n",
    "        \n",
    "else:\n",
    "    if useMVA:\n",
    "        h = create_TH1D(np.array([0, 0]), name='data_obs', title='Data Obs', binning=binning['MVA'])\n",
    "        h.Reset()\n",
    "        for n, hMC in histo['MVA'].iteritems():\n",
    "                if not '__' in n and not n == 'data':\n",
    "                    scale = SM_RDst if 'tau' in n else 1.\n",
    "                    h.Add(hMC, scale)\n",
    "        h.Sumw2(0)\n",
    "        for i in range(1, h.GetNbinsX()+1):\n",
    "            h.SetBinContent(i, np.around(h.GetBinContent(i)))\n",
    "        h.Sumw2()\n",
    "        histo['MVA']['data'] = h\n",
    "    for i_q2 in range(len(binning['q2'])-1):\n",
    "        for var in ['M2_miss', 'Est_mu', 'Unrolled', 'h2D']:\n",
    "            cat_name = var+'_q2bin'+str(i_q2)\n",
    "            \n",
    "            h = histo[cat_name].values()[0].Clone('data_obs')\n",
    "            h.SetTitle('Data Obs')\n",
    "            h.Reset()\n",
    "            for n, hMC in histo[cat_name].iteritems():\n",
    "                if not '__' in n and not n == 'data':\n",
    "                    scale = SM_RDst if 'tau' in n else 1.\n",
    "                    h.Add(hMC, scale)\n",
    "            h.Sumw2(0)\n",
    "            \n",
    "            for ix in range(1, h.GetNbinsX()+1):\n",
    "                if h.GetNbinsY() > 1:\n",
    "                    for iy in range(1, h.GetNbinsY()+1):\n",
    "                        h.SetBinContent(ix, iy, np.around(h.GetBinContent(ix, iy)))\n",
    "                else:\n",
    "                    h.SetBinContent(ix, np.around(h.GetBinContent(ix)))\n",
    "            h.Sumw2()\n",
    "            histo[cat_name]['data'] = h\n",
    "            \n",
    "    for var in ['B_pt', 'B_eta']:\n",
    "        h = create_TH1D(np.array([0, 0]), name='data_obs', title='Data Obs', binning=binning[var])\n",
    "        h.Reset()\n",
    "        for n, hMC in histo[var].iteritems():\n",
    "                if not '__' in n and not n == 'data':\n",
    "                    scale = SM_RDst if 'tau' in n else 1.\n",
    "                    h.Add(hMC, scale)\n",
    "        h.Sumw2(0)\n",
    "        for i in range(1, h.GetNbinsX()+1):\n",
    "            h.SetBinContent(i, np.around(h.GetBinContent(i)))\n",
    "        h.Sumw2()\n",
    "        histo[var]['data'] = h\n",
    "            \n",
    "    for k in sideVar.keys():\n",
    "        h = create_TH1D(np.array([0, 0]), name='data_obs', title='Data Obs', \n",
    "                        binning=binning[k])\n",
    "        h.Reset()\n",
    "        for n, hMC in histo[k].iteritems():\n",
    "            if not '__' in n and not n == 'data':\n",
    "                scale = SM_RDst if 'tau' in n else 1.\n",
    "                h.Add(hMC, scale)\n",
    "        h.Sumw2(0)\n",
    "        for i in range(1, h.GetNbinsX()+1):\n",
    "            h.SetBinContent(i, np.around(h.GetBinContent(i)))\n",
    "        h.Sumw2()\n",
    "        histo[k]['data'] = h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Dump root file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-23T00:02:03.022Z"
    },
    "hidden": true,
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "if not os.path.isdir(histo_file_dir):\n",
    "    os.makedirs(histo_file_dir)\n",
    "\n",
    "for cat_name, h_dic in histo.iteritems():\n",
    "    tf = rt.TFile(histo_file_dir+'{}_{}.root'.format(card_name, cat_name), 'recreate')\n",
    "    for v in h_dic.values():\n",
    "        v.Write()\n",
    "    tf.Close()\n",
    "    \n",
    "del dSet, dSetTkSide"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Pre-fit plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-23T00:02:03.027Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "if not 'histo' in vars().keys(): histo = loadHisto4CombineFromRoot(histo_file_dir, card_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-23T00:02:03.030Z"
    },
    "hidden": true,
    "hide_input": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "CMS_lumi.integrated_lumi = lumi_tot\n",
    "scale_dic = {'tau': SM_RDst}\n",
    "\n",
    "cSigPre = plot_gridVarQ2(CMS_lumi, binning, histo, \n",
    "                         scale_dic=scale_dic, min_y=0, logy=False, \n",
    "                         categoryText=cat.name.capitalize(),\n",
    "                         iq2_maskData=[2, 3] if blinded_fit else [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-23T00:02:03.033Z"
    },
    "hidden": true,
    "hide_input": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cUnrolledPre = []\n",
    "for i_q2 in range(len(binning['q2'])-1):\n",
    "    q2_l = binning['q2'][i_q2]\n",
    "    q2_h = binning['q2'][i_q2 + 1]\n",
    "    nameU = 'Unrolled_q2bin'+str(i_q2)\n",
    "    histo[nameU]['data'].GetXaxis().SetTitle('Unrolled 2D bins')\n",
    "    histo[nameU]['data'].GetYaxis().SetTitle('Events')\n",
    "    cUnrolledPre.append(plot_SingleCategory(CMS_lumi, histo[nameU], scale_dic=scale_dic,\n",
    "                                            addText='Cat. '+category.capitalize()+', {:.1f} <  q^{{2}}  < {:.1f} GeV^{{2}}'.format(q2_l, q2_h), \n",
    "                                            logy=True, legBkg=True,\n",
    "                                            procOrder = ['tau', 'DstD', 'Dstst', 'mu'],\n",
    "                                            min_y=1, \n",
    "                                            tag='Unrolled_q2bin'+str(i_q2), \n",
    "                                            legLoc=[0.15, 0.6, 0.3, 0.8],\n",
    "                                            maskData = blinded_fit and (False if i_q2 < 2 else True)\n",
    "                                      ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-23T00:02:03.036Z"
    },
    "hidden": true,
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "if useMVA:\n",
    "    histo['MVA']['data'].GetXaxis().SetTitle('MVA score')\n",
    "    histo['MVA']['data'].GetYaxis().SetTitle('Events')\n",
    "    cMVAPre = plot_SingleCategory(CMS_lumi, histo['MVA'], scale_dic=scale_dic,\n",
    "                                  addText='', logy=True, legBkg=True,\n",
    "                                  procOrder = ['tau', 'DstD', 'Dstst', 'mu'],\n",
    "                                  min_y=1, tag='MVA', legLoc=[0.25, 0.4, 0.5, 0.7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-23T00:02:03.040Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "histo['B_pt']['data'].GetXaxis().SetTitle('B p_{T} [GeV]')\n",
    "histo['B_pt']['data'].GetYaxis().SetTitle('Events')\n",
    "cB_pt_pre = plot_SingleCategory(CMS_lumi, histo['B_pt'], scale_dic=scale_dic,\n",
    "                                addText='', logy=False, legBkg=True,\n",
    "                                procOrder = ['tau', 'DstD', 'Dstst', 'mu'],\n",
    "                                min_y=1, tag='B_pt', legLoc=[0.65, 0.45, 0.9, 0.75])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-23T00:02:03.043Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "histo['B_eta']['data'].GetXaxis().SetTitle('B #eta')\n",
    "histo['B_eta']['data'].GetYaxis().SetTitle('Events')\n",
    "cB_eta_pre = plot_SingleCategory(CMS_lumi, histo['B_eta'], scale_dic=scale_dic,\n",
    "                                 addText='', logy=False, legBkg=True,\n",
    "                                 procOrder = ['tau', 'DstD', 'Dstst', 'mu'],\n",
    "                                 min_y=1, tag='B_eta', legLoc=[0.44, 0.33, 0.64, 0.63])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-23T00:02:03.046Z"
    },
    "hidden": true,
    "hide_input": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cSidePre = {}\n",
    "for k in np.sort([k for k in histo.keys() if 'AddTk' in k]):\n",
    "    legLoc = [0.65, 0.4, 0.9, 0.7]\n",
    "    if 'Vis' in k:\n",
    "        legLoc = [0.15, 0.45, 0.35, 0.75]\n",
    "    cSidePre[k] = plot_SingleCategory(CMS_lumi, histo[k], scale_dic=scale_dic,\n",
    "                                      xtitle=getControlXtitle(k), \n",
    "                                      addText='Cat. '+cat.name.capitalize() + ', ' + getControlSideText(k), \n",
    "                                      min_y=0, tag=k, legLoc=legLoc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write the card"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-23T00:02:03.051Z"
    }
   },
   "outputs": [],
   "source": [
    "if not 'histo' in vars().keys(): histo = loadHisto4CombineFromRoot(histo_file_dir, card_name)\n",
    "\n",
    "fitRegionsOnly = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-23T00:02:03.054Z"
    }
   },
   "outputs": [],
   "source": [
    "sig_processes = ['tau', 'mu']\n",
    "bkg_processes = ['DstmD0', 'DstmDp', 'DstmDsp', \n",
    "                 'BpDstmHc', 'BmDstmHc', 'antiB0DstmHc',\n",
    "                 'DstPip', 'DstPipPi0', \n",
    "                 'DstPi0', 'DstPipPim', 'DstPi0Pi0',\n",
    "                 'TauDstPip', 'TauDstPi0'\n",
    "                ]\n",
    "processes = sig_processes + bkg_processes\n",
    "nProc = len(processes)\n",
    "categories = []\n",
    "for c in np.sort(histo.keys()):\n",
    "    if c.startswith('h2'): continue\n",
    "    \n",
    "    if fitRegionsOnly:\n",
    "        if c.startswith('B_pt'): continue\n",
    "        if c.startswith('B_eta'): continue\n",
    "        if c.startswith('Est_mu'): continue\n",
    "        if c.startswith('M2_miss'): continue\n",
    "        if c == 'AddTk_pm_mHad': continue\n",
    "        if blinded_fit and (c.endswith('_q2bin2') or c.endswith('_q2bin3')): continue\n",
    "    categories.append(c)\n",
    "\n",
    "# categories = np.sort([k for k in histo.keys() if not 'h2' in k])\n",
    "nCat = len(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-23T00:02:03.058Z"
    }
   },
   "outputs": [],
   "source": [
    "# number of different categories\n",
    "card = 'imax *\\n'\n",
    "# number of background (not scaled by the auto rateParam r) processes\n",
    "card += 'jmax {}\\n'.format(len(processes)-1)\n",
    "# number of nuissance parameters\n",
    "card += 'kmax *\\n'\n",
    "card += 60*'-'+'\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-23T00:02:03.061Z"
    }
   },
   "outputs": [],
   "source": [
    "# shape file location\n",
    "for k in categories:\n",
    "    fname = histo_file_dir+'{}_{}.root'.format(card_name, k)\n",
    "    card += 'shapes * {} {} $PROCESS $PROCESS__$SYSTEMATIC\\n'.format(k, fname)\n",
    "card += 60*'-'+'\\n'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Number of events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-23T00:02:03.065Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# number of events observed\n",
    "card += 'bin ' + ' '.join(categories) + '\\n'\n",
    "obs = map(lambda k: '{:.0f}'.format(histo[k]['data'].Integral()), categories)\n",
    "obs = ' '.join(obs)\n",
    "card += 'observation ' + obs + '\\n'\n",
    "card += 60*'-'+'\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-23T00:02:03.068Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# MC expected events\n",
    "aux_bin = ''\n",
    "aux_proc_name = ''\n",
    "aux_proc_id = ''\n",
    "aux_proc_rate = ''\n",
    "for c, p in itertools.product(categories, processes):\n",
    "    aux_bin += ' '+c\n",
    "    aux_proc_name += ' '+p\n",
    "    aux_proc_id += ' '+str(np.argmax(np.array(processes) == p))\n",
    "    aux_proc_rate += ' {:.2f}'.format(histo[c][p].Integral())\n",
    "    \n",
    "card += 'bin' + aux_bin + '\\n'\n",
    "card += 'process' + aux_proc_name + '\\n'\n",
    "# Zero or negative for sig and positive for bkg\n",
    "card += 'process' + aux_proc_id + '\\n'\n",
    "# Expected rate\n",
    "card += 'rate' + aux_proc_rate + '\\n'\n",
    "card += 60*'-'+'\\n'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Systematic uncertainties"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Scale systematics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-23T00:02:03.073Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#pp -> bb cros-section * luminosity\n",
    "card += 'xsecpp2bbXlumi'+cat.trg+' lnN' + ' 1.3'*nProc*nCat + '\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-23T00:02:03.077Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Hadronization fraction of B0\n",
    "# aux = ''\n",
    "# for n in processes:\n",
    "#     if n in ['tau', 'mu', 'DstmD0', 'DstmDp', 'DstmDsp', 'DstPi0', 'DstPipPim', 'DstPi0Pi0', 'antiB0DstmHc']: \n",
    "#         aux += ' 1.3'\n",
    "#     else: aux += ' -'\n",
    "# card += 'b2B0Had lnN' + aux*nCat + '\\n'\n",
    "\n",
    "#Hadronization fraction of B+\n",
    "# aux = ''\n",
    "# for n in processes:\n",
    "#     if n in ['DstPip', 'DstPipPi0', 'BpDstmHc', 'BmDstmHc']: aux += ' 1.3'\n",
    "#     else: aux += ' -'\n",
    "# card += 'b2BpHad lnN' + aux*nCat + '\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-23T00:02:03.081Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Branching ratio uncertainty\n",
    "decayBR = pickle.load(open('../data/forcedDecayChannelsFactors.pickle', 'rb'))\n",
    "\n",
    "for n in processes:\n",
    "    if n in ['tau', 'DstPip', 'DstPi0', 'DstPipPim', 'DstPipPi0', 'DstPi0Pi0']: continue\n",
    "#     if n in ['tau', 'DstPip', 'DstPi0', 'DstPipPim', 'DstPipPi0', 'DstPi0Pi0', 'BmDstmHc']: continue\n",
    "    val = ' {:.2f}'.format(1+decayBR[n][1]/decayBR[n][0])\n",
    "    aux = ''\n",
    "    for nn in processes:\n",
    "        if nn == n or (n=='mu' and nn=='tau'): \n",
    "            aux += val\n",
    "        else: \n",
    "            aux += ' -'\n",
    "    card += n + 'Br lnN' + aux*nCat + '\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-23T00:02:03.085Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Branching ratio uncertainty with isospin symmetry constraint\n",
    "val = ' {:.2f}'.format(1+decayBR['DstPip'][1]/decayBR['DstPip'][0]) #DstPi0 has no info\n",
    "aux = ''\n",
    "for n in processes:\n",
    "    if n in ['DstPip', 'DstPi0']: aux += val\n",
    "    else: aux += ' -'\n",
    "card += 'DstPiBr lnN' + aux*nCat + '\\n'\n",
    "\n",
    "val = ' {:.2f}'.format(1+decayBR['DstPipPim'][1]/decayBR['DstPipPim'][0]) #DstPipPim is the only one meaasured\n",
    "aux = ''\n",
    "for n in processes:\n",
    "    if n in ['DstPipPim', 'DstPipPi0', 'DstPi0Pi0']: aux += val\n",
    "    else: aux += ' -'\n",
    "card += 'DstPiPiBr lnN' + aux*nCat + '\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-23T00:02:03.089Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "card += 60*'-'+'\\n'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Shape Systematics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-23T00:02:03.096Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# card += 'trg{}SF shape'.format(cat.trg) + ' 1.'*nProc*nCat + '\\n'\n",
    "# card += 'muonIdSF shape' + ' 1.'*nProc*nCat + '\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-23T00:02:03.099Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "aux = ''\n",
    "for c in categories:\n",
    "    if c.startswith('AddTk_'):\n",
    "        aux += ' 1.'*nProc\n",
    "    else: aux += ' -'*nProc\n",
    "card += 'tkPVfrac shape' + aux + '\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-23T00:02:03.103Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# B0 pT spectrum\n",
    "aux = ''\n",
    "for p in processes:\n",
    "    if p in SamplesB0:\n",
    "        aux += ' 1.'\n",
    "    else:\n",
    "        aux += ' -'\n",
    "\n",
    "names = []\n",
    "for k in histo.values()[0].keys():\n",
    "    if k.startswith('mu__B0pT') and k.endswith('Up'):\n",
    "        names.append(k[4:-2])\n",
    "for n in sorted(names):\n",
    "    card += n + ' shape' + aux*nCat + '\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-23T00:02:03.106Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# B +/- pT spectrum\n",
    "aux = ''\n",
    "for p in processes:\n",
    "    if p in SamplesBp:\n",
    "        aux += ' 1.'\n",
    "    else:\n",
    "        aux += ' -'\n",
    "\n",
    "names = []\n",
    "for k in histo.values()[0].keys():\n",
    "    if k.startswith('mu__BpPt') and k.endswith('Up'):\n",
    "        names.append(k[4:-2])\n",
    "for n in sorted(names):\n",
    "    card += n + ' shape' + aux*nCat + '\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-23T00:02:03.111Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Form Factors from Hammer\n",
    "for n_pFF in FreeParFF:\n",
    "    aux = ''\n",
    "    for p in processes:\n",
    "        if p in ['tau', 'mu']:\n",
    "            aux += ' 1.'\n",
    "        else:\n",
    "            aux += ' -'\n",
    "    card += 'B2Dst'+schemeFF+'{} shape'.format(n_pFF) + aux*nCat + '\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-23T00:02:03.116Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Dstst mix composition\n",
    "aux = ''\n",
    "for p in processes:\n",
    "    if p == 'DstPip' or p == 'TauDstPip': \n",
    "        aux += ' 1.'\n",
    "    else: \n",
    "        aux += ' -'\n",
    "card += 'fDststWide shape' + aux*nCat + '\\n'\n",
    "# card += 'DstPipWidth shape' + aux*nCat + '\\n'\n",
    "card += 'D2420_10Width shape' + aux*nCat + '\\n'\n",
    "card += 'D2430_10Width shape' + aux*nCat + '\\n'\n",
    "card += 'D2460_1StWidth shape' + aux*nCat + '\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-23T00:02:03.119Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Dstst->DstPiPi width\n",
    "aux = ''\n",
    "for p in processes:\n",
    "    if p == 'DstPipPim' or p == 'DstPi0Pi0': \n",
    "        aux += ' 1.'\n",
    "    else: aux += ' -'\n",
    "card += 'DstPiPiWidth shape' + aux*nCat + '\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-23T00:02:03.122Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Hc mix composition\n",
    "aux = ''\n",
    "for p in processes:\n",
    "    if p == 'DstmD0': aux += ' 1.'\n",
    "    else: aux += ' -'\n",
    "card += 'BrB02DstD0Kp shape' + aux*nCat + '\\n'\n",
    "card += 'BrB02DstD0Kstp shape' + aux*nCat + '\\n'\n",
    "card += 'BrB02DstDst0Kp shape' + aux*nCat + '\\n'\n",
    "card += 'BrB02DstDst0Kstp shape' + aux*nCat + '\\n'\n",
    "\n",
    "aux = ''\n",
    "for p in processes:\n",
    "    if p == 'DstmDp': aux += ' 1.'\n",
    "    else: aux += ' -'\n",
    "card += 'BrB02DstDpK0 shape' + aux*nCat + '\\n'\n",
    "card += 'BrB02DstDpKst0 shape' + aux*nCat + '\\n'\n",
    "\n",
    "aux = ''\n",
    "for p in processes:\n",
    "    if p == 'DstmDp' or p == 'DstmD0': aux += ' 1.'\n",
    "    else: aux += ' -'\n",
    "card += 'BrB02DstDstpK0 shape' + aux*nCat + '\\n'\n",
    "card += 'BrB02DstDstpKst0 shape' + aux*nCat + '\\n'\n",
    "\n",
    "aux = ''\n",
    "for p in processes:\n",
    "    if p == 'DstmDsp': aux += ' 1.'\n",
    "    else: aux += ' -'\n",
    "card += 'BrB02DstDs shape' + aux*nCat + '\\n'\n",
    "card += 'BrB02DstDsst shape' + aux*nCat + '\\n'\n",
    "card += 'BrB02DstDs0st shape' + aux*nCat + '\\n'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### MC statistic systematics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-23T00:02:03.127Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "if useMCstats:\n",
    "    card += 'AddTk_p_mHad autoMCStats 2 1 1\\n'\n",
    "    card += 'AddTk_m_mHad autoMCStats 2 1 1\\n'\n",
    "    # card += 'AddTk_pm_mHad autoMCStats 2 1 1\\n'\n",
    "    card += 'AddTk_pm_mVis autoMCStats 2 1 1\\n'\n",
    "    card += 'AddTk_pp_mHad autoMCStats 2 1 1\\n'\n",
    "    card += 'AddTk_mm_mHad autoMCStats 2 1 1\\n'\n",
    "\n",
    "    if useMVA:\n",
    "        card += 'MVA autoMCStats 2 1 1\\n'\n",
    "    else:\n",
    "    #     card += 'Est_mu* autoMCStats 0 1 1\\n'\n",
    "    #     card += 'M2_miss* autoMCStats 0 1 1\\n'\n",
    "\n",
    "        card += 'Unrolled_q2bin0 autoMCStats 0 1 1\\n'\n",
    "        card += 'Unrolled_q2bin1 autoMCStats 0 1 1\\n'\n",
    "        if not blinded_fit:\n",
    "            card += 'Unrolled_q2bin2 autoMCStats 0 1 1\\n'\n",
    "            card += 'Unrolled_q2bin3 autoMCStats 0 1 1\\n'\n",
    "\n",
    "    card += 60*'-'+'\\n'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Defining groups of systematics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-23T00:02:03.131Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# autoMCStats group = defined by default when using autoMCStats\n",
    "if useMCstats:\n",
    "    aux_FF = ' '.join(['B2Dst'+schemeFF+n for n in FreeParFF])\n",
    "    card += 'B2DstFF group = ' + aux_FF + '\\n'\n",
    "\n",
    "cardParts = card.split(60*'-'+'\\n')\n",
    "\n",
    "scaleNuis = []\n",
    "for ln in cardParts[4].split('\\n'):\n",
    "    scaleNuis.append(ln.split(' ')[0])\n",
    "    \n",
    "shapeNuis = []\n",
    "for ln in cardParts[5].split('\\n'):\n",
    "    if 'autoMCStats' in ln:\n",
    "        continue\n",
    "    shapeNuis.append(ln.split(' ')[0])\n",
    "\n",
    "card += 'allSys group = ' + ' '.join(scaleNuis+shapeNuis) + '\\n'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Create output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-23T00:02:03.150Z"
    },
    "hidden": true,
    "hide_input": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print card"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-23T00:02:03.164Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "if fitRegionsOnly:\n",
    "    fc = open(card_location.replace('.txt', '_fitRegionsOnly.txt'), 'w')\n",
    "else:\n",
    "    fc = open(card_location, 'w')\n",
    "fc.write(card)\n",
    "fc.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-23T00:02:03.170Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "if not os.path.isdir(outdir):\n",
    "    os.system('mkdir -p ' + outdir + '/fig');\n",
    "\n",
    "if 'processOrder' in vars().keys():\n",
    "    with open(outdir + '/eventCounting.txt', 'w') as f:\n",
    "        for p in processOrder + ['tot']:\n",
    "            f.write(p + '   ' + eventCountingStr[p] + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Combine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-23T00:02:03.175Z"
    }
   },
   "outputs": [],
   "source": [
    "if not runCombine:\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-23T00:02:03.179Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "globalChannelMasking = [\n",
    "#     'AddTk_p_mHad',\n",
    "#     'AddTk_m_mHad',\n",
    "#     'AddTk_pm_mVis',\n",
    "    'AddTk_pm_mHad',\n",
    "#     'AddTk_pp_mHad',\n",
    "#     'AddTk_mm_mHad',\n",
    "#     'Unrolled_q2bin0',\n",
    "#     'Unrolled_q2bin1',\n",
    "#     'Unrolled_q2bin2',\n",
    "#     'Unrolled_q2bin3', \n",
    "    'B_pt',\n",
    "    'B_eta',\n",
    "    'Est_mu_q2bin0',\n",
    "    'Est_mu_q2bin1',\n",
    "    'Est_mu_q2bin2',\n",
    "    'Est_mu_q2bin3',\n",
    "    'M2_miss_q2bin0',\n",
    "    'M2_miss_q2bin1',\n",
    "    'M2_miss_q2bin2',\n",
    "    'M2_miss_q2bin3',\n",
    "#     'MVA'\n",
    "]\n",
    "\n",
    "if blinded_fit:\n",
    "    globalChannelMasking += ['Unrolled_q2bin2', 'Unrolled_q2bin3']\n",
    "#     globalChannelMasking += ['M2_miss_q2bin2', 'M2_miss_q2bin3']\n",
    "    pass\n",
    "\n",
    "globalChannelMaskingStr = ','.join(['mask_{}=1'.format(c) for c in globalChannelMasking])\n",
    "print globalChannelMaskingStr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-23T00:02:03.185Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "aux = card_location\n",
    "if fitRegionsOnly:\n",
    "    aux = card_location.replace('.txt', '_fitRegionsOnly.txt')\n",
    "\n",
    "cmd = 'text2workspace.py ' + aux \n",
    "cmd += ' -o ' + aux.replace('.txt', '.root')\n",
    "cmd += ' --no-b-only'\n",
    "cmd += ' --verbose 1'\n",
    "cmd += ' --channel-masks'\n",
    "# cmd += ' --no-wrappers'\n",
    "status, output = commands.getstatusoutput(cmd)\n",
    "if status: \n",
    "    print output\n",
    "    raise\n",
    "else:\n",
    "    text_file = open(aux.replace('.txt', '_text2workspace.out'), \"w\")\n",
    "    text_file.write(output)\n",
    "    text_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-23T00:02:03.189Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "if runScanOnly:\n",
    "    channelMasking = [\n",
    "#         'AddTk_p_mHad',\n",
    "#         'AddTk_m_mHad',\n",
    "#         'AddTk_pm_mVis',\n",
    "        'AddTk_pm_mHad',\n",
    "#         'AddTk_pp_mHad',\n",
    "#         'AddTk_mm_mHad',\n",
    "        'Unrolled_q2bin0',\n",
    "        'Unrolled_q2bin1',\n",
    "        'Unrolled_q2bin2',\n",
    "        'Unrolled_q2bin3', \n",
    "#         'Est_mu_q2bin0',\n",
    "#         'Est_mu_q2bin1',\n",
    "#         'Est_mu_q2bin2',\n",
    "#         'Est_mu_q2bin3',\n",
    "        'M2_miss_q2bin0',\n",
    "        'M2_miss_q2bin1',\n",
    "        'M2_miss_q2bin2',\n",
    "        'M2_miss_q2bin3',\n",
    "#         'MVA',\n",
    "    ]\n",
    "    scan_tag='EstMuOnly'\n",
    "    \n",
    "    cmd = 'combine'\n",
    "    cmd += ' -M MultiDimFit'\n",
    "    cmd += ' --algo grid --points=100'\n",
    "#     cmd += ' --cminDefaultMinimizerType Minuit2'\n",
    "#     cmd += ' --cminDefaultMinimizerAlgo Migrad'\n",
    "#     cmd += ' --cminDefaultMinimizerTolerance=0.2'\n",
    "#     cmd += ' --setRobustFitStrategy 2 --setRobustFitTolerance 0.001'\n",
    "    cmd += ' --cminDefaultMinimizerStrategy=2 --robustFit 1'\n",
    "    cmd += ' --X-rtd MINIMIZER_analytic'\n",
    "    cmd += ' -d ' + card_location.replace('.txt', '.root')\n",
    "    cmd += ' --rMin={:.3f} --rMax={:.3f}'.format(0.15, 0.45)\n",
    "    cmd += ' -n {}_scanOnly_{}'.format(card_name, scan_tag)\n",
    "    if len(channelMasking):\n",
    "        cmd += ' --setParameters ' + ','.join(['mask_{}=1'.format(c) for c in channelMasking])\n",
    "    cmd += ' --verbose 1'\n",
    "    print cmd\n",
    "    status, output = commands.getstatusoutput(cmd)\n",
    "    \n",
    "    cmd = 'mv higgsCombine{}_scanOnly_{}.MultiDimFit.mH120.root '.format(card_name, scan_tag)\n",
    "    cmd += outdir + '/'\n",
    "    print '\\n'+cmd\n",
    "    os.system(cmd)\n",
    "    \n",
    "    cmd = 'plot1DScan.py {}/higgsCombine{}_scanOnly_{}.MultiDimFit.mH120.root'.format(outdir, card_name, scan_tag)\n",
    "    cmd += '; mv scan.png '+outdir+'/scan_'+scan_tag+'_scanOnly.png'\n",
    "    print '\\n'+cmd\n",
    "    \n",
    "    os.system(cmd)\n",
    "    res_nominal = getUncertaintyFromLimitTree(outdir + '/higgsCombine{}_scanOnly_{}.MultiDimFit.mH120.root'.format(card_name, scan_tag))\n",
    "    display(Image(filename=outdir+'/scan_'+scan_tag+'_scanOnly.png'))\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Run bias studies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-23T00:02:03.195Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "if runBias:\n",
    "    nToys = 30\n",
    "    cmd = 'combine -M GenerateOnly'\n",
    "    cmd += ' -d ' + card_location.replace('.txt', '.root')\n",
    "    cmd += ' --seed 6741'\n",
    "    cmd += ' --noMCbonly 1'\n",
    "    cmd += ' --setParameters r={},{} --freezeParameters r'.format(SM_RDst, globalChannelMaskingStr)\n",
    "    cmd += ' --toysFrequentist -t {} --saveToys'.format(nToys)\n",
    "    cmd += ' -n {} -m {:.0f}'.format(card_name, 100*SM_RDst)\n",
    "    print cmd\n",
    "    status, output = commands.getstatusoutput(cmd)\n",
    "    if status:\n",
    "        print output\n",
    "        raise\n",
    "\n",
    "#     cmd = 'combine -M FitDiagnostics'\n",
    "    cmd = 'combine -M MultiDimFit --algo grid --points=100'\n",
    "    cmd += ' --robustFit 1 --cminDefaultMinimizerStrategy 0 --X-rtd MINIMIZER_analytic'\n",
    "#     cmd += ' --skipBOnlyFit'\n",
    "    cmd += ' --seed 6742'\n",
    "    cmd += ' -d ' + card_location.replace('.txt', '.root')\n",
    "    cmd += ' --toysFile higgsCombine{}.GenerateOnly.mH{}.6741.root -t {}'.format(card_name, 100*SM_RDst, nToys)\n",
    "    cmd += ' --setParameters r={:.2f},{}'.format(SM_RDst, globalChannelMaskingStr)\n",
    "    cmd += ' --setParameterRanges r=0.1,0.8'\n",
    "    cmd += ' -n {}_toys -m {:.0f}'.format(card_name, 100*SM_RDst)\n",
    "#     cmd += ' --out ' + outdir\n",
    "#     cmd += ' --trackParameters rgx{.*}'\n",
    "    cmd += ' --verbose 1'\n",
    "    print cmd\n",
    "    \n",
    "    status, output = commands.getstatusoutput(cmd)\n",
    "    for line in output.split('\\n'):\n",
    "        if 'ERROR' in line: print line.replace('ERROR', '\\033[1m\\x1b[31mError\\x1b[0m')\n",
    "    if status:\n",
    "        print output\n",
    "        raise\n",
    "        \n",
    "    if os.path.isdir(outdir + '/biasStudyToys'):\n",
    "        os.system('rm -rf ' + outdir + '/biasStudyToys')\n",
    "    os.system('mkdir ' + outdir + '/biasStudyToys')\n",
    "    os.system('mv -v *{}*.GenerateOnly.*.root '.format(card_name) + outdir + '/biasStudyToys/')\n",
    "#     os.system('mv -v higgsCombine{}_toys.FitDiagnostics.*.root '.format(card_name) + outdir + '/biasStudyToys/')\n",
    "    os.system('mv -v higgsCombine{}_toys.MultiDimFit.*.root '.format(card_name) + outdir + '/biasStudyToys/')\n",
    "    os.system('mv combine_logger.out ' + outdir + '/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-23T00:02:03.202Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "if runBias:\n",
    "#     f = ur.open(outdir+'/fitDiagnostics{}_toys.root'.format(card_name))\n",
    "#     r = f['tree_fit_sb']['r'].array()\n",
    "#     rLoErr = f['tree_fit_sb']['rLoErr'].array()\n",
    "#     rHiErr = f['tree_fit_sb']['rHiErr'].array()\n",
    "    fname = 'higgsCombine{}_toys.MultiDimFit.mH{:.0f}.6742.root'.format(card_name, 100*SM_RDst)\n",
    "    res = getUncertaintyFromLimitTree(outdir + '/biasStudyToys/'+fname, verbose=False)\n",
    "    r = res[:,0]\n",
    "    rLoErr = res[:,1]\n",
    "    rHiErr = res[:,2]\n",
    "    \n",
    "    plt.rcParams.update({'font.size': 18})\n",
    "    fig = plt.figure(figsize=(8,6))\n",
    "    plt.errorbar(np.arange(1, 1+r.shape[0]), r, yerr=np.column_stack((rLoErr, rHiErr)).T, fmt='o', color='#1f77b4', label='Toys fit results')\n",
    "    m = np.mean(r)\n",
    "    sm = np.std(r)/np.sqrt(r.shape[0])\n",
    "    x = [0, r.shape[0]+1]\n",
    "    plt.fill_between(x, 2*[m-sm], 2*[m+sm], color='#ff7f0e', alpha=0.3)\n",
    "    plt.plot(x, 2*[m], color='#d62728', lw=1, label='Toys mean')\n",
    "    plt.plot(x, [SM_RDst, SM_RDst], 'm--', lw=2, label='Injected value')\n",
    "    plt.legend(loc='upper right', numpoints=1)\n",
    "    plt.xlabel('Toy number')\n",
    "    plt.ylabel(r'$R(D^*)$')\n",
    "    plt.savefig(outdir + '/fig/biasStudy_toysResults.png')\n",
    "    \n",
    "    z = (r - SM_RDst)/(0.5*(rLoErr + rHiErr))\n",
    "    h = create_TH1D(z, name='hZtest', binning=[int(2*np.sqrt(r.shape[0])), -4, 4], axis_title=['#hat{R(D*)} - R(D*) / #sigma', 'Number of toys'])\n",
    "    h.Sumw2()\n",
    "    h.Fit('gaus', 'ILQ')\n",
    "    rt.gStyle.SetStatY(0.95)\n",
    "    c = drawOnCMSCanvas(CMS_lumi, [h])\n",
    "    c.Draw()\n",
    "    c.SaveAs(outdir + '/fig/biasStudy_zTest.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run pre-scan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-23T00:02:03.208Z"
    },
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "if use_real_data:\n",
    "    rDst_postFitRegion = [0.05, 0.7]\n",
    "else:\n",
    "    rDst_postFitRegion = [0.01, 0.6]\n",
    "\n",
    "cmd = 'combine'\n",
    "cmd += ' -M MultiDimFit'\n",
    "cmd += ' --algo grid --points=70'\n",
    "cmd += ' --robustFit 1'\n",
    "cmd += ' -d ' + card_location.replace('.txt', '.root')\n",
    "cmd += ' --X-rtd MINIMIZER_analytic'\n",
    "cmd += ' --rMin={:.2f} --rMax={:.2f}'.format(*rDst_postFitRegion)\n",
    "cmd += ' -n {}_preFitScan'.format(card_name)\n",
    "cmd += ' --setParameters r={:.2f},{}'.format(SM_RDst, globalChannelMaskingStr)\n",
    "cmd += ' --verbose -1'\n",
    "print cmd\n",
    "os.system(cmd)\n",
    "cmd = 'plot1DScan.py higgsCombine{}_preFitScan.MultiDimFit.mH120.root'.format(card_name)\n",
    "cmd += '; mv scan.png {}/scan_preFit.png'.format(outdir)\n",
    "cmd += '; mv higgsCombine{}_preFitScan.MultiDimFit.mH120.root {}/'.format(card_name, outdir)\n",
    "os.system(cmd)\n",
    "res = getUncertaintyFromLimitTree(outdir+'/higgsCombine{}_preFitScan.MultiDimFit.mH120.root'.format(card_name))\n",
    "rDst_postFitRegion = [res[0] - 3*res[1], res[0] + 3*res[2]]\n",
    "fit_RDst = res[0]\n",
    "display(Image(filename=outdir+'/scan_preFit.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the Maximum Likelyhood fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-23T00:02:03.213Z"
    }
   },
   "outputs": [],
   "source": [
    "seedMLf = '6741'\n",
    "forceRDst = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-23T00:02:03.217Z"
    },
    "hide_input": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cmd = 'combine -M FitDiagnostics'\n",
    "cmd += ' --robustFit 1 --robustHesse 1 --cminDefaultMinimizerStrategy 2 --X-rtd MINIMIZER_analytic'\n",
    "cmd += ' --seed ' + seedMLf\n",
    "cmd += ' -d ' + card_location.replace('.txt', '.root')\n",
    "if forceRDst:\n",
    "    cmd += ' --setParameterRanges r={:.2f},{:.2f}'.format(0, 1)  \n",
    "    cmd += ' --customStartingPoint --setParameters r={:.3f}'.format(SM_RDst)\n",
    "else:\n",
    "    cmd += ' --skipBOnlyFit'\n",
    "    cmd += ' --setParameterRanges r={:.2f},{:.2f}'.format(*rDst_postFitRegion)  \n",
    "    cmd += ' --setParameters r={:.3f}'.format(fit_RDst)\n",
    "if globalChannelMaskingStr:\n",
    "    cmd += ',' + globalChannelMaskingStr\n",
    "runName = card_name + ('_RDstFixed' if forceRDst else '')\n",
    "cmd += ' -n ' + runName\n",
    "cmd += ' --out ' + outdir\n",
    "cmd += ' --saveShapes --saveWithUncertainties --saveNormalizations'\n",
    "cmd += ' --trackParameters rgx{.*}'\n",
    "cmd += ' --plots'\n",
    "cmd += ' --verbose 0'\n",
    "\n",
    "if runFitDiagnostics:\n",
    "    print cmd\n",
    "    status, output = commands.getstatusoutput(cmd)\n",
    "    if status or 'There was a crash.' in output:\n",
    "        print output\n",
    "        raise\n",
    "    for line in output.split('\\n'):\n",
    "            if 'ERROR' in line: print line.replace('ERROR', '\\033[1m\\x1b[31mError\\x1b[0m')\n",
    "            if line.startswith('customStartingPoint'): print line\n",
    "    os.system('mv combine_logger.out ' + outdir + '/combine_logger_FitDiagnostics.out')\n",
    "    os.system('mv ./higgsCombine{}.FitDiagnostics.mH120.{}.root '.format(runName, seedMLf) + outdir + '/');\n",
    "    \n",
    "    f = ur.open(glob(outdir + '/higgsCombine{}.FitDiagnostics.mH120.{}.root'.format(runName, seedMLf))[0])\n",
    "    c, d, u, _ = f['limit']['limit'].array()\n",
    "    print 'R(D*) = {:.3f} +{:.3f}/-{:.3f} [{:.1f} %]'.format(c, u-c, c-d, 100*(u-d)*0.5/c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-23T00:02:03.220Z"
    },
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "# Get post-fit shapes\n",
    "n = outdir + '/fitDiagnostics{}.root'.format(card_name+ ('_RDstFixed' if forceRDst else ''))\n",
    "fFitDiagnostics = rt.TFile.Open(n, 'READ')\n",
    "if forceRDst:\n",
    "    fd = fFitDiagnostics.shapes_fit_b\n",
    "else:\n",
    "    fd = fFitDiagnostics.shapes_fit_s\n",
    "\n",
    "if not 'histo' in vars().keys(): histo = loadHisto4CombineFromRoot(histo_file_dir, card_name)\n",
    "    \n",
    "histo_postfit = {}\n",
    "for regName in [k.GetTitle() for k in fd.GetListOfKeys()]:\n",
    "    histo_postfit[regName] = {}\n",
    "    \n",
    "    for n, h in histo[regName].iteritems():\n",
    "        if '__' in n: \n",
    "            continue\n",
    "        h_post = h.Clone(h.GetName() + '_postfit')\n",
    "        if 'data' in n:\n",
    "            h_fit = fd.Get(regName+'/total')\n",
    "            h_data = h.Clone(h.GetName() + '_data')\n",
    "            for i in range(1, h_post.GetNbinsX()+1):\n",
    "                h_post.SetBinContent(i, h_fit.GetBinContent(i))\n",
    "                h_post.SetBinError(i, h_fit.GetBinError(i))     \n",
    "\n",
    "            histo_postfit[regName]['total'] = h_post\n",
    "            histo_postfit[regName]['data'] = h_data\n",
    "        else:\n",
    "            h_fit = fd.Get(regName+'/'+n)\n",
    "            if not h_fit: \n",
    "                print n+' missing from '+regName\n",
    "                continue\n",
    "            for i in range(1, h_post.GetNbinsX()+1):\n",
    "                h_post.SetBinContent(i, h_fit.GetBinContent(i))\n",
    "                h_post.SetBinError(i, h_fit.GetBinError(i)) \n",
    "\n",
    "            histo_postfit[regName][n] = h_post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-23T00:02:03.224Z"
    },
    "hide_input": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "h2 = fFitDiagnostics.Get('covariance_fit_' + ('b' if forceRDst else 's'))\n",
    "rt.gStyle.SetPaintTextFormat('.1f')\n",
    "\n",
    "N = h2.GetNbinsX()\n",
    "n=35\n",
    "\n",
    "h2.GetXaxis().SetRange(1, n)\n",
    "h2.GetYaxis().SetRangeUser(N-n, N)\n",
    "h2.SetMarkerSize(.8)\n",
    "h2.LabelsOption(\"v\")\n",
    "CC = drawOnCMSCanvas(CMS_lumi, [h2, h2], ['colz', 'text same'], size=(900, 700), tag='tl', mL=0.22, mR=0.15, mB=0.25)\n",
    "CC.SaveAs(outdir+'/fig/covariance_zoom'+ ('_RDstFixed' if forceRDst else '')+'.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-23T00:02:03.228Z"
    },
    "hide_input": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cUnrolledPost = []\n",
    "for i_q2 in range(len(binning['q2'])-1):\n",
    "    q2_l = binning['q2'][i_q2]\n",
    "    q2_h = binning['q2'][i_q2 + 1]\n",
    "    nameU = 'Unrolled_q2bin'+str(i_q2)\n",
    "    histo_postfit[nameU]['data'].GetXaxis().SetTitle('Unrolled 2D bins')\n",
    "    histo_postfit[nameU]['data'].GetYaxis().SetTitle('Events')\n",
    "    cUnrolledPost.append(plot_SingleCategory(CMS_lumi, histo_postfit[nameU], draw_pulls=True, pullsRatio=False,\n",
    "                                             addText='Cat. '+category.capitalize()+', {:.1f} <  q^{{2}}  < {:.1f} GeV^{{2}}'.format(q2_l, q2_h), \n",
    "                                             logy=True, legBkg=True,\n",
    "                                             procOrder = ['tau', 'DstD', 'Dstst', 'mu'],\n",
    "                                             min_y=1, \n",
    "                                             tag='Unrolled_q2bin'+str(i_q2), \n",
    "                                             legLoc=[0.15, 0.6, 0.3, 0.8],\n",
    "                                             maskData = blinded_fit and (False if i_q2 < 2 else True),\n",
    "                                             figsize = [1200, 400]\n",
    "                                      ))\n",
    "    n = outdir+'/fig/Unrolled_q2bin'+str(i_q2)+'_postfit'+ ('_RDstFixed' if forceRDst else '')+'.png'\n",
    "    cUnrolledPost[i_q2].SaveAs(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-23T00:02:03.232Z"
    },
    "hide_input": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cSigPost = plot_gridVarQ2(CMS_lumi, binning, histo_postfit, draw_pulls=True, \n",
    "                          categoryText=cat.name.capitalize(),\n",
    "                          iq2_maskData=[2, 3] if blinded_fit else [])\n",
    "n = outdir+'/fig/signalRegion_postfit'+ ('_RDstFixed' if forceRDst else '')+'.png'\n",
    "cSigPost.SaveAs(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-23T00:02:03.235Z"
    },
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "if useMVA:\n",
    "    cMVAPost = plot_SingleCategory(CMS_lumi, histo_postfit['MVA'], draw_pulls=True,\n",
    "                                  addText='', logy=True, legBkg=True,\n",
    "                                  procOrder = ['tau', 'DstD', 'Dstst', 'mu'],\n",
    "                                  min_y=1, tag='MVA', legLoc=[0.2, 0.1, 0.4, 0.4])\n",
    "    n = outdir+'/fig/MVA_postfit'+ ('_RDstFixed' if forceRDst else '')+'.png'\n",
    "    cMVAPost.SaveAs(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-23T00:02:03.240Z"
    },
    "hide_input": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cB_pt_post = plot_SingleCategory(CMS_lumi, histo_postfit['B_pt'], draw_pulls=True,\n",
    "                                 addText='', logy=False, legBkg=True,\n",
    "                                 procOrder = ['tau', 'DstD', 'Dstst', 'mu'],\n",
    "                                 min_y=1, tag='B_pt', legLoc=[0.65, 0.45, 0.9, 0.75])\n",
    "n = outdir+'/fig/B_pt_postfit'+ ('_RDstFixed' if forceRDst else '')+'.png'\n",
    "cB_pt_post.SaveAs(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-23T00:02:03.246Z"
    },
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "cB_eta_post = plot_SingleCategory(CMS_lumi, histo_postfit['B_eta'], draw_pulls=True,\n",
    "                                  addText='', logy=False, legBkg=True,\n",
    "                                  procOrder = ['tau', 'DstD', 'Dstst', 'mu'],\n",
    "                                  min_y=1, tag='B_eta', legLoc=[0.44, 0.23, 0.64, 0.53])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-23T00:02:03.250Z"
    },
    "code_folding": [],
    "hide_input": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cSidePost = {}\n",
    "for k in np.sort([k for k in histo.keys() if 'AddTk' in k]):\n",
    "    legLoc = [0.67, 0.3, 0.93, 0.72]\n",
    "    if 'Vis' in k:\n",
    "        legLoc = [0.18, 0.4, 0.4, 0.75]\n",
    "    cSidePost[k] = plot_SingleCategory(CMS_lumi, histo_postfit[k], \n",
    "                                       xtitle=getControlXtitle(k), \n",
    "                                       addText='Cat. '+cat.name.capitalize() + ', ' + getControlSideText(k),\n",
    "                                       tag=k, legLoc=legLoc,\n",
    "                                       draw_pulls=True\n",
    "                                      )\n",
    "    n = outdir+'/fig/'+k+'_postfit'+ ('_RDstFixed' if forceRDst else '')+'.png'\n",
    "    cSidePost[k].SaveAs(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-23T00:02:03.256Z"
    }
   },
   "outputs": [],
   "source": [
    "dumpDiffNuisances = dumpDiffNuisances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-23T00:02:03.260Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cmd = 'python diffNuisances.py '.format(os.environ['CMSSW_BASE'])\n",
    "cmd += outdir + '/fitDiagnostics{}.root'.format(card_name+ ('_RDstFixed' if forceRDst else ''))\n",
    "if not forceRDst:\n",
    "    cmd += ' --skipFitB'\n",
    "# cmd += ' --all'\n",
    "cmd += ' --abs'\n",
    "cmd += ' -g {}/nuisance_difference'.format(outdir) + ('_RDstFixed' if forceRDst else '') + '.root'\n",
    "print cmd\n",
    "status, output = commands.getstatusoutput(cmd)\n",
    "dumpDiffNuisances(output, outdir, tag='_RDstFixed' if forceRDst else '', \n",
    "                  useBonlyResults=forceRDst, parsToPrint=35)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": true
   },
   "source": [
    "## Run likelyhood scan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-23T00:02:03.265Z"
    },
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "cmd = 'combine'\n",
    "cmd += ' -M MultiDimFit'\n",
    "cmd += ' --algo grid --points=100'\n",
    "cmd += ' --cminDefaultMinimizerStrategy=2 --robustFit 1 --X-rtd MINIMIZER_analytic'\n",
    "cmd += ' -d ' + card_location.replace('.txt', '.root')\n",
    "cmd += ' --rMin={:.3f} --rMax={:.3f}'.format(*rDst_postFitRegion)\n",
    "cmd += ' -n {}_nominal'.format(card_name)\n",
    "cmd += ' --setParameters r={:.2f},{}'.format(fit_RDst, globalChannelMaskingStr)\n",
    "cmd += ' --verbose -1'\n",
    "print cmd\n",
    "os.system(cmd)\n",
    "cmd = 'plot1DScan.py higgsCombine{}_nominal.MultiDimFit.mH120.root'.format(card_name)\n",
    "cmd += '; mv scan.png scan_nominal.png'\n",
    "os.system(cmd)\n",
    "res_nominal = getUncertaintyFromLimitTree('higgsCombine{}_nominal.MultiDimFit.mH120.root'.format(card_name))\n",
    "rDst_postFitRegion = [res_nominal[0] - 2.5*res_nominal[1], res_nominal[0] + 2.5*res_nominal[2]]\n",
    "fit_RDst = res_nominal[0]\n",
    "display(Image(filename='scan_nominal.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uncertainy breakdown by group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-23T00:02:03.271Z"
    },
    "hide_input": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cmd = 'combine -M MultiDimFit'\n",
    "cmd += ' --cminDefaultMinimizerStrategy=2 --robustFit 1 --X-rtd MINIMIZER_analytic'\n",
    "cmd += ' -d ' + card_location.replace('.txt', '.root')\n",
    "cmd += ' --setParameters r={:.2f},{}'.format(fit_RDst, globalChannelMaskingStr)\n",
    "cmd += ' --setParameterRanges r={:.3f},{:.3f}'.format(*rDst_postFitRegion)\n",
    "cmd += ' -n {}_bestfit'.format(card_name)\n",
    "cmd += ' --saveWorkspace --verbose -1'\n",
    "print cmd\n",
    "os.system(cmd);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-23T00:02:03.275Z"
    },
    "hide_input": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Statistical uncertainty\n",
    "cmd = 'combine -M MultiDimFit --algo grid --points=100'\n",
    "cmd += ' --cminDefaultMinimizerStrategy=2 --robustFit 1 --X-rtd MINIMIZER_analytic'\n",
    "cmd += ' -d higgsCombine{}_bestfit.MultiDimFit.mH120.root'.format(card_name)\n",
    "cmd += ' --snapshotName MultiDimFit'\n",
    "cmd += ' --rMin={:.3f} --rMax={:.3f}'.format(*rDst_postFitRegion)\n",
    "cmd += ' -n {}_stat'.format(card_name)\n",
    "cmd += ' --freezeParameters allConstrainedNuisances'\n",
    "cmd += ' --setParameters ' + globalChannelMaskingStr\n",
    "cmd += ' --fastScan' # To be added if there are no free parameters otherwise\n",
    "cmd += ' --verbose -1'\n",
    "print cmd\n",
    "os.system(cmd);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-23T00:02:03.279Z"
    }
   },
   "outputs": [],
   "source": [
    "n = 'higgsCombine{}_stat.MultiDimFit.mH120.root'.format(card_name)\n",
    "getUncertaintyFromLimitTree(n);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-23T00:02:03.282Z"
    },
    "hide_input": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# MC Statistics\n",
    "cmd = 'combine -M MultiDimFit --algo grid --points=100'\n",
    "cmd += ' --cminDefaultMinimizerStrategy=2 --robustFit 1 --X-rtd MINIMIZER_analytic'\n",
    "cmd += ' -d higgsCombine{}_bestfit.MultiDimFit.mH120.root'.format(card_name)\n",
    "cmd += ' --rMin={:.4f} --rMax={:.4f}'.format(*rDst_postFitRegion)\n",
    "cmd += ' -n {}_MCstat'.format(card_name)\n",
    "cmd += ' --snapshotName MultiDimFit'\n",
    "cmd += ' --setParameters ' + globalChannelMaskingStr\n",
    "cmd += ' --freezeNuisanceGroups=autoMCStats'\n",
    "cmd += ' --verbose -1'\n",
    "print cmd\n",
    "os.system(cmd);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-23T00:02:03.286Z"
    }
   },
   "outputs": [],
   "source": [
    "n = 'higgsCombine{}_MCstat.MultiDimFit.mH120.root'.format(card_name)\n",
    "getUncertaintyFromLimitTree(n);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-23T00:02:03.290Z"
    },
    "hide_input": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "json.dump({'r': 'R(D*)'}, open(outdir+'/renameDicLikelihoodScan.json', 'w'))\n",
    "\n",
    "cmd = 'plot1DScan.py higgsCombine{}_nominal.MultiDimFit.mH120.root'.format(card_name)\n",
    "cmd += ' --main-label \"{} {}'.format('Obs.' if use_real_data else 'Asimov', category.capitalize())\n",
    "if blinded_fit: cmd += ' (blinded)'\n",
    "cmd += '\"'\n",
    "cmd += ' --others'\n",
    "cmd += ' \"higgsCombine{}_MCstat.MultiDimFit.mH120.root:Stat. + Syst.:4\"'.format(card_name)\n",
    "cmd += ' \"higgsCombine{}_stat.MultiDimFit.mH120.root:Stat. only:2\"'.format(card_name)\n",
    "cmd += ' --breakdown \"MC stat.,syst.,stat.\"'\n",
    "cmd += ' --translate ' + outdir+'/renameDicLikelihoodScan.json'\n",
    "cmd += '; mv scan.png scan_breakdown.png'\n",
    "print cmd\n",
    "os.system(cmd)\n",
    "display(Image(filename='scan_breakdown.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-23T00:02:03.294Z"
    }
   },
   "outputs": [],
   "source": [
    "os.system('mv higgsCombine{}_*.MultiDimFit.mH120.root '.format(card_name) + outdir + '/')\n",
    "os.system('mv scan* ' + outdir + '/')\n",
    "os.system('mv combine_logger.out ' + outdir + '/');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Run the impact plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Fit first the POI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-23T00:02:03.300Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "if not os.path.isdir(outdir+'/impactPlots'): os.mkdir(outdir+'/impactPlots')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-23T00:02:03.303Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cmd = 'cd {}/impactPlots;'.format(outdir)\n",
    "cmd += ' combineTool.py -M Impacts --doInitialFit -m 120'\n",
    "cmd += ' --robustFit 1 --X-rtd MINIMIZER_analytic'\n",
    "cmd += ' -d ../../../' + card_location.replace('.txt', '.root')\n",
    "cmd += ' -D ' + histo[histo.keys()[0]]['data'].GetName()\n",
    "cmd += ' --setParameters r={:.2f},{}'.format(SM_RDst, globalChannelMaskingStr)\n",
    "cmd += ' --setParameterRanges r=0.05,1'\n",
    "cmd += ' -n {}'.format(card_name)\n",
    "cmd += ' --verbose -1'\n",
    "if runImpacts: os.system(cmd);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    " Perform a similar scan for each nuisance parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "If running on Tier2 condor remmeber to add this line to CombineToolBase.py ln 11\n",
    "``source /cvmfs/cms.cern.ch/cmsset_default.sh``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-23T00:02:03.309Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cmd = 'cd {}/impactPlots;'.format(outdir)\n",
    "cmd += ' combineTool.py -M Impacts --doFits -m 120'\n",
    "cmd += ' --robustFit 1 --X-rtd MINIMIZER_analytic'\n",
    "cmd += ' --parallel 100 --job-mode condor --task-name combineImpacts_'+category\n",
    "cmd += ' --sub-opts \"{}\"'.format(stringJubCustomizationCaltechT2.replace('\"', '\\\\\\\"').replace('$', '\\$'))\n",
    "cmd += ' -d ../../../' + card_location.replace('.txt', '.root')\n",
    "cmd += ' -D ' + histo[histo.keys()[0]]['data'].GetName()\n",
    "cmd += ' -n {}'.format(card_name)\n",
    "cmd += ' --setParameters ' + globalChannelMaskingStr \n",
    "cmd += ' --verbose -1'\n",
    "print cmd\n",
    "if runImpacts: os.system(cmd);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Collect the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-23T00:02:03.314Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "status, output = commands.getstatusoutput('condor_q')\n",
    "while runImpacts and ('combineImpacts_'+category in output):\n",
    "    time.sleep(20)\n",
    "    status, output = commands.getstatusoutput('condor_q')\n",
    "    for l in output.split('\\n'):\n",
    "        if 'combineImpacts_'+category in l: \n",
    "            print l\n",
    "            sys.stdout.flush()\n",
    "cmd = 'cd {}/impactPlots;'.format(outdir)\n",
    "cmd += ' combineTool.py -M Impacts -o impacts.json -m 120'\n",
    "cmd += ' -d ../../../' + card_location.replace('.txt', '.root')\n",
    "cmd += ' -n {}'.format(card_name)\n",
    "print cmd\n",
    "if runImpacts: os.system(cmd);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-23T00:02:03.318Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "rename = {\n",
    "'r': 'R(D*)',\n",
    "'B0pT': 'B_{0} p_{T} spectrum',\n",
    "'B2DstCLNR0':'R_{0} (CLN B#rightarrow D*l#nu)',\n",
    "'B2DstCLNeig1':'#lambda_{1} (CLN B#rightarrow D*l#nu)',\n",
    "'B2DstCLNeig2':'#lambda_{2} (CLN B#rightarrow D*l#nu)',\n",
    "'B2DstCLNeig3':'#lambda_{3} (CLN B#rightarrow D*l#nu)',\n",
    "'trgSF': 'Trigger scale factor',\n",
    "'xsecpp2bbXlumi': 'Luminosity*#sigma_{pp#rightarrowbb}',\n",
    "}\n",
    "for i in range(1,5):\n",
    "    s = str(i)\n",
    "    rename['B0pT_lam'+s] = 'B_{0} p_{T} #lambda_{'+s+'}'\n",
    "\n",
    "procName_dic = {\n",
    "'mu'        : 'B_{0}#rightarrow D*#mu#nu',\n",
    "'tau'       : 'B_{0}#rightarrow D*#tau#nu',\n",
    "'DstmD0'    : 'B^{+}#rightarrow D*D_{0}(#muY) + X',\n",
    "'DstmDp'    : 'B^{+}#rightarrow D*D^{+}(#muY) + X',\n",
    "'DstmDsp'   : 'B^{+}#rightarrow D*D_{s}^{+}(#muX)',\n",
    "'DstPip'    : 'B^{+}#rightarrow D*#pi^{+}#mu#nu',\n",
    "'DstPipPi0' : 'B^{+}#rightarrow D*#pi^{+}#pi^{0}#mu#nu',\n",
    "'DstPi0'    : 'B_{0}#rightarrow D*#pi^{0}#mu#nu',\n",
    "'DstPipPim' : 'B_{0}#rightarrow D*#pi^{+}#pi^{-}#mu#nu',\n",
    "'DstPi0Pi0' : 'B_{0}#rightarrow D*#pi^{0}#pi^{0}#mu#nu',\n",
    "'BpDstmHc'  : 'B^{+}#rightarrow D*D(#muX)',\n",
    "'BmDstmHc'  : 'B^{-}#rightarrow D*D(#muX)',\n",
    "'antiB0DstmHc'  : '#bar{B}_{0}#rightarrow D*D(#muX)',\n",
    "'DstPi'     : 'B #rightarrow D**(#rightarrow D*#pi)#mu#nu',\n",
    "'DstPiPi'   : 'B #rightarrow D**(#rightarrow D*#pi#pi)#mu#nu',\n",
    "}\n",
    "\n",
    "for n in procName_dic:\n",
    "    rename[n+'Br'] = 'Branching fraction ' + procName_dic[n]\n",
    "    \n",
    "if runImpacts: \n",
    "    d = json.load(open(outdir+'/impactPlots/impacts.json', 'r'))\n",
    "    for par in d['params']:\n",
    "        name = str(par['name'])\n",
    "        if not name.startswith('prop_bin'): continue\n",
    "        label = name.replace('prop_bin', 'MC stat. ')\n",
    "        label = label.replace('M2_miss_', 'M^{2}_{miss} ')\n",
    "        label = label.replace('Est_mu_', 'E*_{#mu} ')\n",
    "        label = label.replace('q2bin', '[b_{q^{2}}=')\n",
    "        label = label.replace('_bin', '] ')\n",
    "        rename[name] = label + 10*' '\n",
    "\n",
    "    json.dump(rename, open(outdir+'/impactPlots/rename.json', 'w'))\n",
    "\n",
    "    cmd = 'cd {};'.format(outdir)\n",
    "    cmd += 'plotImpacts.py -i impactPlots/impacts.json -o impacts -t impactPlots/rename.json'\n",
    "    os.system(cmd)\n",
    "    IFrame(outdir+'/impacts.pdf', width=900, height=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the Goodness of fit test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-23T00:02:03.322Z"
    }
   },
   "outputs": [],
   "source": [
    "if not runGoF: raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the observed test stat value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-23T00:02:03.327Z"
    }
   },
   "outputs": [],
   "source": [
    "GoF_AdditionalChannelMasking = [\n",
    "#     'AddTk_p_mHad',\n",
    "#     'AddTk_m_mHad',\n",
    "#     'AddTk_pm_mVis',\n",
    "#     'AddTk_pp_mHad',\n",
    "#     'AddTk_mm_mHad',\n",
    "#     'Unrolled_q2bin0',\n",
    "#     'Unrolled_q2bin1',\n",
    "#     'Unrolled_q2bin2',\n",
    "#     'Unrolled_q2bin3', \n",
    "#     'Est_mu_q2bin0',\n",
    "#     'Est_mu_q2bin1',\n",
    "#     'Est_mu_q2bin2',\n",
    "#     'Est_mu_q2bin3',\n",
    "#     'M2_miss_q2bin0',\n",
    "#     'M2_miss_q2bin1',\n",
    "#     'M2_miss_q2bin2',\n",
    "#     'M2_miss_q2bin3',\n",
    "#     'MVA',\n",
    "#     'AddTk_pm_mHad',\n",
    "]\n",
    "\n",
    "maskGoF = globalChannelMaskingStr\n",
    "for c in GoF_AdditionalChannelMasking:\n",
    "    maskGoF += ',mask_'+c+'=1'\n",
    "tag = '_All'\n",
    "# tag = '_SignalRegionOnly'\n",
    "# tag = '_ControlRegionOnly'\n",
    "# tag = '_AddTk_pp_mHad_Only'\n",
    "\n",
    "algo = ['Sat', 'AD'][0]\n",
    "fixRDst = False\n",
    "fitRegionsOnly = False\n",
    "\n",
    "tag += '_algo'+algo\n",
    "if fixRDst:\n",
    "    tag += '_fixRDst'\n",
    "if fitRegionsOnly or algo!='Sat':\n",
    "    tag += '_fitRegionsOnly'\n",
    "    \n",
    "os.system('rm -rf *.GoodnessOfFit.*.root')\n",
    "print tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-23T00:02:03.333Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cmd = 'combine -M GoodnessOfFit'\n",
    "cmd += ' --algo=saturated  --toysFrequentist' if algo=='Sat' else ' --algo=AD'\n",
    "cmd += ' --X-rtd MINIMIZER_analytic  --cminDefaultMinimizerStrategy=1'\n",
    "if not fitRegionsOnly:\n",
    "    cmd += ' --setParametersForFit ' + globalChannelMaskingStr\n",
    "    cmd += ' --setParametersForEval ' + maskGoF\n",
    "if fixRDst or fitRegionsOnly:\n",
    "    aux = card_location.replace('.txt', '.root')\n",
    "    if fitRegionsOnly:\n",
    "        aux = aux.replace('.root', '_fitRegionsOnly.root')\n",
    "    cmd += ' -d ' + aux\n",
    "    cmd += ' --freezeParameters r --setParameters r={:.3f}'.format(SM_RDst, maskGoF)\n",
    "else:\n",
    "    cmd += ' -d results/{cn}/higgsCombine{cn}_bestfit.MultiDimFit.mH120.root'.format(cn=card_name)\n",
    "    cmd += ' --snapshotName MultiDimFit'\n",
    "cmd += ' -n Obs'+tag\n",
    "cmd += ' -t 0 -s 100'\n",
    "cmd += ' --verbose -1'\n",
    "print cmd\n",
    "status, output = commands.getstatusoutput(cmd)\n",
    "print output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the test stat toy distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-23T00:02:03.338Z"
    }
   },
   "outputs": [],
   "source": [
    "cmdToys = cmd.replace('-n Obs', '-n Toys')\n",
    "cmdToys = cmdToys.replace('-t 0 -s 100', '-t 20 -s -1')\n",
    "print cmdToys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-23T00:02:03.341Z"
    }
   },
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "\n",
    "def runCommand(cmd):\n",
    "    status, output = commands.getstatusoutput(cmd)\n",
    "    return [status, output]\n",
    "\n",
    "Nrep = 15\n",
    "p = Pool(min(20,Nrep))\n",
    "outputs = p.map(runCommand, Nrep*[cmdToys])\n",
    "for s,o in outputs:\n",
    "    if s: print o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-23T00:02:03.345Z"
    }
   },
   "outputs": [],
   "source": [
    "gofOutdir = outdir + '/goodnessOfFit'+tag\n",
    "\n",
    "if os.path.isdir(gofOutdir):\n",
    "    os.system('rm -rf ' + gofOutdir)\n",
    "    \n",
    "if not os.path.isdir(gofOutdir):\n",
    "    os.system('mkdir ' + gofOutdir)\n",
    "\n",
    "os.system('mv *.root {}/'.format(gofOutdir));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine them to get the p-value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-23T00:02:03.351Z"
    }
   },
   "outputs": [],
   "source": [
    "f = ur.open(gofOutdir+'/higgsCombineObs'+tag+'.GoodnessOfFit.mH120.100.root')\n",
    "s_obs = f['limit']['limit'].array()[0]\n",
    "\n",
    "s_toys = []\n",
    "for name_toys in glob(gofOutdir+'/higgsCombineToys'+tag+'.GoodnessOfFit.*.root'):\n",
    "    f = ur.open(name_toys)\n",
    "    s_toys += list(f['limit']['limit'].array())\n",
    "p_val = np.sum(s_toys > s_obs)/float(len(s_toys))\n",
    "\n",
    "plt.rcParams.update({'font.size': 18})\n",
    "fig = plt.figure(figsize=(8,6))\n",
    "content, center, _ = plt.hist(s_toys, weights=np.ones_like(s_toys)/float(len(s_toys)), \n",
    "                              alpha=0.7, label='Toys ({:.0f})'.format(float(len(s_toys))))\n",
    "plt.plot([s_obs, s_obs], [0, np.max(content)], 'm--', label='Observed\\np-val {:.1f}%'.format(100*p_val))\n",
    "plt.legend(loc='upper right')\n",
    "plt.xlabel('Test statistic')\n",
    "plt.ylabel('Probability / {:.1f}'.format(0.5*(center[2]-center[1])))\n",
    "plt.savefig(outdir + '/fig/GoF_results'+tag+'.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-23T00:02:03.356Z"
    }
   },
   "outputs": [],
   "source": [
    "strRes = tag[1:]\n",
    "strRes += ' '*(55-len(strRes))\n",
    "strRes += '{:.1f}'.format(s_obs)\n",
    "strRes += ' '*(70-len(strRes))\n",
    "strRes += '{:.1f}\\t{:.1f}'.format(np.percentile(s_toys, 50), np.percentile(s_toys, 95))\n",
    "os.system('echo \"{}\" >> {}/GoF_results.txt'.format(strRes, outdir));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-23T00:02:03.361Z"
    }
   },
   "outputs": [],
   "source": [
    "print 'Done'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14+"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "308px",
    "left": "1550px",
    "right": "20px",
    "top": "120px",
    "width": "338px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
